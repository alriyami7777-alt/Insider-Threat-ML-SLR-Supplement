TY  - JOUR
AU  - Randive, K.D.
AU  - Mohan, R.
AU  - Sivakrishna, A.M.
TI  - Cyber insights: exploring the effectiveness of image-based and vector-based feature representations in insider threat detection
PY  - 2026
T2  - International Journal of Data Science and Analytics
VL  - 21
IS  - 1
C7  - 13
DO  - 10.1007/s41060-025-00960-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105023287047&doi=10.1007%2Fs41060-025-00960-3&partnerID=40&md5=263b0c013c7f72db615a9ab0738b1f3e
AB  - Detecting insider threats is a critical challenge for organizations due to their potential to cause substantial financial and reputational harm. This study explores the effectiveness of two feature representation approaches, vector-based (VecRep) and image-based (ImgRep), in detecting insider threats using various deep learning (DL) and machine learning (ML) models. The study uses the Carnegie Mellon University CERT benchmark dataset, which provides realistic simulations of insider threat scenarios. VecRep captures activity-based numerical data but may miss complex behavioral patterns crucial for detecting subtle threats. ImgRep, on the other hand, transforms user activity into image representations, enabling the analysis of intricate patterns within user behavior. Our findings demonstrate that ImgRep, especially when paired with DL models, significantly outperforms VecRep in terms of accuracy, F1 score, and AUC score, showing greater robustness in handling high-dimensional data. Furthermore, this study provides the first comparative analysis of VecRep and ImgRep for insider threat detection, offering practical insights for researchers and practitioners. These insights include implications for the choice of feature representation techniques, model selection, and system scalability. Results indicate that ImgRep holds substantial promise for improving insider threat detection systems, as it effectively addresses some limitations of VecRep in capturing complex patterns. This research contributes to the field by underscoring the potential of ImgRep in cybersecurity and by identifying avenues for future work, such as enhancing data resolution and conducting further statistical validation to confirm these findings. © The Author(s), under exclusive licence to Springer Nature Switzerland AG 2025.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Eshmawi, A.A.
AU  - Al-Nowami, A.
AU  - Mirza, M.
AU  - Abu-Raya, N.
AU  - Al-Thabit, R.
AU  - Shiaeles, S.
AU  - Choi, J.-G.
AU  - Ashraf, I.
TI  - Machine Learning-Based Network Monitoring for Cybersecurity Threat Detection
PY  - 2026
T2  - Journal of Network and Systems Management
VL  - 34
IS  - 1
C7  - 27
DO  - 10.1007/s10922-025-10001-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021799509&doi=10.1007%2Fs10922-025-10001-w&partnerID=40&md5=f62408bf24f054416f29581702f5ca11
AB  - Cybersecurity has become an important task to safeguard digital assets. Timely detection of cybersecurity threats and effective response are key tasks to deal with ever-complicating cyberattacks. Cyberattacks, particularly insider threats, have become a big threat to networks. Insider threat detection faces additional challenges, such as a lack of insider threat data to analyze properly. In addition, the inability of traditional approaches to distinguish between insider attacks and legitimate activity increases the likelihood that sensitive data and information can be misused by malicious insiders. To mitigate insider threats, this study utilizes multi-class machine learning models, including support vector machines (SVM), random forest (RF), K nearest neighbor (KNN), deep neural network (DNN), and Naive Bayes (NB) to detect user-centered insider threats at various granularity levels. The CERT r5.2 dataset was used in this study to create a user context model for training the models in various experiments. To establish which models are optimal for detecting each insider threat at various granularity levels, the results of several models are compared based on various criteria. Most machine learning models provided satisfactory results, except for NB and KNN, which are primarily affected by unbalanced data. Thereby, oversampling techniques were utilized to optimize the results. The proposed approach produced good results for KNN, RF, DNN, and SVM models with an accuracy of 99.9%, 95.5%, 94%, and 90.5%, respectively. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Pérez-Miguel, L.
AU  - Muñoz, A.M.
AU  - Larriva-Novo, X.
AU  - Álvarez-Campana, M.
AU  - Rivera, D.
TI  - Design and generation of a dataset for training insider threat prevention and detection models: The SPEDIA dataset
PY  - 2026
T2  - Computers and Security
VL  - 161
C7  - 104743
DO  - 10.1016/j.cose.2025.104743
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105023167250&doi=10.1016%2Fj.cose.2025.104743&partnerID=40&md5=971b587d64dfc8de8d63c0c2d2005626
AB  - The increasing complexity of insider threats poses a critical challenge for modern cybersecurity. Existing datasets used for training detection systems often lack realism, suffer from severe class imbalance, or are outdated. This paper presents a novel methodology for the generation of insider threat datasets through the integration of three data sources: (1) real user behavior collected during a controlled cyber exercise, (2) simulated user activity modeled on realistic work roles, and (3) synthetic data derived from the CERT Insider Threat Test dataset. The result is the SPEDIA dataset, designed to support the development and evaluation of machine learning models for detecting insider threats. The dataset includes detailed event-level logs of user activity, such as file manipulation, command execution, service usage, and network behavior, with annotations mapped to MITRE ATT&CK tactics and techniques. Unlike previous datasets, SPEDIA achieves a more balanced distribution of malicious and non-malicious events, enhancing its suitability for supervised learning. This work also provides a replicable framework for generating similar datasets, contributing to the advancement of insider threat detection research and the development of robust, real-world mitigation strategies. © 2025 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Mutshafa, L.
AU  - Moyo, B.
TI  - Towards Facial Expression Analysis for Enhanced Threat Detection in Surveillance
PY  - 2026
T2  - IFIP Advances in Information and Communication Technology
VL  - 777 IFIPAICT
SP  - 40
EP  - 61
DO  - 10.1007/978-3-032-13075-4_4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105024708353&doi=10.1007%2F978-3-032-13075-4_4&partnerID=40&md5=7bd1e0703fc49e5fcf9cac34b7ad249e
AB  - As cyber-physical systems become increasingly integrated into critical infrastructure such as energy distribution, transportation, healthcare, and public services, they are also becoming exposed to complex cyber threats. These threats range from traditional cyber intrusions to physical breaches and insider threats aimed at disrupting real-time operations. Enhancing situational awareness in such environments requires the development of proactive surveillance mechanisms that can detect early behavioural cues associated with potential threats. This paper presents a deep learning-based surveillance framework that incorporates facial expression analysis as a behavioral indicator to support the detection of anomalous. The framework takes into consideration that emotional states such as sustained anger, fear, and disgust can precede hostile actions. To operationalise these, we employed a convolutional neural network (CNN) and a recurrent neural network architecture trained in two benchmark datasets, the Amsterdam Dynamic Facial Expression Set (ADFES), and the Chinese Face Dataset with Dynamic Expressions to classify seven basic emotions (anger, disgust, fear, happiness, sadness, surprise, neutrality) from video streams. Based on a system throughput of 43.09 frames per second, a macro-averaged F1-score of 95%, and a per-frame inference time of 0.0232 s, preliminary results show that using facial expression analysis for real-time threat detection is feasible. These results underscore its potential to augment surveillance capabilities within cyberphysical systems, contributing to more proactive surveillance. © IFIP International Federation for Information Processing 2026.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Kavitha, T.
AU  - Poojitha, E.
AU  - Bhavani, M.
AU  - Sravanthi, K.
TI  - Privilege Escalation Attack Detection and Mitigation in Cloud Using Machine Learning
PY  - 2026
T2  - Lecture Notes in Electrical Engineering
VL  - 1466 LNEE
SP  - 793
EP  - 799
DO  - 10.1007/978-981-95-0269-1_90
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105023273809&doi=10.1007%2F978-981-95-0269-1_90&partnerID=40&md5=32077db7393838bd79acabff0966baf5
AB  - With the expansion of technology, the frequency and complexity of attacks are also increasing, and cybersecurity competition is also strong. While centralized cloud computing has changed for businesses, it has faced problems when using decentralized security systems [1]. Due to the large amount of inconsistent and weak data exchange between businesses and cloud service providers, this can lead to data leakage. Insider threats, especially from malicious people with significant access, pose a significant risk. To solve this problem, a machine learning-based application for detecting and classifying insider threats focuses on suspicious situations that indicate increased privilege [2].Integrated learning technology is used to improve prediction performance by combining multiple models. Although previous studies have examined the vulnerability and vulnerability in the network, most of them did not provide information about the attack and its distribution [3]. This study uses a data set from the CERT dataset and uses four machine learning algorithms: Random Forest, Adaboost, XGBoost, and LightGBM. Results show that LightGBM outperforms the other algorithms, demonstrating its efficacy in identifying and classifying insider attacks. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2026.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Xu, T.
AU  - Liu, C.
AU  - Wang, Z.
AU  - Wang, K.
TI  - Multi-agent Collaborative Framework with Few-Shot CoT for Threat Detection
PY  - 2026
T2  - Lecture Notes in Computer Science
VL  - 15922 LNAI
SP  - 384
EP  - 392
DO  - 10.1007/978-981-95-3058-8_36
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105022978164&doi=10.1007%2F978-981-95-3058-8_36&partnerID=40&md5=68e64d317bd02f34c2987bd135471b2b
AB  - To address the challenges of data scarcity, dynamic threats, and real-time detection in complex enterprise networks, this paper proposes a multi-agent collaborative framework integrated with Few-Shot Chain-of-Thought (CoT) reasoning for insider threat detection. The framework coordinates specialized agents—Manager, Behavior Analyst, Searcher, and Reflector—to execute end-to-end log analysis, anomaly detection, and rule refinement. By combining Few-Shot Learning with explicit CoT reasoning, the system generates interpretable detection rules from limited samples and dynamically optimizes them through multi-agent feedback. Evaluations on the CERT-IT r4.2 dataset demonstrate that our method outperforms traditional machine learning, deep learning, and zero-shot/few-shot LLM baselines, achieving 8–12% higher accuracy and 6–23% improvement in F1-score across diverse attack scenarios. Notably, the framework attains 92% rule interpretability and converges to stable rules within 1–2 iterations, reducing false positives/negatives by 30–45% compared to static approaches. These results highlight the effectiveness of integrating multi-agent collaboration and Few-Shot CoT reasoning for scalable, adaptive, and explainable insider threat detection. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2026.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Tian, T.
AU  - Zhang, C.
AU  - Jiang, B.
AU  - Feng, H.
AU  - Lu, Z.
TI  - Insider threat detection for specific threat scenarios
PY  - 2025
T2  - Cybersecurity
VL  - 8
IS  - 1
C7  - 17
DO  - 10.1186/s42400-024-00321-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000717153&doi=10.1186%2Fs42400-024-00321-w&partnerID=40&md5=83fc2ea2c5a81cd0034f3f4fe0e147b1
AB  - Insider threats pose significant challenges to network security due to their destructive and covert nature, often resulting in substantial losses for enterprises. Traditional methods mainly analyze user behavior patterns or convert behaviors into time sequences for further analysis. However, existing detection methods primarily focus on identifying abnormal users or behaviors, lacking the capability to pinpoint specific threats. Additionally, these methods struggle to accurately identify long-distance dependencies in behavior sequences, frequently increasing false positives. To address these issues, we introduce a scenario-oriented insider threat detection model. This model targets three specific threat scenarios-privilege abuse, identity theft, and data leakage-by analyzing user behavior patterns, extracting detailed behavioral characteristics, and constructing behavior sequences. Firstly, this paper serializes user behavior daily and vectorizes it using one-hot encoding. Then, it introduces contextual characteristic information and reconstructs the background of abnormal behavior through behavior vectorization, providing a comprehensive description of user behavior characteristics. This approach addresses the issue of behavior isolation, thereby improving the accuracy and robustness of anomaly detection. Subsequently, a time series analysis model based on a multi-head attention mechanism is employed to analyze long-distance dependencies in behavior sequences. The multi-head attention mechanism simultaneously attends to multiple positions in the behavior sequence, capturing potential correlations between behaviors and user behavior patterns. This mechanism can analyze local information and obtain long-distance dependencies, providing depth feature representation for anomaly detection. Ultimately, we achieve the goal of classifying abnormal behavior sequences. We conduct comprehensive tests on the CERT dataset, demonstrating that our method outperforms traditional deep learning approaches (LSTM, GNN, and GCN) in detecting abnormal sequences. Compared to the best results among the baseline methods, it shows an improvement in accuracy of approximately 2% for privilege abuse, 5% for identity theft, and 2% for data leakage. © The Author(s) 2025.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Kotb, H.M.
AU  - Gaber, T.
AU  - AlJanah, S.
AU  - Zawbaa, H.M.
AU  - AlKhathami, M.
TI  - A novel deep synthesis-based insider intrusion detection (DS-IID) model for malicious insiders and AI-generated threats
PY  - 2025
T2  - Scientific Reports
VL  - 15
IS  - 1
C7  - 207
DO  - 10.1038/s41598-024-84673-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213955510&doi=10.1038%2Fs41598-024-84673-w&partnerID=40&md5=2dab258ce707e66f2ed94a8be2886824
AB  - Insider threats pose a significant challenge to IT security, particularly with the rise of generative AI technologies, which can create convincing fake user profiles and mimic legitimate behaviors. Traditional intrusion detection systems struggle to differentiate between real and AI-generated activities, creating vulnerabilities in detecting malicious insiders. To address this challenge, this paper introduces a novel Deep Synthesis Insider Intrusion Detection (DS-IID) model. The model employs deep feature synthesis to automatically generate detailed user profiles from event data and utilizes binary deep learning for accurate threat identification. The DS-IID model addresses three key issues: it (i) detects malicious insiders using supervised learning, (ii) evaluates the effectiveness of generative algorithms in replicating real user profiles, and (iii) distinguishes between real and synthetic abnormal user profiles. To handle imbalanced data, the model uses on-the-fly weighted random sampling. Tested on the CERT insider threat dataset, the DS-IID achieved 97% accuracy and an AUC of 0.99. Moreover, the model demonstrates strong performance in differentiating real from AI-generated (synthetic) threats, achieving over 99% accuracy on optimally generated data. While primarily evaluated on synthetic datasets, the high accuracy of the DS-IID model suggests its potential as a valuable tool for real-world cybersecurity applications. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 7
ER  -

TY  - JOUR
AU  - Gayathri, B.
TI  - ITD-GMJN: Insider Thread Detection in Cloud Computing using Golf Optimized MICE based Jordan Neural Network
PY  - 2025
T2  - International Journal of Computer Network and Information Security
VL  - 17
IS  - 6
SP  - 116
EP  - 132
DO  - 10.5815/ijcnis.2025.06.08
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105024760473&doi=10.5815%2Fijcnis.2025.06.08&partnerID=40&md5=af68f7eeb0b0b2bc392ec916d224b808
AB  - Cloud computing refers to a high-level network architecture that allows consumers, authorized users, owners, and users to swiftly access and store their data. These days, the user's internal risks have a significant impact on this cloud. An intrusive party is established as a network member and presented as a user. Once they have access to the network, they will attempt to attack or steal confidential information while others are exchanging information or conversing. For the cloud network's external security, there are numerous options. But it's important to deal with internal or insider threats. Thus, in the proposed work, an advanced deep learning with optimized missing value imputation is developed to mitigate insider thread in the cloud system. Behavioral log files were taken in an organization which is split into sequential data and standalone data based on the login process. This data was not ready for the detection process due to improper data samples so it was pre-processed using Multivariate Imputation by Chained Equations (MICE) imputation. In this imputation process, the estimation parameter was optimally chosen using the Golf Optimization Algorithm (GOA). After the missing values were filled, the data proceeded to the extraction process. In this, the sequential data are proceeded for the domain extractor and the standalone data are proceeded for Long Short-Term Memory-Autoencoder (LS-AE). Both features are fused to create a single data which is further given to the detection process using Jordan Neural Network (JNN). The proposed method offers 96% accuracy, 92% recall, 91.6% specificity, 8.39% fall out and 8% Miss Rate. The results showed that the recommended JNN detection model has successfully detected insider threads in a cloud system. © 2025, Modern Education and Computer Science Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Murala, D.K.
AU  - Ahmad, S.
AU  - Ponnapalli, V.A.S.
AU  - Vuyyuru, V.A.
AU  - Hitimana, E.
TI  - ChainShieldML an intelligent decentralized security framework for next generation wireless sensor networks
PY  - 2025
T2  - Scientific Reports
VL  - 15
IS  - 1
C7  - 42960
DO  - 10.1038/s41598-025-27077-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105023584597&doi=10.1038%2Fs41598-025-27077-8&partnerID=40&md5=553bd74206303d6f80db3e8e6b8cae2f
AB  - Wireless sensor networks (WSNs) will be necessary for the next generation of Internet of Things (IoT) apps. They make it possible to use smart and long-lasting sensors and smart automation in healthcare, Industry 4.0, and critical infrastructure. But security is particularly hard since they have built-in flaws, not enough computer power, not enough energy, and a significant danger of insider threats. Standard encryption methods aren’t enough, and in situations where resources are restricted, heavier blockchain or machine learning solutions aren’t always possible. This study presents ChainShieldML, a lightweight hybrid security architecture that combines Blockchain (BC) and machine learning (ML) to provide decentralised, adaptive, and resource-efficient protection for wireless sensor networks (WSNs). The idea is based on a two-pronged defence strategy. The Blockchain Prevention Module’s permissionless blockchain architecture for base stations and cluster heads makes it possible to verify identities, maintain trust in a decentralised way, and keep node interactions unchangeable. Smart contracts made in solidity and connected to the Ethereum ecosystem make it possible to safely register nodes and keep an eye on what they do. The VBFT consensus algorithm makes it possible to quickly validate without using as much computing power as most proof of work methods. The machine learning detection module uses the lightweight gradient boosting method (LightGBM) to find and rank dangerous nodes in real time. LightGBM is the best machine learning classifier when looking at things like recall, F1-score, Matthews correlation coefficient, training cost, and inference latency. ChainShieldML dramatically improves the detection of insider attacks, builds trust, and protects data while using very little energy and having very little communication delay, as shown in tests. For Wireless sensor networks (WSNs) to keep working, all of these things are very important. ChainShieldML is a novel solution to keep IoT devices safe. It uses blockchain’s decentralised trust and ML’s adaptive intelligence to make a defence system for next-generation wireless sensor networks that can grow, is strong, and is ready for the future. © The Author(s) 2025.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Kundiya, K.
AU  - Haribhakta, Y.
TI  - A systematic review on insider threat detection using natural language processing
PY  - 2025
T2  - International Journal of Information Security
VL  - 24
IS  - 6
C7  - 227
DO  - 10.1007/s10207-025-01145-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020387620&doi=10.1007%2Fs10207-025-01145-6&partnerID=40&md5=3390746bfca74833f6c35d167f46d9a3
AB  - This systematic review, conducted under the PRISMA 2020 framework, investigates the application of Natural Language Processing (NLP) in insider threat detection, integrating Machine Learning (ML) and Deep Learning (DL) techniques, based on literature from 2019 to 2024. Addressing research questions (RQ1–RQ5) on techniques, datasets, performance metrics, challenges, and future directions, and evaluated via quality assessment criteria (QA1–QA4), the study synthesizes 66 high-quality studies from an initial 132 records across databases like IEEE, ScienceDirect, and Scopus. Findings reveal a surge in publications, peaking in 2023 and 2024, with Deep Learning (30.3%), hybrid NLP-ML/DL (27.3%), traditional ML (27.3%), and NLP-only (15.2%) approaches dominating, leveraging datasets like CERT and Enron to achieve accuracies up to 99.2% and F1-scores above 94%. However, reliance on synthetic data limits real-world applicability. Challenges include model complexity, explainability issues, binary classification biases, and dataset gaps, while future opportunities lie in lightweight, interpretable models, hybrid pipelines, anonymized datasets, and digital twins. The review highlights NLP’s transformative potential in enhancing cybersecurity against insider risks, offering a novel taxonomy and critique. Interdisciplinary efforts are recommended to align academic innovations with practical deployment, addressing gaps in real-time analysis and dataset diversity to strengthen organizational security frameworks. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2025.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Ali, B.
AU  - Chen, G.
TI  - Next-generation AI for advanced threat detection and security enhancement in DNS over HTTPS
PY  - 2025
T2  - Journal of Network and Computer Applications
VL  - 244
C7  - 104326
DO  - 10.1016/j.jnca.2025.104326
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105019223438&doi=10.1016%2Fj.jnca.2025.104326&partnerID=40&md5=12d8dce0d3c5033d40cdfe3816f9befa
AB  - The widespread adoption of DNS over HTTPS(DoH) has inaugurated a new paradigm of network privacy through the encryption of DNS queries; paradoxically, this very mechanism has been weaponized by malicious actors to orchestrate convert cyberattacks ranging from polymorphic malware delivery and data exfiltration to command-and-control (C2) operations. Classic signature-based solutions that rely on static security policies and packet-depth inspection are rendered useless in the face of encrypted DoH traffic, and today’s AI-driven defense solutions typically fail to achieve adversarial robustness, explainability, and real-time scalability. Bridging these gaps, this paper proposes an AI framework that integrates the best practices in machine learning together with secure execution environments to offer resilience, transparency, and low-latency DoH threat detection. Specifically, Capsule Networks (CapsNets) are used to learn hierarchical traffic flow patterns, Graph Transformers to uncover temporal anomalies, and Contrastive Self-Supervised Learning (CSSL) to leverage massive unlabeled datasets. Adversarial robustness is reinforced through perturbation-aware training and mutation-driven fuzzing simulations, while interpretability is enhanced via SHAP and LIME, rendering AI decision-making processes more intelligible to analysts. A distributed Apache Flink/Kafka pipeline enables real-time processing of DoH streams at scale, reducing detection latency by 50% compared to batch-oriented systems. Furthermore, Trusted Execution Environments(TEEs) safeguard model inference against tempering, mitigating insider threats and runtime exploitation. Empirical evaluation on the doh_real_world_2022 dataset demonstrates 99.1% detection accuracy with CapsNets, 98.8% with Graph Transformers, and an 80% improvement in adversarial resilience. These developments collectively propel the discipline of encrypted traffic analysis and establish a benchmark for safeguarding cybersecurity protocols such as QUIC and HTTP/3 that are gaining traction. The findings validate the feasibility of AI-driven, privacy-augmented security systems during an era of escalating cyber-attacks and demands algorithmic transparency. © 2025 Elsevier Ltd. All rights are reserved, including those for text and data mining, AI training, and similar technologies.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Lilhore, U.K.
AU  - Simaiya, S.
AU  - Alroobaea, R.
AU  - Baqasah, A.M.
AU  - Alsafyani, M.
AU  - Alhazmi, A.
AU  - Khan, M.M.
TI  - SmartTrust: a hybrid deep learning framework for real-time threat detection in cloud environments using Zero-Trust Architecture
PY  - 2025
T2  - Journal of Cloud Computing
VL  - 14
IS  - 1
C7  - 35
DO  - 10.1186/s13677-025-00764-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009543756&doi=10.1186%2Fs13677-025-00764-7&partnerID=40&md5=c5d44c8952833e86f83d494b4b4fcfe3
AB  - The rapid growth of cloud computing has brought scalability and flexibility to modern organizations, but it has also introduced a new wave of complex and evolving security threats. Traditional security mechanisms, such as static rule-based systems and Multi-Factor Authentication (MFA), often fall short of identifying advanced attacks like insider threats, privilege escalation, and data breaches. Addressing this gap, we propose SmartTrust, a hybrid deep learning framework designed for real-time threat detection in cloud environments built on Zero-Trust Architecture (ZTA) principles. SmartTrust integrates CNN, LSTM, and Transformer models to analyze spatial and temporal patterns in network traffic and user behaviours. Unlike conventional models, it leverages Reinforcement Learning to enable adaptive decision-making, allowing it to adjust responses based on real-time contextual signals dynamically. To ensure transparency and tamper-proof event tracking, the framework also incorporates blockchain-based logging that is aligned with ZTA compliance. We evaluated SmartTrust on two benchmark datasets, CIC-IoT 2023 and UNSW-NB15, which simulate realistic cloud-based attack scenarios. The model achieved detection rates of 99.19% for insider threats, 98.23% for privilege escalation, and 99.27% for data breaches while reducing false positives by over 40% compared to existing approaches. Though the model’s complexity introduces higher computational demands, its performance demonstrates that SmartTrust offers a robust, intelligent, and adaptive alternative to traditional cloud security solutions capable of evolving with today’s rapidly changing threat landscape. © The Author(s) 2025.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Ahmadi, S.
TI  - Autonomous identity-based threat segmentation for zero trust architecture
PY  - 2025
T2  - Cyber Security and Applications
VL  - 3
C7  - 100106
DO  - 10.1016/j.csa.2025.100106
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009474901&doi=10.1016%2Fj.csa.2025.100106&partnerID=40&md5=9057543f5ba5fb97c8ca03af07a95a32
AB  - Zero Trust Architecture (ZTA) fundamentally redefine network security by adopting a "trust nothing, verify everything" approach requiring identity verification for all access. However, conventional access controls are static and fail to consider evolving user activities and contextual threats, leading to internal risks and breaches. This research proposes an AI-driven, autonomous, identity-based threat segmentation framework for ZTA. Behavioral analytics provide real-time risk scores by analyzing login patterns, access behavior, and resource utilization, while Machine Learning models dynamically adjust permissions based on geolocation, device type, and time of access. Automated threat segmentation enables the real-time isolation of compromised identities, minimizing breach progression. Practical use cases, such as insider threat mitigation across distributed offices, are discussed. Privacy concerns, false positives, and scalability challenges are addressed. Comparative analysis demonstrates the system's precision and scalability, enhancing dynamic access governance while maintaining user productivity. © 2025
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Ye, X.
AU  - Luo, F.
AU  - Cui, H.
AU  - Wang, J.
AU  - Xiong, X.
AU  - Zhang, W.
AU  - Yu, J.
AU  - Zhao, W.
TI  - Research on insider threat detection based on personalized federated learning and behavior log analysis
PY  - 2025
T2  - Scientific Reports
VL  - 15
IS  - 1
C7  - 19214
DO  - 10.1038/s41598-025-04029-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006913949&doi=10.1038%2Fs41598-025-04029-w&partnerID=40&md5=3b9ad2bd7fd7c8876ffb2cd755c753a5
AB  - As the cybersecurity landscape becomes increasingly challenging, insider threat detection has emerged as a critical research area. Traditional methods for detecting insider threats, such as Random Forest and Isolation Forest, suffer from high computational resource consumption, poor feature representation, and sensitivity to noise. While machine learning methods offer certain advantages, they still face challenges in complex data scenarios. This study focuses on the application of Federated Learning in insider threat detection. As a distributed machine learning framework, FL enables collaborative model building and analysis while safeguarding data privacy. It encompasses various types, including horizontal, vertical, and federated transfer learning. However, its application in insider threat detection remains limited. This research proposes an innovative solution to address the shortcomings of existing Federated Learning-based detection methods (e.g., FedAT), such as insufficient feature extraction and high resource consumption. Drawing on the DeepInsight concept, we convert different data types into image formats for use with Convolutional Neural Networks (CNNs) to train insider threat detection models. This approach leverages the advantages of FL’s privacy protection and multi-source data integration while harnessing the powerful feature learning capabilities of CNNs. It improves key metrics such as accuracy and recall in insider threat detection. The proposed method offers a more efficient and precise approach to detecting insider threats in cybersecurity, advancing the development and practical application of relevant technologies in this field with significant theoretical and practical implications. © The Author(s) 2025.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CHAP
AU  - Mathew, B.B.
AU  - Vajha, V.K.
AU  - Jakhmola-Mani, R.J.
TI  - Data Science for Threat Detection and Analysis
PY  - 2025
SP  - 59
EP  - 86
DO  - 10.1515/9783111712895-003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105023462588&doi=10.1515%2F9783111712895-003&partnerID=40&md5=83e29e397c1b8fc43fbb52f99e003ccf
AB  - This chapter explores the applications of data science techniques that enhance cybersecurity. It provides a theoretical analysis based on existing literature, focusing on how tools like machine learning, deep learning, and natural language processing help contribute to threat detection, analysis, and prevention. By examining user behavior and device interactions, the chapter highlights important machine learning and deep learning techniques that are used to identify these interactions, helping us to classify them as benign behavior or malicious behavior. Typically, these techniques are used in identifying DDoS attacks, malware, and insider threats. This chapter also emphasizes the need for real-time threat detection systems and integrated systems with highly accurate models for predictions. Additionally, we delve into challenges that arise when trying to implement data science techniques in this field while also explaining what limitations the model themselves faces. Furthermore, we learn about future trends and how integrating and developing better techniques and technologies can help strengthen our defenses while allowing for real time response. On doing so we are able to shift from reactive measures to proactive measures. © 2026 Walter de Gruyter GmbH, Berlin/Boston, Genthiner Straße 13, 10785 Berlin.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Aslam, M.M.
AU  - Tufail, A.
AU  - Gul, H.
AU  - Irshad, M.N.
AU  - Namoun, A.
TI  - Artificial intelligence for secure and sustainable industrial control systems - A Survey of challenges and solutions
PY  - 2025
T2  - Artificial Intelligence Review
VL  - 58
IS  - 11
C7  - 349
DO  - 10.1007/s10462-025-11320-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013840054&doi=10.1007%2Fs10462-025-11320-9&partnerID=40&md5=026cf6487d3340e243bba37ebe6d81a5
AB  - In modern industrial environments, the security and sustainability of Industrial Control Systems (ICS) have become crucial. This comprehensive review examines the transformative potential of Artificial Intelligence (AI) in ICS, focusing on technologies like Machine Learning (ML), Deep Learning (DL), Large Language Models (LLMs), and cloud computing. Moreover, this research explores integrating existing and proposed sustainable practices within the ICS framework, with a particular emphasis on energy efficiency and carbon footprint reduction, to enhance the overall sustainability of ICS. This review employed a systematic approach to select relevant articles from multiple reputable databases, such as Scopus, IEEE Explore, Science Direct, ACM digital library, Web of Science, and IET digital library, including 250 articles that provide valuable insights into the intersection of AI, security, and sustainability in ICS. This review examines vulnerabilities in ICS, such as data breaches, insider threats, and malware, emphasizing the need for effective anomaly detection. It highlights how AI technologies like anomaly detection and predictive analytics can enhance threat detection and response in ICS by improving accuracy and efficiency. The review offers insights to researchers and professionals on the future of secure, sustainable ICS, supporting a resilient industrial landscape that meets cybersecurity, compliance, and sustainability goals. © The Author(s) 2025.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Ofori, H.K.
AU  - Bell-Dzide, K.
AU  - Brown-Acquaye, W.L.
AU  - Lempogo, F.
AU  - Frimpong, S.O.
AU  - Agbehadji, I.E.
AU  - Millham, R.C.
TI  - Application of Machine Learning and Deep Learning Techniques for Enhanced Insider Threat Detection in Cybersecurity: Bibliometric Review
PY  - 2025
T2  - Symmetry
VL  - 17
IS  - 10
C7  - 1704
DO  - 10.3390/sym17101704
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020286674&doi=10.3390%2Fsym17101704&partnerID=40&md5=795ade096f031c94e6012aef982e905e
AB  - Insider threats remain a persistent challenge in cybersecurity, as malicious or negligent insiders exploit legitimate access to compromise systems and data. This study presents a bibliometric review of 325 peer-reviewed publications from 2015 to 2025 to examine how machine learning (ML) and deep learning (DL) techniques for insider threat detection have evolved. The analysis investigates temporal publication trends, influential authors, international collaboration networks, thematic shifts, and algorithmic preferences. Results show a steady rise in research output and a transition from traditional ML models, such as decision trees and random forests, toward advanced DL methods, including long short-term memory (LSTM) networks, autoencoders, and hybrid ML–DL frameworks. Co-authorship mapping highlights China, India, and the United States as leading contributors, while keyword analysis underscores the increasing focus on behavior-based and eXplainable AI models. Symmetry emerges as a central theme, reflected in balancing detection accuracy with computational efficiency, and minimizing false positives while avoiding false negatives. The study recommends adaptive hybrid architectures, particularly Bidirectional LSTM–Variational Auto-Encoder (BiLSTM-VAE) models with eXplainable AI, as promising solutions that restore symmetry between detection accuracy and transparency, strengthening both technical performance and organizational trust. © 2025 by the authors.
M3  - Review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Nazir, I.
AU  - Mushtaq, N.
AU  - Amin, W.
TI  - Smart Grid Systems: Addressing Privacy Threats, Security Vulnerabilities, and Demand–Supply Balance (A Review)
PY  - 2025
T2  - Energies
VL  - 18
IS  - 19
C7  - 5076
DO  - 10.3390/en18195076
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105019259264&doi=10.3390%2Fen18195076&partnerID=40&md5=c422c5da99a7e5ec4894a872bba383d2
AB  - The smart grid (SG) plays a seminal role in the modern energy landscape by integrating digital technologies, the Internet of Things (IoT), and Advanced Metering Infrastructure (AMI) to enable bidirectional energy flow, real-time monitoring, and enhanced operational efficiency. However, these advancements also introduce critical challenges related to data privacy, cybersecurity, and operational balance. This review critically evaluates SG systems, beginning with an analysis of data privacy vulnerabilities, including Man-in-the-Middle (MITM), Denial-of-Service (DoS), and replay attacks, as well as insider threats, exemplified by incidents such as the 2023 Hydro-Québec cyberattack and the 2024 blackout in Spain. The review further details the SG architecture and its key components, including smart meters (SMs), control centers (CCs), aggregators, smart appliances, and renewable energy sources (RESs), while emphasizing essential security requirements such as confidentiality, integrity, availability, secure storage, and scalability. Various privacy preservation techniques are discussed, including cryptographic tools like Homomorphic Encryption, Zero-Knowledge Proofs, and Secure Multiparty Computation, anonymization and aggregation methods such as differential privacy and k-Anonymity, as well as blockchain-based approaches and machine learning solutions. Additionally, the review examines pricing models and their resolution strategies, Demand–Supply Balance Programs (DSBPs) utilizing optimization, game-theoretic, and AI-based approaches, and energy storage systems (ESSs) encompassing lead–acid, lithium-ion, sodium-sulfur, and sodium-ion batteries, highlighting their respective advantages and limitations. By synthesizing these findings, the review identifies existing research gaps and provides guidance for future studies aimed at advancing secure, efficient, and sustainable smart grid implementations. © 2025 by the authors.
M3  - Review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Ferraro, A.
AU  - Orlando, G.M.
AU  - Russo, D.
TI  - Generative Agent-Based Modeling with Large Language Models for insider threat detection
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 157
C7  - 111343
DO  - 10.1016/j.engappai.2025.111343
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008555934&doi=10.1016%2Fj.engappai.2025.111343&partnerID=40&md5=9094401a04a7e0546b9a20b9f0bf6846
AB  - Insider threats pose a critical challenge in cybersecurity, as individuals within organizations misuse legitimate access to compromise sensitive systems and data. Traditional detection methods often struggle with the complexity of such threats, while Deep Learning (DL) approaches face issues like overfitting and lack of interpretability. To address these limitations, we propose a Generative Agent-Based Modeling (GABM) framework that integrates Large Language Models (LLMs) with a hierarchical multi-agent system. Our framework employs Specialized Agents to process categorized log files and generate detailed reports, which are synthesized by a Supervisor Agent for final activity classification. We validated this approach on both network-centric (PicoDomain) and behavior-rich (CERT r5.2) datasets, demonstrating its ability to handle diverse logs, model complex threats, and generalize across insider risk scenarios. The framework outperformed existing baselines, prioritizing high recall to minimize false negatives—crucial in cybersecurity contexts. While precision was comparatively lower, this trade-off supports early threat detection. An ablation study highlighted the importance of the Supervisor Agent, whose removal led to a significant drop in performance and increased false positives. These results demonstrate the potential of LLM-powered hierarchical multi-agent frameworks for scalable, interpretable, and reliable insider threat detection. Our contributions include the integration of GABM and LLMs, a hierarchical system for log analysis, and the use of Chain-of-Thought reasoning for enhanced interpretability. © 2025 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Patel, T.
AU  - Iyer, S.S.
TI  - SiaDNN: Siamese deep neural network for anomaly detection in user behavior
PY  - 2025
T2  - Knowledge-Based Systems
VL  - 324
C7  - 113769
DO  - 10.1016/j.knosys.2025.113769
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007555764&doi=10.1016%2Fj.knosys.2025.113769&partnerID=40&md5=70970c1a30bca545d329e6159dce23d8
AB  - Recently, insider threat detection become a very challenging task as the identification of anomalies from log data is a complex process. Insider threats are unusual activities raised by authorized users. When compared to the external network attack, the insider threats are much lower and the detection of these malicious behavior is a difficult process. The conventional schemes focus on rule-based approaches but are not flexible and robust. User behavior modelling is essential for this anomaly identification. Thus, this paper proposed an effective approach, the Siamese Deep Neural Network (SiaDNN) for detecting anomalies based on user behavior. Here, the SiaNN is designed by the incorporation of Siamese Convolution Neural Network (SCNN) and Deep Neural Network (DNN). At first, the log file is fed to the user behavior features extraction module, where the administrator, authentication, and comments are extracted. Then, the extracted features are encoded and considered for the evaluation of user behavior patterns. Here, the Frequent Pattern Growth (FP growth algorithm) is used for analyzing user behavior patterns. Subsequently, the proposed SiaDNN is used for conducting Anomaly Detection (AD) based on user behavior. The evaluation results show that the SiaDNN accomplished accuracy, False Positive Rate (FPR), and True Positive Rate (TPR) as 91.136 %, 7.300 %, and 90.703 %. The high-performance results achieved by the devised model indicate that the model is highly robust in identifying anomalous requests correctly based on user behavior. The high accuracy rate indicates that the devised model maintains system integrity and trustworthiness in real-time web services. © 2025 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Medvedev, V.
AU  - Budzys, A.
AU  - Kurasova, O.
TI  - A decision-making framework for user authentication using keystroke dynamics
PY  - 2025
T2  - Computers and Security
VL  - 155
C7  - 104494
DO  - 10.1016/j.cose.2025.104494
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003383719&doi=10.1016%2Fj.cose.2025.104494&partnerID=40&md5=fdc4434f77868ee21e56527242308395
AB  - Increasingly sophisticated cyber attacks threaten critical infrastructures, requiring more trusted user authentication mechanisms. In this work, we propose a deep learning-based user authentication framework that combines keystroke dynamics with Siamese neural networks to differentiate legitimate users from impostors. A key challenge in this area is the variability in password lengths, which leads to different feature sizes and complicates model training. Our approach uses interpolation-based data fusion strategies to standardize the number of keystroke features, ensuring consistency across different datasets and password lengths. Through experiments on the fused CMU and KeyRecs datasets, we have evaluated the effectiveness of the proposed decision-making framework with adaptive threshold strategies. The threshold strategy determines how the final decision boundary is set with respect to the user's baseline typing behavior. We empirically evaluated the framework on fused data, achieving an equal error rate as low as 0.11–0.12, indicating strong efficacy in detecting insider threats. We show how the obtained Siamese neural network with triplet loss function can be used to distinguish genuine users from impostors even under different input conditions, contributing to more robust and scalable intrusion detection systems. © 2025 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Liu, H.
AU  - Liu, M.
AU  - Han, L.
AU  - Sun, H.
AU  - Fu, C.
TI  - Ripple2Detect: A semantic similarity learning based framework for insider threat multi-step evidence detection
PY  - 2025
T2  - Computers and Security
VL  - 154
C7  - 104387
DO  - 10.1016/j.cose.2025.104387
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000106916&doi=10.1016%2Fj.cose.2025.104387&partnerID=40&md5=11204ee718346184cc5899d59944eeb7
AB  - Insider threat attacks occur when individuals misuse their access to an organization's systems, data, or networks. These attacks, including Advanced Persistent Threats (APT), Pivoting, and Lateral Movement, often involve prolonged timelines and similar sensitive actions. Given the complexity of these attacks, current internal threat detection methods have their shortcomings. Firstly, internal threat attacks typically involve multiple sequences of malicious operations, making it challenging to capture the entire attack process using a single model. Secondly, current research often overlooks the interconnections between user behavior sequences, failing to differentiate between malicious intentions, actions, and outcomes. This neglect may lead to forensic inaccuracies and the misattribution of benign activities as attacks, potentially causing erroneous responses. Furthermore, existing internal threat detection methods fail to mine relevant attack evidence from known sensitive behaviors to thoroughly analyze the attack mechanisms. To address these challenges, we propose Ripple2Detect, a multi-step evidence detection framework for insider threat detection. First, Ripple2Detect builds an evidence sequence library by decomposing known attack behaviors into sequences and constructing a knowledge graph to measure their correlations. Next, we train a semantic similarity model based on the BERT architecture, tailored for operation sequences, to improve the detection of attack evidence. To overcome data imbalance, we introduce a contrastive learning loss to better distinguish between attack and non-attack behaviors. Finally, a preference propagation mechanism is used to predict attack behaviors within the knowledge graph. We conduct experiments on Cert-r4.2 and Cert-r5.2 benchmark datasets, comparing our model with state-of-the-art approaches. The results suggest that our model can identify malicious sequences with 0.96 F1 score and achieve an attack identification F1 score of up to 0.99. The source code can be obtained from https://github.com/L3LeTrigger-F/Ripple2Detect_code © 2025
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Pennada, P.S.S.
AU  - Nayak, S.K.
AU  - Vamsikrishna, M.V.
TI  - Hybrid Machine Learning for Enhanced Insider Threat Detection Using Generative Latent Features
PY  - 2025
T2  - International Journal of Engineering Trends and Technology
VL  - 73
IS  - 6
SP  - 102
EP  - 113
DO  - 10.14445/22315381/IJETT-V73I6P110
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009844872&doi=10.14445%2F22315381%2FIJETT-V73I6P110&partnerID=40&md5=d83f8486f62cc52845e1acb09a9599d6
AB  - Insider threats are a constant and evolving security threat to organizations, with vast financial and reputational damage. Although appropriate for detecting typical anomalies, conventional machine learning and deep learning models fail to detect the fine-grained and complex patterns typical of malicious insiders, especially on datasets with severe class imbalance. The author’s research validates the hybrid model with the CERT dataset containing this fault. For comparison, existing generative AI techniques like Deep Autoencoders (DAEs) and Variational Autoencoders (VAEs) provide stronger anomaly detection based on latent feature extraction. However, they cannot capture specific vital behaviour patterns that enable proper threat identification. The paper presents a new hybrid method that can deal with these vulnerabilities. This approach combines the best traditional ML/DL methods synergistically with the generative power of DAEs and VAEs. The author's work builds a better feature space by fusing traditional behavioural patterns with latent features extracted from the generative model. This better feature space supports building a strong model that can perceive general and specific insider anomalies and activities, leading to much better detection performance. Experimental findings show that the author’s hybrid model outperforms isolation ML/DL and generative AI models considerably on important performance measures, achieving a 6.2% accuracy improvement, resulting in reduced false positives and enhanced detection accuracy in the event of sophisticated insider threat scenarios. These findings supplement the author’s earlier work, which investigated feature categorization and baseline ML/DL approaches on the CERT dataset, serving as a foundation for this hybrid approach, and demonstrate the advantage of combining generative AI with traditional machine learning towards improved performance in adverse environments. © 2025 Seventh Sense Research Group®.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Gayathri, R.G.
AU  - Sajjanhar, A.
AU  - Xiang, Y.
TI  - Adversarial Training for Mitigating Insider-Driven XAI-Based Backdoor Attacks
PY  - 2025
T2  - Future Internet
VL  - 17
IS  - 5
C7  - 209
DO  - 10.3390/fi17050209
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006438155&doi=10.3390%2Ffi17050209&partnerID=40&md5=bd3aa1ffe399dba99e924a8953675807
AB  - The study investigates how adversarial training techniques can be used to introduce backdoors into deep learning models by an insider with privileged access to training data. The research demonstrates an insider-driven poison-label backdoor approach in which triggers are introduced into the training dataset. These triggers misclassify poisoned inputs while maintaining standard classification on clean data. An adversary can improve the stealth and effectiveness of such attacks by utilizing XAI techniques, which makes the detection of such attacks more difficult. The study uses publicly available datasets to evaluate the robustness of the deep learning models in this situation. Our experiments show that adversarial training considerably reduces backdoor attacks. These results are verified using various performance metrics, revealing model vulnerabilities and possible countermeasures. The findings demonstrate the importance of robust training techniques and effective adversarial defenses to improve the security of deep learning models against insider-driven backdoor attacks. © 2025 by the authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Thite, M.
AU  - Iyer, R.
TI  - Addressing the gap in information security: an HR-centric and AI-driven framework for mitigating insider threats
PY  - 2025
T2  - Personnel Review
VL  - 54
IS  - 3
SP  - 935
EP  - 951
DO  - 10.1108/PR-04-2023-0358
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001841637&doi=10.1108%2FPR-04-2023-0358&partnerID=40&md5=c6801f57188f0e5ea3494735cfd9d140
AB  - Purpose: Despite ongoing reports of insider-driven leakage of confidential data, both academic scholars and practitioners tend to focus on external threats and favour information technology (IT)-centric solutions to secure and strengthen their information security ecosystem. Unfortunately, they pay little attention to human resource management (HRM) solutions. This paper aims to address this gap and proposes an actionable human resource (HR)-centric and artificial intelligence (AI)-driven framework. Design/methodology/approach: The paper highlights the dangers posed by insider threats and presents key findings from a Leximancer-based analysis of a rapid literature review on the role, nature and contribution of HRM for information security, especially in addressing insider threats. The study also discusses the limitations of these solutions and proposes an HR-in-the-loop model, driven by AI and machine learning to mitigate these limitations. Findings: The paper argues that AI promises to offer many HRM-centric opportunities to fortify the information security architecture if used strategically and intelligently. The HR-in-the-loop model can ensure that the human factors are considered when designing information security solutions. By combining AI and machine learning with human expertise, this model can provide an effective and comprehensive approach to addressing insider threats. Originality/value: The paper fills the research gap on the critical role of HR in securing and strengthening information security. It makes further contribution in identifying the limitations of HRM solutions in info security and how AI and machine learning can be leveraged to address these limitations to some extent. © 2024, Emerald Publishing Limited.
M3  - Review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Kamatchi, K.
AU  - Uma, E.
TI  - Insights into user behavioral-based insider threat detection: systematic review
PY  - 2025
T2  - International Journal of Information Security
VL  - 24
IS  - 2
C7  - 88
DO  - 10.1007/s10207-025-01002-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000740708&doi=10.1007%2Fs10207-025-01002-6&partnerID=40&md5=4383430798ea08ec20a48e47bc04bb13
AB  - The increasing complexity of organizational systems creates new opportunities for insider threats to exploit vulnerabilities and cause significant damage. Insider threat detection (ITD) has become a critical first line of defense for organizations to prevent security breaches. Researchers have developed numerous methodologies targeting specific types of network activities, such as file transfers, login attempts, and network traffic patterns to address these threats. User behavioral-based insider threat detection (UBITD) is a critical research and development direction in cybersecurity. Despite the abundance of research on ITD methods, there is a notable scarcity of systematic reviews focusing on the latest advancements and the data used to train them. Although numerous review papers have explored various ITD approaches, most adopt a non-systematic approach, merely comparing existing techniques without providing a comprehensive analytical synthesis of methodologies and performance outcomes. Consequently, these reviews fall short of delivering a holistic understanding of the current ITD landscape, as much of the existing literature emphasizes signature-based ITD with a focus on machine learning and deep learning models, while UBITD remains minimally explored. This paper presents an in-depth analysis of UBITD by systematically reviewing 101 of the most influential research papers published on the topic. Our analysis rigorously examines the technical advancements, data preprocessing techniques, detection approaches, evaluation metrics, researcher collaborations, datasets, and future trends in this field. The findings reveal unsolved research challenges and uncharted research areas within each of these perspectives. By outlining several high-impact future research endeavors, this study aims to strengthen ITD role in cybersecurity, contributing to the development of more robust and proactive defenses against insider threats. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2025.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Kim, C.M.
AU  - Kim, T.R.
AU  - Yim, M.-S.
TI  - Trustworthiness evaluation of workers in critical facilities using electroencephalography-based acquaintance test
PY  - 2025
T2  - Nuclear Engineering and Technology
VL  - 57
IS  - 3
C7  - 103257
DO  - 10.1016/j.net.2024.10.019
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207007563&doi=10.1016%2Fj.net.2024.10.019&partnerID=40&md5=e04a17528e18985d01eaed6a68fdee4d
AB  - This study emphasized the critical importance of prioritizing workers' trustworthiness in safeguarding critical facilities from the potential harm caused by insiders' betrayal. By noting the limitations of existing physical protection systems in critical facilities, this study showed that effectively characterizing and detecting malicious insider activity can be possible by observing immediate brain physiological reactions to specific stimuli. Based on the finding, a novel approach using electroencephalography (EEG)-based acquaintance tests was introduced to objectively assess ’a level of suspicion between colleagues by measuring their brain responses when he/she is exposed to familiar and unfamiliar stimuli. If a person claims falsely about one's acquaintance, the model assumes he/she has malicious or suspicious intent by violating the reporting obligation. The experiment was designed with a relatively short time of monitoring of less than 2 min and with a simple EEG headband device called MUSE. The experiment is to analyze whether the model could provide reliable prediction of disguised acquaintance avoiding complex preparation process. Averaged N170 peak analysis indicated that MUSE provided adequate signal characteristics to classify acquaintance. Also, a machine learning-based subject-wise classification model showed adequate capability to differentiate the EEG signals of acquaintances from unknowns. The final prediction combined multiple single-trial classification results, correctly detected the participant's acquaintance about 94.1 % of the cases, with similar performance when strangers were presented. The results indicated the possibility of using biosignal to enhance security culture and mitigate insider threats in critical facilities, by providing an indication of behavior that disregards security policies and procedures. © 2024 Korean Nuclear Society
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Qawasmeh, S.A.-D.
AU  - Alqahtani, A.A.S.
TI  - Beyond Firewall: Leveraging Machine Learning for Real-Time Insider Threats Identification and User Profiling
PY  - 2025
T2  - Future Internet
VL  - 17
IS  - 2
C7  - 93
DO  - 10.3390/fi17020093
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218638480&doi=10.3390%2Ffi17020093&partnerID=40&md5=63822cc95226b81ff37ad38558f6ba41
AB  - Insider threats pose a significant challenge to organizational cybersecurity, often leading to catastrophic financial and reputational damages. Traditional tools such as firewalls and antivirus systems lack the sophistication needed to detect and mitigate these threats in real time. This paper introduces a machine learning-based system that integrates real-time anomaly detection with dynamic user profiling, enabling the classification of employees into categories of low, medium, and high risk. The system was validated using a synthetic dataset, achieving exceptional accuracy across machine learning models, with XGBoost emerging as the most effective. © 2025 by the authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Ahmad, W.
TI  - Unveiling Anomalies: Leveraging Machine Learning for Internal User Behaviour Analysis – Top 10 Use Cases
PY  - 2025
T2  - International Journal of Innovative Technology and Interdisciplinary Sciences
VL  - 8
IS  - 1
SP  - 272
EP  - 293
DO  - 10.15157/IJITIS.2025.8.1.272-293
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011512198&doi=10.15157%2FIJITIS.2025.8.1.272-293&partnerID=40&md5=d641073cdd35eef0db56c6059d3f90ca
AB  - Insider threats pose a significant risk to organizations, as traditional Security Information and Event Management (SIEM) systems struggle to detect subtle, evolving anomalies in user behaviour. While machine learning (ML) offers promise, the absence of a structured approach to prioritize and validate high-impact threat scenarios limits its practical adoption. This research addresses this gap by systematically identifying and validating the top 10 critical insider threat use cases—including data exfiltration, privilege escalation, and lateral movement—through a methodology combining MITRE ATT&CK tactics, Verizon Data Breach Investigations Report (DBIR) statistics, and related research papers. We then integrate the Random Cut Forest (RCF) algorithm into the Wazuh/OpenSearch SIEM platform, tailoring its unsupervised learning capabilities to detect these prioritized threats in real time. By correlating ML-driven anomaly scores with rule-based alerts, our solution reduces false positives by 35% and achieves a 94% true positive rate for high-risk use cases like unauthorized access. Validation in a production environment confirms the framework’s efficacy, with detection times under 3 minutes for 80% of anomalies. Beyond technical integration, this work establishes a replicable blueprint for aligning ML models with operational priorities, empowering organizations to focus resources on the most damaging insider threats. © 2024 Authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Feng, W.
AU  - Cao, Y.
AU  - Chen, Y.
AU  - Wang, Y.
AU  - Hu, N.
AU  - Jia, Y.
AU  - Gu, Z.
TI  - Multi-Granularity User Anomalous Behavior Detection
PY  - 2025
T2  - Applied Sciences (Switzerland)
VL  - 15
IS  - 1
C7  - 128
DO  - 10.3390/app15010128
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214465322&doi=10.3390%2Fapp15010128&partnerID=40&md5=b1268b172c40f71ce565e60005a4b7da
AB  - Insider threats pose significant risks to organizational security, often going undetected due to their familiarity with the systems. Detection of insider threats faces challenges of imbalanced data distributions and difficulties in fine-grained detection. Specifically, anomalous users and anomalous behaviors take up a very small fraction of all insider behavior data, making precise detection of anomalous users challenging. Moreover, not all behaviors of anomalous users are anomalous, so it is difficult to detect their behaviors by standardizing with single rules or models. To address these challenges, this paper presents a novel approach for insider threat detection, leveraging machine learning techniques to conduct multi-granularity anomaly detection. We introduce the Multi-Granularity User Anomalous Behavior Detection (MG-UABD) system, which combines coarse-grained and fine-grained anomaly detection to improve the accuracy and effectiveness of detecting anomalous behaviors. The coarse-grained module screens all of the user activities to identify potential anomalies, while the fine-grained module focuses on specific anomalous users to refine the detection process. Besides, MG-UABD employs a combination of oversampling and undersampling techniques to address the imbalance in the datasets, ensuring robust model performance. Through extensive experimentation on the commonly used dataset CERT R4.2, we demonstrate that the MG-UABD system achieves superior detection rate and precision. Compared to the suboptimal model, the accuracy has increased by 3.1% and the detection rate has increased by 4.1%. Our findings suggest that a multi-granularity approach for anomaly detection, combined with tailored sampling strategies, is highly effective in addressing insider threats. © 2024 by the authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Kamatchi, K.
AU  - Uma, E.
TI  - Securing the edge: privacy-preserving federated learning for insider threats in IoT networks
PY  - 2025
T2  - Journal of Supercomputing
VL  - 81
IS  - 1
C7  - 246
DO  - 10.1007/s11227-024-06752-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211328708&doi=10.1007%2Fs11227-024-06752-z&partnerID=40&md5=64936b2d7dc87e0934ddc66802fd94e7
AB  - Insider threats in Internet of Things (IoT) networks pose significant risks, as compromised devices can misuse their privileges to cause substantial harm. Centralized methods for insider threat detection in IoT devices are critical for identifying and mitigating insider risks. User behavior, such as access patterns, login times and data transmission, is profiled using machine learning algorithms to detect deviations that may indicate insider risks. However, training a model that generalizes across different data sources is challenging due to data heterogeneity, which can lead to a drift in performance. This paper introduces a decentralized approach called federated learning (FL) to address these challenges. An advanced privacy-preserving method is proposed for detecting and reducing insider threats in IoT devices. The process begins with a trust authority generating a random digital certificate using the hybrid Rivest–Shamir–Adleman and elliptic curve digital signature algorithm for IoT user registration. Node clustering is performed using the ordering points to identify the clustering structure with centroid refinement algorithm, ensuring data privacy by transmitting only cluster heads to local models. Additionally, the federated automatic weight optimization hash-based message authentication code with secure hash algorithm is introduced to further strengthen protection. The experimental results show accuracy rates of 98.85% on the simulated dataset and 83.74% on the X-IIoTID test dataset. These finding facilitates the effectiveness of the proposed solution in terms of accuracy, time, throughput, node scalability and overall performance. The results indicate that the proposed model outperforms other prominent approaches in the field. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Gao, P.
AU  - Zhang, H.
AU  - Wang, M.
AU  - Yang, W.
AU  - Wei, X.
AU  - Lv, Z.
AU  - Ma, Z.
TI  - Deep Temporal Graph Infomax for Imbalanced Insider Threat Detection
PY  - 2025
T2  - Journal of Computer Information Systems
VL  - 65
IS  - 1
SP  - 108
EP  - 118
DO  - 10.1080/08874417.2023.2267510
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174286173&doi=10.1080%2F08874417.2023.2267510&partnerID=40&md5=6877376732d27df8656fd44a690ad7b4
AB  - Insider threats pose a significant concern for critical information infrastructures. Graph neural networks are widely used for detection due to their ability to model complex relationships among network entities. However, deep learning algorithms struggle with learning from business system data as anomalies are extremely rare. To tackle this challenge, we propose deep temporal graph infomax (DTGI), a new method for detecting insider threats in real-world scenarios with highly imbalanced data. DTGI utilizes an extended continuous-time dynamic heterogeneous graph network and a behavior context constraint anomaly sample generator. This generator incorporates attack behavior context constraints to augment attack samples and enhance the performance of the supervised model. Extensive experiments conducted on the CERT dataset, consisting of over one million records, demonstrate that DTGI surpasses state-of-the-art methods in terms of detection performance. © 2023 International Association for Computer Information Systems.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 7
ER  -

TY  - JOUR
AU  - Ramani, S.
AU  - S Shukla, M.
AU  - Sata, A.
AU  - Mobarsa, D.
AU  - Jarboui, S.
TI  - Cybersecurity threat detection for financial institutions: developing advanced systems using R to safeguard against cyber attacks
PY  - 2025
T2  - International Journal of System Assurance Engineering and Management
DO  - 10.1007/s13198-025-03072-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105024971375&doi=10.1007%2Fs13198-025-03072-0&partnerID=40&md5=a24f6540cebb68b9729f53ce9e04b9c1
AB  - The study highlights the significance of cybersecurity in defending significant organizations' sensitive data while confronting the real issue of increasing cyber dangers in the banking sector. Therefore, the study hopes to improve the capability of identifying and mitigating the increasing cases of cyber threats, including DDoS and Malware attacks, utilizing a mix of machine learning algorithms in the context of R Studio. Therefore, the study demonstrates how enhanced big data and proactive analytical models support risk evaluation and offer trustworthy defenses against cyber threats that raise customer confidence in financial services. With the use of R Studio, the study evaluates cybersecurity risks related to the banking sector leveraging secondary data collection approaches. It includes techniques for processing the pre-processing, cleaning, and conversion of data to make room for the 40,000 entries with 25 columns. Multiple methods, including K-Nearest Neighbors, Decision Trees, and Gaussian Naive Bayes, are used to categorize and forecast the risks. R libraries are used for comparisons and searches to improve the precision of the model while searching for any trends. The present study confirms that the banking industry's capability to detect and identify cybersecurity issues is enhanced by the integration of machine learning into R Studio. To model cybersecurity threats, R Studio was used to implement the Gaussian Naïve Bayes (GNB), Decision Tree (DT), and K-Nearest Neighbour (KNN) classifiers. The models' respective accuracies of 34.08%, 34.04%, and 34.05% were extremely near to the random baseline that would be anticipated for a three-class problem. These findings suggest that the current dataset has limited predictive power and offer a repeatable standard for subsequent research using enhanced feature engineering and sophisticated ensemble or deep learning techniques. © The Author(s) under exclusive licence to The Society for Reliability Engineering, Quality and Operations Management (SREQOM), India and The Division of Operation and Maintenance, Lulea University of Technology, Sweden 2025.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Parthasarathy, S.M.
AU  - Gurunathan, K.
AU  - Deepalakshmi, P.
TI  - Identifying Insider Threats using AI: Detecting Malicious Behavior in Corporate Networks and Systems via Machine Learning
PY  - 2025
DO  - 10.1109/INCSST64791.2025.11210425
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105024935756&doi=10.1109%2FINCSST64791.2025.11210425&partnerID=40&md5=75b1a5c186cda92330cbbab193cc9dfc
AB  - The newest corporate cybersecurity challenge comes not from hackers, but from insiders; the malicious actions that insiders exchange has always been more difficult to detect and prevent than outside attacks. Regular rule-based security systems often struggle to detect the subtle, anomalous patterns related to insider threats, requiring more sophisticated and adaptive detection techniques. In this research, we study the potential of Artificial Intelligence (AI) and Machine Learning (ML) technologies in proactively detecting insider threats on corporate devices and networks. In this paper, a holistic AI-based detection framework is proposed that employs supervised and unsupervised learning models to evaluate associated user behavior, system logs, access patterns, and network activity. The models train by using historical data and behavioral baselines in an attempt to separate benign anomalies from malicious intent. In this study, we evaluate several key machine learning algorithms (Random Forest, Support Vector Machines (SVM), and Isolation Forest) and deep learning models (Recurrent Neural Networks (RNNs) and Autoencoders) for detecting insider threats. It also utilizes Natural Language Processing (NLP) techniques to veryvse unstructured data including emails, chat logs and internal documentation for early signs of potential risk. This paper presents a hybrid anomaly detection approach utilizing statistical profiling and real-time predictive analytics to improve accuracy and reduce the false positives. To experimentally validate our approach, we use benchmark datasets, like CERT Insider Threat Dataset, and synthetic enterprise network simulations. Results show that AI-enabled detection systems can be extremely effective in improving the accuracy of threat identification, which could provide a useful early warning system to prevent further damage. Moreover, this study also deals with the issues/problem of data labeling, interpretability of models as well as magnitude of employee supervision and privacy. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Kumar, A.
AU  - Patwa, S.
AU  - Jangir, S.K.
TI  - Insider Threat Prediction Using Machine Learning Techniques: A Literature Review
PY  - 2025
T2  - Lecture Notes in Networks and Systems
VL  - 1414 LNNS
SP  - 475
EP  - 487
DO  - 10.1007/978-981-96-6432-0_36
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105023951117&doi=10.1007%2F978-981-96-6432-0_36&partnerID=40&md5=a48cd28539cbce23be56d8e729e0f539
AB  - Insider threats are one of the toughest challenges in cybersecurity. Insider attacks can be particularly dangerous because they often go unnoticed and can lead to serious problems like data breaches, financial losses, and damage to a company’s reputation. This issue has become even more pressing in recent years with the rise of digital operations and remote work. Researchers have shown how machine learning can help predict these insider threats. While supervised learning models have shown great accuracy in identifying threats in certain datasets, they face a major hurdle: there simply isn’t enough labeled data on insider threats. On the other hand, unsupervised learning methods can spot unusual behavior and reveal hidden threats, but they often produce false alarms. Deep learning techniques could potentially offer better accuracy, but they require a lot of computing power and large amounts of training data. There are also exciting new trends in the field, such as behavioral biometrics, hybrid models, and explainable AI. However, challenges like inconsistent evaluation metrics and the difficulty of applying these models across different organizations still exist. This review aims to bring together existing research and pinpoint key areas that need more attention, providing a roadmap for future studies. By addressing issues like the need for standardized datasets, encouraging collaboration across different fields, and incorporating contextual data from organizations, this paper seeks to help future researchers create more effective and adaptable models for predicting insider threats. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Sangeethaa, S.N.
AU  - Balamurugan, M.
AU  - Boopathi Rajan, P.
AU  - Shobana, G.
AU  - Biju, J.
AU  - Nivedha, S.
TI  - Deep Learning-Based User Behavior Prediction for IT Security and Fraud Detection
PY  - 2025
DO  - 10.1109/ICCDS64403.2025.11209442
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105023832274&doi=10.1109%2FICCDS64403.2025.11209442&partnerID=40&md5=9211ab120cd792384d5e4d0282a0883b
AB  - Insider threat detection and financial fraud prevention remain significant challenges in cybersecurity and data-driven financial systems. This research introduces a novel hybrid deep learning model that integrates Convolutional Neural Networks (CNN), Bidirectional Gated Recurrent Units (BiGRU), and Transformer-based attention mechanisms to effectively learn both spatial and temporal features from user behavior and transaction logs. The proposed architecture is rigorously evaluated on two benchmark datasets: the CERT Insider Threat dataset and the Credit Card Fraud dataset. Experimental results reveal that the model outperforms traditional approaches such as CNN, GRU, and CNN-GRU with attention. On the CERT dataset, the model achieves a precision of 0.91, recall of 0.92, and an F1-score of 0.915. Similarly, it delivers a high Area Under Curve (AUC) of 0.99 on the Credit Card dataset, indicating excellent discriminatory power. These findings demonstrate the effectiveness and adaptability of the proposed model in real-world anomaly detection scenarios involving both insider threats and financial fraud. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Pandiya, B.
AU  - Kulkarni, P.
TI  - Managing Complexity in Cybersecurity: The Necessity of Human Oversight in Digital Immune Systems from Behavioral Forensic Perspective.
PY  - 2025
SP  - 145
EP  - 166
DO  - 10.1002/9781394383788.ch7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105023782317&doi=10.1002%2F9781394383788.ch7&partnerID=40&md5=c59277410fbab722e1fbd235061486a3
AB  - The rise of complex cyber-attacks is automation based on artificial intelligence (AI), and problems arise when the control of these events is not in the hands of humans. While digital immune systems (DIS) utilize AI and machine learning to spot and combat cyber risks in real-time, the systems are not immune to human-based threats like insider attacks, social engineering, and credential-based intrusions. These tactics leverage behavioral and psychological vulnerabilities rather than the technical ones, making them challenging for AI-based security solutions to catch. This study analyzes why automated cybersecurity mechanisms may have their limitations, and how human oversight may complement DIS, with potentially a behavioral forensic view of human oversight. This research discusses AI-run security models shortcomings using two well-known cyber incidents, the first being the Twitter Bitcoin Scam (2020) and the second being the Solar Winds cyberattack (2020). In both instances, attackers evaded automated security controls by exploiting human weaknesses via social engineering in Twitter’s case and a complex supply chain attack in SolarWinds. The first detects anomalies while the second relies on known attack signatures, therefore failing to recognize these attacks. Analysts later detected behavioral discrepancies that uncovered these breaches. Behavioral forensics is the intersection of psychology, criminology, and data analysis and holds the key to detecting deceptive behaviors and insider threats that AI-driven systems miss. This research analyzes the limitations of DIS and explores a cyber-physical infrastructure that essentially combines DIS with both behavioral forensics and human oversight to build a strong and adaptive cybersecurity framework. The findings discuss how a Human-in-the-Loop (HITL) security model, explainable AI (XAI) and zero-trust frameworks can increase cyber resilience by balancing automation with human expertise. The importance of introducing human oversight for cyber operations against technical threats and behavioral threats enabling a security-aware culture in an organization. © 2026 Scrivener Publishing LLC. All rights reserved.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Pinki, G.
AU  - Meenal, H.
AU  - Kishor Kumar Reddy, C.K.K.
AU  - Tabassum, S.H.
AU  - Lippert, K.
TI  - Leveraging AI in Cyber Defence: Transforming Modern Cybersecurity
PY  - 2025
SP  - 171
EP  - 188
DO  - 10.1201/9781003631507-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105023720756&doi=10.1201%2F9781003631507-9&partnerID=40&md5=0ead9e5fde7f83da668a5fa27655bff4
AB  - Advanced solutions for better protection In the world of digital threats in this fast-paced era, a call for drastic change has come from the conventional approach of cybersecurity implementation to AI-based ones. Today, artificial intelligence is playing an important role in modern cyber defence through unmatched capabilities in real-time threat detection, predictive analytics, and automated incident response. AI, leveraging the most advanced technologies of machine learning, deep learning, and natural language processing, makes it possible to examine massive, complex data to identify anomalies, detect advanced attacks including phishing, ransomware, and insider threats, and respond dynamically to changing risk patterns. It is this transformation alone that will improve the speed, accuracy, and scalability of cybersecurity but will also ensure quicker response times, hence reducing the damage potential. Despite its benefits, AI in cyber defence is not without issues. False positives and adversarial attacks that take advantage of system vulnerabilities pose management headaches. Inherent biases in the algorithms are also concerns and require careful management. Ethical concerns surrounding privacy and the over-reliance on automated systems have to be managed by humans to prevent misbehaviour. Collaboration between AI professionals and cybersecurity specialists ensures a robust and ethical operation of the system. Emerging technologies, such as quantum AI and federated learning, promise to further revolutionise cybersecurity, opening up fresh opportunities to strengthen defences but demanding updated regulatory frameworks and guidelines on ethics. © 2025 CRC Press.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Tamhankar, I.
AU  - Patel, Y.
AU  - Pandya, S.S.
TI  - Frameworks for Managing Insider Threats Using Behavioral Analytics and Machine Learning in Hybrid Clouds
PY  - 2025
DO  - 10.1109/WorldSUAS66815.2025.11199044
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105022310544&doi=10.1109%2FWorldSUAS66815.2025.11199044&partnerID=40&md5=d10f46a2a3f62b8c03bf98db6369ce73
AB  - This research provides an integrated framework for handling the insider threat problem for hybrid cloud environments utilizing the behavioral analytics and machine learning. The proposed system incorporates aspects of user activity monitoring, anomaly detection and automatic threat response in a multi-layered architecture. For the establishment of behavioral baselines, both unsupervised learning models such as Isolation Forest and Autoencoders and supervised classifiers such as Random Forest and XGBoost are used. The framework utilizes cloud-native monitoring tools that possesses the ability to aggregate data securely across on premise and public cloud infrastructures to facilitate scalability and real-time threat detection. A synthetic insider threat dataset modeling hybrid cloud behavior was used in experiments. The model resulted in overall accuracy of 93.6%, precision 92.1% and recall of 91.5%, F1-score of 91.8%. The MSE of 0.009, MAE of 0.062 in each event while proving the efficiency of the system. This framework provides a robust, scalable & adaptive approach to reduce insider threats in complex distributed cloud ecosystem. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Vengathattil, S.
AU  - Shaffi, S.M.
TI  - Advanced Network Security Through Predictive Intelligence: Machine Learning Approaches for Proactive Threat Detection—An Experimental Study
PY  - 2025
T2  - Premier Journal of Science
VL  - 15
C7  - 100155
DO  - 10.70389/PJS.100155
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021944327&doi=10.70389%2FPJS.100155&partnerID=40&md5=9d04706923abb1e0cfefb922eddfdbfb
AB  - Predictive intelligence is revolutionizing network security by introducing various Machine Learning (ML) techniques. As seen in the ever-increasing number of threats and attacks, the traditional approach to network security is inadequate. This article focuses on how ML enhances early identification and prevention of cyber threats and decreases response time and impacts. It is meant to explore the applicability of different types of ML, such as classification, clustering, deep learning, and anomalous signatures, in the detection of network intrusions and malicious actions before they do significant damage. Due to the use of large amounts of data acquired in real-time, ML algorithms can identify relationships and behaviors, observe anomalies, and detect threats to the organization’s security with impressive accuracy. Key points based on security findings stress the potency of security systems that incorporate ML algorithms in enhancing threat detection rates compared to traditional processes. These models are efficient in identifying zero-day attacks, insider threats, and refined malware threats since they learn from new threats. Further, they also minimize human involvement in a function, taking the efficiency of security operations to another level. In conclusion, incorporating ML into networks increases the protection methods of a network from posture to action, thus making it more holistic. Despite such issues as false alarms, adversarial examples, and data privacy, the future holds constant innovation towards even better predictive intelligence through development in AI and ML. Machine learning will play a key role in cybersecurity as threats evolve and new efficient solutions are sought. © 2025, Premier Science. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Baswaraju, B.
AU  - Reddy, I.
AU  - Akshaya, M.
TI  - Technical Insights into Systemic Vulnerabilities Behind Significant Cybersecurity Breaches
PY  - 2025
SP  - 171
EP  - 176
DO  - 10.1109/ICIMIA67127.2025.11200671
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021942334&doi=10.1109%2FICIMIA67127.2025.11200671&partnerID=40&md5=e009db467410d59b546e93e321e27477
AB  - This paper examines the growing threat of cybersecurity breaches in today's technology dependent world, where digital transformation and increased digital reliance from mobile phones to AI systems exposes more data and makes organizations increasingly vulnerable to sophisticated cybercrime. The study analyzes major cybersecurity threats by examining cyber attack methodologies, exploited vulnerabilities, and evolving threat actors, including nation states, organized cybercrime groups, and insider threats, while assessing the broader implications of large scale cyber incidents in critical industries like healthcare and finance. Through analysis of breaches over recent years, this research identifies recurring weaknesses in security infrastructure and emphasizes the need for proactive cybersecurity frameworks and enhanced threat detection capabilities. In this paper we employ Machine Learning classification models to analyze attack patterns and implement a structured four-phase incident response framework focusing on containment, defense, security implementation, and recovery. The approach integrates AI-driven threat detection and regular security assessments to strengthen organizational cybersecurity posture against evolving threats targeting networks, data, and endpoint users. The findings contribute to cybersecurity research by providing insights from previous incidents and proposing adaptive security measures that organizations can implement to mitigate risks and protect critical systems from emerging threats. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Pandey, P.
AU  - Kumar, P.
AU  - Parakh, V.K.
AU  - Verma, A.P.
AU  - Dwivedi, A.
AU  - Sharma, A.
TI  - AI-Powered Defenses: A Machine Learning Approaches in Cybersecurity Threat Detection
PY  - 2025
SP  - 394
EP  - 399
DO  - 10.1109/ICCPCT65132.2025.11176700
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020183969&doi=10.1109%2FICCPCT65132.2025.11176700&partnerID=40&md5=f29cde87ccb47711cdcb296670bd8fef
AB  - The increasing complexity and frequency of cyber threats call for advanced and adaptive defense mechanisms. Traditional cybersecurity techniques, which are mostly reactive and rule-based, no longer work in the presence of sophisticated attacks. This paper gives an in-depth review of the integration of machine learning into cybersecurity threat detection systems and how AI-driven defenses are shifting the face of digital security. It provides insight into various machine learning approaches, including supervision, unsupervised, and reinforcement learning toward the detection of a wide range of cyber threats, from malware and phishing to zero-day attacks and insider threats. The paper reviews their strengths and limitations of such approaches but also some of the problems that can be encountered in their implementation, which include data privacy issues, model interpretability, and adversarial attacks. We will identify, through analysis of current trends and case studies, how machine learning can really offer adaptive threat detection in near real time to enhance the resilience of cybersecurity infrastructures. This review aims at giving insight into the future directions of AIdriven cybersecurity and the ongoing evolution of threat detection methodologies. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Sahu, D.P.
AU  - Bhagat, S.
AU  - Dwivedi, V.
AU  - Singh, J.
AU  - Singh, N.
AU  - Garg, K.K.
TI  - Enhancing Security in Human Resource Management Through the Integration of Artificial Intelligence and Machine Learning
PY  - 2025
T2  - Lecture Notes in Networks and Systems
VL  - 1433 LNNS
SP  - 595
EP  - 609
DO  - 10.1007/978-981-96-7131-1_42
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105019302213&doi=10.1007%2F978-981-96-7131-1_42&partnerID=40&md5=650a453653c6247f27970bb6a14ed14b
AB  - The increasing threats from unauthorized access, insider threats, and data breaches have made the need for research in enhancing security within human resource management (HRM) systems critical for organizations. In that regard, the importance of incorporating advanced security measures in such systems arises since they contain sensitive information regarding employees. This research delves into the use of ML models to solve the above challenges through the development of an automated real-time predictive and preventive security breach system. The present study makes use of four different ML techniques: random forest (RF), artificial neural networks (ANNs), support vector machines (SVMs), and gated recurrent units (GRUs), on employee access logs, biometric authentication data, and the security-related event logs. The models were exposed to a mix of publicly accessible datasets made available by Kaggle, along with real-time data coming in from an institution's HRM system. After preprocessing the data, the performance of the models was evaluated with the help of metrics such as accuracy, precision, recall, and F1-score, and GRU turned out to be the winner with an accuracy of 95.89%. The SVM and RF models also delivered good accuracies at 93.45% and 91.20%, respectively, with ANN giving a slightly lower accuracy at 89.76%. The outcomes show that there is tremendous potential for improving HRM system security from machine learning models, particularly GRU, in spotting suspicious login attempts as well as patterns of unauthorized access. The original idea behind this research is to contribute to the development of real-time, proactive security solutions that can be integrated into HRM systems to safeguard sensitive organizational data and improve overall security posture. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Paul, A.
AU  - Sadiq, B.O.
AU  - Ramachandra, D.
AU  - Venkateswarlu, M.
AU  - Gutam, B.G.
AU  - Brian, M.
TI  - Implementing an Advanced Hybrid Models for Network Intrusion Detection Systems Against Insider Threats
PY  - 2025
DO  - 10.1109/ICCTDC64446.2025.11158098
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105019056171&doi=10.1109%2FICCTDC64446.2025.11158098&partnerID=40&md5=de754db9ee4688c4edc0956b369bb808
AB  - In the realm of cybersecurity, detecting insider threats presents a significant challenge due to their subtlety and complexity. This study employs advanced machine learning techniques, focusing on Long Short-Term Memory (LSTM) networks with attention mechanisms, alongside XGBoost and Transformer models, to enhance the detection of these threats. The LSTM models, particularly those utilizing attention mechanisms, demonstrated remarkable robustness by effectively prioritizing significant user behavior patterns, leading to high performance metrics. These findings underscore the effectiveness of LSTMbased attention mechanisms in capturing temporal dependencies and improving the model's sensitivity to anomalies, making them particularly suitable for identifying malicious behavior within networks. For future research, we recommend exploring hybrid models that integrate these attention-driven LSTM approaches to further enhance robustness and adaptability in evolving threat landscapes in intrusion detection systems. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Joshua Daniel Raj, J.J.
AU  - Sasikala, T.
AU  - Ezhilarasan, K.
AU  - Rajesh, K.
AU  - Karthik, P.
AU  - Immanuel, J.S.
TI  - Adaptive Attribute-based Encryption(A-ABE) Framework for Securing Smart IoT Networks
PY  - 2025
SP  - 249
EP  - 254
DO  - 10.1109/ICSCSA66339.2025.11171299
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018468812&doi=10.1109%2FICSCSA66339.2025.11171299&partnerID=40&md5=92335787fbccd2b41f4b73b8279fc22a
AB  - In this paper, we proposed and implemented an Adaptive Attribute-Based Encryption (A-ABE) Framework that combines Ciphertext-Policy ABE with context-aware machine learning to secure smart IoT networks. The framework focused on key limitations of traditional ABE schemes, and their inability for adapting to dynamic user contexts and access requirements in real time scenarios. By deploying lightweight machine learning models, the system can be enabled to intelligently analyze contextual data like location, user behavior, and role changes - and update access policies accordingly, without requiring manual re-encryption or administrative intervention. The implementation and evaluation conducted in a simulated smart healthcare environment demonstrated that the A-ABE framework offers an optimal balance between security, adaptability, and system efficiency. The experimental results showed low encryption and decryption delays, high policy enforcement accuracy , and modest increases in resource utilization, making the solution is viable for deployment on edge devices. Overall, the proposed framework improves both the confidentiality of sensitive IoT data and the resilience of access control mechanisms against insider threats, contextual anomalies, and unauthorized access. This research confirms that combining ABE with real-time machine learning provides a scalable and intelligent approach to enforcing secure access in dynamic IoT environments. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Bilychenko, M.
AU  - Kasianova, N.
AU  - Smerichevskyi, S.
AU  - Lavrynenko, O.
AU  - Kryvovyazyuk, I.
TI  - Development of a smart personnel security system using machine learning
PY  - 2025
T2  - CEUR Workshop Proceedings
VL  - 4042
SP  - 203
EP  - 215
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018455201&partnerID=40&md5=5224b770b8b37eb0f8a098a87340b24e
AB  - Insider threats remain one of the most challenging aspects of organizational security, particularly in the era of digital transformation and widespread remote access to sensitive data. This study proposes a machine learning-based approach to personnel security that combines Isolation Forest and Local Outlier Factor algorithms with behavioral features enhanced through the use of large language models (LLMs). To improve detection accuracy, user web activity was classified using LLM-generated labels derived from website content analysis. Experimental results demonstrate strong model performance in identifying insider activity at the user level, with high detection accuracy and minimal false classifications. In addition, time-to-detection analysis revealed that most insider threats were identified before or shortly after the onset of malicious behavior. The findings suggest that the proposed system is not only effective in capturing behavioral anomalies but also feasible for real-time deployment in enterprise environments. © 2025 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Krishna, S.
AU  - Sidharth, S.
TI  - CYBERATTACKS AND EMPLOYEE ATTRITION ANALYSIS FOR BUSINESS CONTINUITY PLANNING: A MACHINE LEARNING APPROACH AND AN AI APPLICATION
PY  - 2025
SP  - 199
EP  - 220
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018275928&partnerID=40&md5=22a8ae60baf020486fc30858f9d66ad7
AB  - Cybersecurity and employee attrition are two important areas of concern for any organization. Employee attrition can have a notable effect on an organization's cybersecurity and the broader cyber ecosystem. Departing employees may take with them valuable knowledge, expertise, and access to sensitive systems and data, which can be used by malicious actors to harm the organization or others in the cyber ecosystem. Additionally, employee attrition can lead to an increased risk of insider threats, a skills gap, and a loss of talent and intellectual property in the wider cyber ecosystem. Employee attrition has become a critical setback for companies. This is because of the adverse effect employee attrition has on workforce motivation and productivity, as well as also long-term augmentation strategies. To miti gate the impact of employee attrition, organizations should implement robust cybersecurity policies and procedures, prioritize employee engagement and retention, and ensure that all employees receive regular training on cyber security best practices. By doing so, organizations can better protect their assets and contribute to a more secure and resilient cyber ecosystem. Additionally, to combat the problems of employee attrition, compa nies are also employing machine learning (ML) techniques to predict the turnover of recruits. Throughout this study, an attempt was undertaken to create a model using IBM HR analytics data that can predict the rate of employee turnover. The real dataset contains 35 functionalities on top of 1470 samples. To make predictions, random forest (RF) is used. SMOTE converts the model built with RF classifier to perk up target class imbalance. However, after SMOTE process training model metrics are enhanced, validation metrics are somewhat better, with little impact on sensitivity. Moreover, this paper includes the factors influencing employee attrition within an organization thus providing senior manage ment with a clearer context while trying to make the most important decisions concerning the interaction of the firm's preponderance of the workforce. In prospective research, the experiment may be meant to diminish the prediction error margin. © 2026 by Apple Academic Press, Inc.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Ande, B.R.
TI  - Autonomous AI Agents for Identity Governance: Enhancing Financial Security Through Intelligent Insider Threat Detection and Compliance Enforcement
PY  - 2025
T2  - Learning and Analytics in Intelligent Systems
VL  - 56
SP  - 491
EP  - 502
DO  - 10.1007/978-3-032-05373-2_43
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018004698&doi=10.1007%2F978-3-032-05373-2_43&partnerID=40&md5=a0b05625e119fc684a71075ba5b75733
AB  - The increasing complexity of financial architectures and the rise of cyber threats, securing enterprise data and regulatory compliance, has never been more necessary. The identity governance landscape is a domain that can benefit significantly from this approach, as autonomous AI agents have shown that they can act in real-time and adjust as per learning. These intelligent agents can also help enhance financial security through proactive insider threat detection and dynamic compliance enforcement. Machine learning algorithms are used by AI to identify anomalies and shut down anything that appears as ZBB (Zero Based Budgeting) implementation taking place, which significantly minimizes the chances of data theft and insider fraud. Moreover, these agents are able to monitor and enforce adherence to ever-changing regulatory requirements in the field, ensuring organizations’ operational health and preventing heavy fines for non-compliance. Using autonomous AI agents minimizes business risk for organizations by allowing them to identify potential insider threats earlier, decrease false-positive rates, and streamline compliance tracking. The emergence of autonomous AI agents embedded in identity governance frameworks is the next innovative step in solving the challenge of financial data security and helping enterprises stay one step ahead of outside or insider threats. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Girma, A.
AU  - Tamirat, M.
TI  - “The Impact of Personality on Cyberthreat Perception and Mitigation”: An Integrating Behavioral Insights by Promoting a More Comprehensive, Human-Oriented Approach to Threat Identification and Management
PY  - 2025
T2  - Lecture Notes in Networks and Systems
VL  - 1554 LNNS
SP  - 695
EP  - 707
DO  - 10.1007/978-3-031-99965-9_43
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017228500&doi=10.1007%2F978-3-031-99965-9_43&partnerID=40&md5=dd667f665d73d9f02759ec0ef1dbe8b8
AB  - In an era marked by increasing cyber threats, understanding the human factors that influence security perceptions is more crucial than ever. As cyber risks, particularly those stemming from insider behavior and intricate attack strategies, become increasingly common, this research highlights several key issues including the limitations of current detection systems that primarily focus on technological solutions; the tendency to overlook the critical role of human behavior in cybersecurity; and the urgent need for strategies that integrate behavioral insights to enhance threat mitigation. By analyzing insider threat dataset, we reveal important correlations between personality traits and the suspicion of cyber threats, suggesting that understanding these traits is essential for evaluating vulnerabilities. Our findings indicate that incorporating human behavior insights into sophisticated deep learning models can significantly enhance CyberSecurity strategies, promoting a more comprehensive, human-oriented approach to threat identification and management. This paper not only elucidates the vital connections between personality traits and CyberSecurity vulnerabilities but also proposes an innovative framework for blending psychometric data with conventional intrusion detection systems. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Dreshaj, A.
AU  - Hamiti, M.
AU  - Hasani, Z.
AU  - Ajdari, J.
AU  - Besimi, N.
TI  - Systematic Literature Review on Automatic Anomaly Detection Based on Database Logs
PY  - 2025
SP  - 1933
EP  - 1937
DO  - 10.1109/MIPRO65660.2025.11132041
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016564301&doi=10.1109%2FMIPRO65660.2025.11132041&partnerID=40&md5=606605bd116c59f1944288f3218887f9
AB  - Automatic anomaly detection based on database logs is an approach for ensuring the security and reliability of modern database management systems. This systematic literature review, which is significant to the field, summarises the existing research on database logs methodologies, algorithms, and anomaly detection applications. The review explores various approaches, including statistical methods, machine learning techniques, and hybrid models, highlighting their effectiveness in identifying anomalies such as unauthorised access, data corruption, and performance issues. By analysing conference papers, articles, and industry reports published over the past two decades, this study identifies key trends, challenges, and future directions in the field. The findings suggest that while significant advancements have been made, there are still gaps in scalability, real-time detection, and handling of complex data environments. This review provides a comprehensive overview for researchers and practitioners, engaging them in the current landscape and inspiring them to develop more robust anomaly detection systems in database management. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Manju, A.
AU  - Puteh, M.
AU  - Subha, R.
TI  - Insider Threat Detection using Machine Learning Models for User Behavior Analysis
PY  - 2025
SP  - 811
EP  - 814
DO  - 10.1109/ICOECA66273.2025.00143
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015518641&doi=10.1109%2FICOECA66273.2025.00143&partnerID=40&md5=34e95b733b6682484d616791b9f06c1a
AB  - Insider threats pose a serious threat to an organization's security in the current digital environment. The emergence of Bring Your Own Device (BYOD) and Cloud Computing has made the protection of sensitive data critical. This work explored using machine learning (ML) models to analyze user behavior, with a focus on insider threat detection. The models employed state-of-the-art techniques such as anomaly detection, clustering, and deep learning to identify malicious activity initiated by authorized users. Further, the results demonstrated that these models can help organizations reduce insider risks and enhance cybersecurity protocols. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Iseed, S.
AU  - Hamarsheh, M.M.N.
TI  - Performance Evaluation of LSTM Autoencoder for Behavioral-Based Insider Threat Detection
PY  - 2025
DO  - 10.1109/SmartNets65254.2025.11106886
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015375363&doi=10.1109%2FSmartNets65254.2025.11106886&partnerID=40&md5=bdbefe6564143f5e882f206e953fb118
AB  - Trusted employees in the companies may pose a serious threat to their organizations. Their malicious behaviors will be hard to detect because they depend on the complexity of human behavior, which poses a big challenge to companies, this is called an insider threat attack. Detecting insider actors requires sophisticated user behavior detection models. However, these models need to be highly resource efficient. The proposed approach focuses on insider threat detection using user behavior analysis deep learning. CMU-CERT insider threat $\mathbf{r 4. 2}$ dataset is used in our approach. The events were analyzed to extract the features; they were selected based on the valuable data they included, such as user identity, login and logoff time, etc. Feature vectors were created from selected features and split into training and testing data for the Long-Term-Short-Memory (LSTM) Autoencoder model and evaluated the resource usage during the training and testing stages. The results of the proposed solutions produced an Accuracy of 98.6%. Moreover, the average utilization of the Central Processing Unit (CPU) during training phase is only 6% and the usage of Random Access Memory (RAM) is stabilized at $\mathbf{2 5 0 MB}$. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Chahid, A.
AU  - El Marzak, Y.
AU  - Ahriz, S.
AU  - Mansouri, K.
TI  - Cloud Security: A Model for Attack Detection and Prevention Using AI Technologies
PY  - 2025
T2  - Lecture Notes in Networks and Systems
VL  - 1555 LNNS
SP  - 172
EP  - 181
DO  - 10.1007/978-3-031-99997-0_16
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014495612&doi=10.1007%2F978-3-031-99997-0_16&partnerID=40&md5=de7d01f4ea330a54b5451a01abec59bf
AB  - The rapid adoption of cloud computing has revolutionized data management worldwide, offering unmatched flexibility, significant cost savings, and seamless scalability. However, this transformation also introduces a host of security challenges data theft, denial-of-service attacks, insider threats, misconfiguration errors, and malware infections all of which expose the limitations of traditional security approaches. This study explores how artificial intelligence (AI) can strengthen cloud security by leveraging machine learning, deep learning, natural language processing, predictive analytics, and automated incident response. To create a well-structured understanding of the intricate connections between security threats, AI-driven solutions, and protection strategies, an ontology has been incorporated into the proposed model. This integration not only enhances issue identification but also improves the assessment of AI-based defense mechanisms, leading to practical and effective security recommendations. By enabling early risk detection, swift attack responses, and reinforced data protection, this approach ensures a more resilient and secure cloud environment. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Walia, G.S.
AU  - Deepalakshmi, P.
TI  - Protecting Cloud Computing Environments from Cyber Threats with AI-Powered Machine Learning Systems
PY  - 2025
DO  - 10.1109/GINOTECH63460.2025.11076781
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013625145&doi=10.1109%2FGINOTECH63460.2025.11076781&partnerID=40&md5=ffa3fad0df2be2290c669ae59612f707
AB  - Cyberattacks on cloud computing have increased dramatically in recent years due to the technology's central role in today's digital infrastructure. The scattered and ever-changing nature of cloud systems makes it difficult for traditional security measures to identify and counteract sophisticated attackers. With an emphasis on their capacity to identify, avert, and react to cyber dangers in real-time, this study investigates the use of AI and ML technologies to improve cloud security. By analyzing massive databases for trends, predicting harmful actions, and mitigating assaults before they do harm, AI-powered solutions provide an adaptable, automated method to cloud security. Cloud security features including intrusion detection, anomaly detection, and threat intelligence are among those studied in this research, along with supervised, unsupervised, and reinforcement learning machine learning models. Artificial intelligence (AI)-powered systems may swiftly and accurately identify sophisticated multi-vector cyberattacks, zero-day attacks, insider threats, and other forms of cybercrime by examining network traffic, user behavior, and system vulnerabilities. Data privacy, scalability, and the possibility of adversarial assaults on AI models are some of the issues that this study resolves as they pertain to cloud AI integration. The practical benefits of cloud security solutions powered by AI are demonstrated through case studies from areas like e-commerce, healthcare, and finance. Improving the interpretability of AI models, making them more scalable, and making sure they comply with regulations so they may be used more widely are all topics covered in the paper's discussion of future research directions. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Imamguluyev, R.
TI  - Detection and Prevention of Cyber Attacks Based on Fuzzy Logic and Deep Learning
PY  - 2025
T2  - Lecture Notes in Networks and Systems
VL  - 1529 LNNS
SP  - 402
EP  - 409
DO  - 10.1007/978-3-031-97992-7_45
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013049841&doi=10.1007%2F978-3-031-97992-7_45&partnerID=40&md5=369f0db2cc374f4b30de90a42176941b
AB  - In the rapidly evolving landscape of cybersecurity, the increasing sophistication of cyberattacks necessitates the development of intelligent and adaptive defense mechanisms. Traditional security systems often struggle to effectively detect and mitigate novel and complex attacks due to their reliance on predefined rule-based techniques. This paper proposes a hybrid approach integrating Fuzzy Logic and Deep Learning for cyberattack detection and prevention, aiming to enhance the accuracy and adaptability of security systems. The proposed framework leverages Fuzzy Logic to handle uncertainty in network traffic, enabling real-time decision-making with flexible rule sets. Meanwhile, Deep Learning models, particularly Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), are utilized to analyze patterns in large-scale cybersecurity datasets, improving threat identification. The fusion of these technologies ensures an adaptive, self-learning, and robust defense mechanism against cyber threats, including DDoS attacks, malware, and insider threats. Extensive simulations and real-world datasets validate the effectiveness of the proposed system, demonstrating superior detection accuracy compared to conventional methods. This study contributes to the advancement of AI-driven cybersecurity by providing an intelligent, scalable, and interpretable cyber defense framework, suitable for modern network infrastructures. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Yapa, K.
AU  - Jayakody, A.
AU  - Wijayasekara, S.
AU  - Kerrison, S.
AU  - Rathu Baduge, D.P.P.
TI  - AI and SDN Based Framework to Mitigate Threats and Vulnerabilities in Internet of Medical Things
PY  - 2025
T2  - International Journal on Communications Antenna and Propagation
VL  - 15
IS  - 2
SP  - 112
EP  - 121
DO  - 10.15866/irecap.v15i2.25994
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012988962&doi=10.15866%2Firecap.v15i2.25994&partnerID=40&md5=705132487d31df9ac367b9a4b71c0266
AB  - The healthcare industry is critical for the well-being of humans. New technologies have positively influenced the healthcare industry, finding new ways to improve patient care. Internet of Medical Things devices are vulnerable to network-related attacks like Denial of Service attacks, reconnaissance, insider threats, etc. There are numerous benefits to the healthcare industry, but at the same time, various evolving cybersecurity threats are potentially affecting the IoMT environment. Software Defined Networking is an emerging networking field that introduces SDN Controllers that can dynamically control data flow in a network. A system model to effectively use SDN with IoMT, as well as the development of a framework for categorizing attacks on IoMT devices, is presented in this paper. Further, the use of machine learning and deep learning methods to accurately identify network-related attacks in an IoMT network environment is also explored. © 2025 Praise Worthy Prize S.r.l.-All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Laczi, S.A.
AU  - Póser, V.
TI  - Behavioural Analysis in Human-Machine Interaction for Insider Threats
PY  - 2025
SP  - 101
EP  - 106
DO  - 10.1109/INES67149.2025.11078220
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012713494&doi=10.1109%2FINES67149.2025.11078220&partnerID=40&md5=b0b0948740adb1b41b23e43249be6dac
AB  - Human-machine interaction (HMI) plays a critical role in understanding and mitigating insider threats within cybersecurity systems. In this context, HMI refers to the dynamic exchange of actions and feedback between users and computer systems, which includes behaviours such as login/logout patterns, file access frequency, typing dynamics and emotion-based sentiment indicators. Insider threats are often manifested in subtle variations in these behavioural patterns, such as unusual access times, excessive file downloads or altered typing speeds caused by cognitive or emotional stress. This study uses Random Forest (machine learning) classifiers to analyze HMI data and predict insider threats. Key features such as login times, number of file accesses, typing speed and emotional scores are used as critical input data for these models. The results show that HMI patterns coupled with advanced anomaly detection provide a robust mechanism for identifying deviations from normal behaviour and thus indicating potential threats. It underlines the importance of combining behavioural, cognitive and emotional indicators to create more adaptive and resilient cybersecurity systems. This research highlights the potential of HMI-based analytics in transforming insider threat detection from reactive to predictive, ensuring safer and more proactive organisational environments. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Kong, K.
AU  - Jin, X.
AU  - Liu, D.
AU  - Xu, S.
AU  - Liu, Z.
AU  - Geng, G.
TI  - DPI-ITD: A Dual-Perspective Information-Driven Framework for Insider Threat Detection in IoT Systems
PY  - 2025
T2  - IEEE Internet of Things Journal
VL  - 12
IS  - 19
SP  - 40731
EP  - 40749
DO  - 10.1109/JIOT.2025.3589636
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012315755&doi=10.1109%2FJIOT.2025.3589636&partnerID=40&md5=a2b838f252b13d6d4f292c4af76e0dd6
AB  - In Internet of Things (IoT) environments, insider threat detection has advanced with the integration of deep learning techniques, which can effectively model complex behaviors and heterogeneous data. However, the fragmented nature of IoT logs, behavioral redundancy, and the sparsity of insider actions increase detection complexity. While fine-grained behavior classification can improve accuracy, it also raises computational overhead, limiting applicability in resource-constrained scenarios. To address these challenges, we propose dual-perspective information-driven framework for insider threat detection (DPI-ITD), which combines user-centric and behavior-centric analyses to enhance detection efficiency and accuracy. DPI-ITD introduces a symbolic tagging strategy guided by tagging scores (TS), derived from user action diversity and behavioral context, to filter redundant fragments and focus on high-impact behaviors. It further incorporates an adaptive embedding mechanism based on GloVe, which dynamically adjusts the context window for rare but critical actions. Experiments on multiple closed and open behavioral datasets demonstrate DPI-ITD's superior detection performance, scalability, and efficiency, confirming its suitability for lightweight deployment in real-world IoT security systems. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Modalavalasa, G.
AU  - Yadav, P.
TI  - A Hybrid Approach to Cloud Database Security: Integrating DL and Machine Learning for Threat Detection and Prevention
PY  - 2025
SP  - 1147
EP  - 1154
DO  - 10.1109/ICICI65870.2025.11069530
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012166061&doi=10.1109%2FICICI65870.2025.11069530&partnerID=40&md5=a1e62531f3d6a26a3d40a5f7299b015d
AB  - The complexity and ongoing evolution of Advanced Persistent Threats (APTs) compromise the efficacy of conventional cybersecurity measures. Insider threats remain a critical concern in cloud environments, necessitating robust strategies for detection and mitigation. This study presents a new method for detecting intrusions in cloud databases that combines ML and DL approaches. The model used is the Autoencoder Multilayer Perceptron (AE-MLP). This research trains and tests its models using the CICDS 2019 dataset, which includes labeled data on network traffic indicating both typical and malicious activity. The AE-MLP model demonstrates superior performance, achieving 99% accuracy, 98.75% precision, 98.92% recall, and 98.79% F1-score, significantly outperforming other models The findings demonstrate that the AE-MLP model is a viable option for protecting cloud databases since it can identify cyber risks with high accuracy and low false positive and negative rates. The Research article also discusses the performance evaluation, including the training and testing accuracy over epochs and the impact of model complexity on detection efficiency. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Komalavalli, D.
AU  - Dhanus, E.M.
AU  - Ilam Bharathi, R.
AU  - Aishwarya, V.
AU  - Gowrarasan, A.
TI  - A Literature Survey on Data Leaks in Cloud Environments
PY  - 2025
DO  - 10.1109/ICCRTEE64519.2025.11052952
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012161467&doi=10.1109%2FICCRTEE64519.2025.11052952&partnerID=40&md5=8ee2ab3f6e85d3ffbd6026c7dcd50a78
AB  - Data leaks in cloud computing have become a major security threat, exposing sensitive data to all kinds of unwanted access. The big question, of course, is: How does this happen? Leaks can occur because of Misconfigurations, Insider threats, Insecure APIs, Malicious attacks. These aren't just theoretical problems. They have caused severe and sometimes irreversible damage to many organizations. As more and more companies turn to the cloud, traditional security methods that operate in real time and use well-defined system boundaries are having a tougher time protecting anything at all. This article examines the many causes and effects of data leaks in cloud systems, focusing on important vulnerabilities and risk factors. Furthermore, it examines cutting-edge detection strategies, such as machine learning-based anomaly detection, cryptography algorithms, and deep learning architectures meant to detect unauthorized data access. This study seeks to provide a complete understanding of data leak detection and prevention tactics by examining existing research and real-world case studies, which will help to design stronger cloud security frameworks. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Sharma, R.
AU  - Sherje, S.N.
AU  - Sharma, S.
AU  - Ahuja, K.
AU  - Marathe, V.
AU  - Birari, D.R.
TI  - Machine Learning for Insider Threat Detection in Cybersecurity—A Comparative Analysis
PY  - 2025
T2  - Lecture Notes in Networks and Systems
VL  - 1365 LNNS
SP  - 343
EP  - 355
DO  - 10.1007/978-981-96-5223-5_28
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011282842&doi=10.1007%2F978-981-96-5223-5_28&partnerID=40&md5=5228697e1b1f23fff344b6874e500a3f
AB  - With the growing dependence of organizations on digital infrastructures, the threat of insider cybersecurity breaches has become a significant worry. This study investigates how machine learning models perform in identifying insider threats, specifically examining the influence of feature selection through Recursive Feature Elimination (RFE). The models chosen for evaluation are Random Forest, SVM (One-Class), Isolation Forest, LSTM, and Autoencoder. The research methodology includes gathering a thorough dataset that encompasses various insider threat scenarios. The dataset contains features that include a range of behavioral, network, and system-related attributes. Two experimental setups are used: one involves feature selection using Recursive Feature Elimination (RFE) and the other does not use feature selection. Random Forest is utilized to assess the models’ performance due to its resilience and capability to manage varied datasets. SVM (One-Class) is evaluated for its effectiveness in detecting insider threats due to its ability to perform effectively in high-dimensional spaces. The Isolation Forest algorithm is used for anomaly detection to pinpoint uncommon patterns in the data. LSTM, a Recurrent Neural Network, and Autoencoder, a neural network architecture for unsupervised learning, are used to capture temporal dependencies and latent representations, respectively. The comparative analysis evaluates important performance metrics including precision, recall, F1-Score, and area under the receiver operating characteristic curve (AUC-ROC). The study seeks to assess how feature selection affects the effectiveness of each model, investigating whether eliminating irrelevant features improves or impairs the identification of insider threats. This research offers valuable insights into the strengths and weaknesses of the chosen machine learning models for detecting insider threats in cybersecurity. Organizations can analyze how feature selection affects the deployment of models to enhance their cybersecurity defenses against insider threats, helping them make well-informed decisions based on their unique needs and limitations. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Prakash, V.
AU  - Gnanaselvi, J.A.
TI  - An AI-Driven Intelligent Threat-Responsive Shard Management System ITRSMS for Adaptive Cloud Security
PY  - 2025
DO  - 10.1109/ICFTS62006.2025.11031848
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010817780&doi=10.1109%2FICFTS62006.2025.11031848&partnerID=40&md5=0ce7134dfba0cb807d4d433321b8476d
AB  - The increased use of cloud computing has been accompanied by serious security challenges, particularly in safeguarding sensitive data from cyber threats characterized by unauthorized access, ransomware, and insider threats. Traditional security approaches tend to rely on static defense mechanisms, which demonstrate inflexibility in a dynamic and evolving threat landscape. To overcome the above-stated problems, this paper proposes the Intelligent Threat-Responsive Shard Management System (ITRSMS), an artificial intelligence-powered system designed to enhance cloud security by using anomaly detection, predictive threat analysis, and adaptive shard redeployment. The ITRSMS employs deep learning techniques for anomaly detection to enable the identification of anomalous behaviors in cloud systems. By training normal operational behaviors with autoencoders, the system is able to detect anomalies based on reconstruction errors, thereby enabling early detection of potential security threats. Upon detection of an anomaly, the system will determine the severity of the threat and rebalance data shards to minimize exposure to compromised nodes. The redistribution process is governed by a weighted optimization function that assesses the security risk of every storage node in order to avoid high-risk regions in shard allocations. Furthermore, the ITRSMS system uses reinforcement learning to progressively enhance its shard assignment strategy. The architecture models shard assignment as a Markov Decision Process (MDP) and uses a reward-based learning algorithm to optimize security in a way that security countermeasures are reinforced. With its ability to be perpetually dynamic in accordance with evolving threat profiles, the ITRSMS provides enhanced security from cyberattacks with transparent data availability and minimal performance impact. AI-driven cybersecurity practice finds additional avenues through this research work by providing a novel security platform that provides protection for cloud data using the strength of predictive analytics and real-time dynamic allocation mechanisms. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Alketbi, K.S.
AU  - Mehmood, A.
TI  - A Comprehensive Survey of Explainable Artificial Intelligence Techniques for Malicious Insider Threat Detection
PY  - 2025
T2  - IEEE Access
VL  - 13
SP  - 121772
EP  - 121798
DO  - 10.1109/ACCESS.2025.3587114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010326835&doi=10.1109%2FACCESS.2025.3587114&partnerID=40&md5=753f0a1e21332b0aa27cb0f15cde8729
AB  - Malicious insider threats remain a persistent and formidable challenge for organizations, primarily due to their covert nature and the severe impact they can have on critical systems and sensitive data. Traditional detection mechanisms often struggle to uncover such threats, underscoring the need for more intelligent, interpretable, and trustworthy solutions. Although the research community has shown increasing interest in Insider Threat Detection (ITD), existing surveys rarely emphasize the integration of Explainable Artificial Intelligence (XAI) with machine learning (ML) and deep learning (DL) techniques. This oversight has limited progress in understanding how interpretability can improve both detection effectiveness and the trust of security analysts. To address this gap, this survey presents a comprehensive review of the application of XAI in ITD. It explores how ML and DL models, when combined with XAI techniques, can uncover anomalous behaviors and insider actions while enhancing the transparency of model decisions. Tools such as SHAP and LIME are examined for their role in revealing feature contributions and improving analyst insight. The paper also highlights critical data sources–ranging from behavioral logs and network activity to psychometric indicators–that support the development of interpretable detection models. We categorize existing literature based on XAI techniques, data modalities, and threat models, and propose a conceptual framework for aligning XAI methods with specific ITD challenges. Our findings reveal that while XAI enhances interpretability and trust in AI-driven threat detection, several challenges persist. These include class imbalance in datasets, integration of heterogeneous data streams, and the absence of standardized metrics for evaluating explainability in cybersecurity contexts. Finally, the survey identifies key directions for future research, including privacy-preserving AI, human-in-the-loop explainability, and the development of benchmarking frameworks tailored to ITD applications. By offering a structured and up-to-date overview of XAI-enhanced ITD approaches, this work supports the advancement of more transparent, accountable, and operationally effective insider threat detection systems. © 2013 IEEE.
M3  - Review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Senevirathna, D.H.
AU  - Gunasekara, W.M.M.
AU  - Gunawardhana, K.P.A.T.
AU  - Ashra, M.F.F.
AU  - Fernando, H.
AU  - Abeywardena, K.Y.
TI  - Enhancing Organizational Threat Profiling by Employing Deep Learning with Physical Security Systems and Human Behavior Analysis
PY  - 2025
T2  - International Journal of Advanced Computer Science and Applications
VL  - 16
IS  - 6
SP  - 284
EP  - 293
DO  - 10.14569/IJACSA.2025.0160628
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009493244&doi=10.14569%2FIJACSA.2025.0160628&partnerID=40&md5=5d706f0f6f02f9b807cbc16fe4298bb1
AB  - Organizations need a comprehensive threat profiling system that uses cybersecurity methods together with physical security methods because advanced cyber-threats have become more complex. The objective of this study is to implement deep learning models to boost organizational threat identification via human behavior assessment and continuous surveillance activities. Our method for human behavior analysis detects insider threats through assessments of user activities that include logon patterns along with device interactions and measurement of psychometric traits. CNN, together with Random Forest classifiers, has been utilized to identify behavioral patterns that indicate security threats from inside the organization. Our model uses labeled datasets of abnormal user behavior to properly differentiate between normal and dangerous user activities with high accuracy. The physical security component improves surveillance abilities through the use of MobileNetV2 for real-time anomaly detection in CCTV video data. The system receives training to detect security breaches and violent and unauthorized entry attempts, and specific security-related incidents. The combination of transfer learning and fine-tuning methodologies enables MobileNetV2 to deliver outstanding security anomaly detection alongside low power requirements, thus it fits into Security Operations Centers operations. Experiments using our framework operate on existing benchmark collection sets that assess cybersecurity, together with physical security threats. Experimental testing establishes high precision levels for detecting insider threats along with physical security violations by surpassing conventional rule-based methods. Security Operation Centers gain an effective modern threat profiling solution through the application of deep learning models. The investigation generates better organization defenses against cyber-physical threats using behavioral analytics together with intelligent surveillance systems. © (2025), (Science and Information Organization). All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Jeny, J.R.V.
AU  - Shivaspandana, S.
AU  - Pavan, K.
AU  - Muthukumaran, N.
AU  - Akash, K.
TI  - Threat Eye: Behavior Analytics for Cloud Security using ML
PY  - 2025
SP  - 1551
EP  - 1556
DO  - 10.1109/ICICCS65191.2025.10984898
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007522850&doi=10.1109%2FICICCS65191.2025.10984898&partnerID=40&md5=f25b28a3182b3814430924f19532493a
AB  - Cloud computing has developed for its storage and accessibility of data, providing flexibility, scalability, and affordability. But its extensive use has also resulted in cyberattacks and unauthorized access. The traditional intrusion detection mechanisms become ineffective for different attack patterns, insider attacks and zero-day exploits. This paper provides an efficient way to address this issue by providing a mechanism to identify the threat based on the behaviour of the user. Unlike traditional approaches this paper provides a system that monitors the user behaviour patterns considering the features such as login history, authentication attempts, session duration, file access activities, password change frequency and IP location modifications. By considering these features the attack can be detected, and the data access is restricted to prevent from unauthorized access. This paper provides handling of attack with a combination of machine learning algorithms including SVM, Decision tree and XBoost, these help in distinguishing between the attacker and the authorized user. This helps in identifying complex attack behaviours and detect insider threats. Additionally, RSA encryption is integrated to secure data transmissions, preventing unauthorized access. By combining behavioural analysis, attacks prediction, and encryption, this provides a robust cybersecurity framework. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Ali, S.
AU  - Deverill, H.
AU  - Lindquist, J.
AU  - Roginski, J.
TI  - Human and machine partnership: natural language processing of army insider threat hub data
PY  - 2025
T2  - International Journal of Applied Decision Sciences
VL  - 18
IS  - 7
SP  - 1
EP  - 22
DO  - 10.1504/IJADS.2025.146569
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007346726&doi=10.1504%2FIJADS.2025.146569&partnerID=40&md5=1d8b6e4601abc0b0984f803d6161cc04
AB  - Threats to organisational efficacy and wellness may come from competitors (external threat) or from trusted agents (insider threat). Countering the insider threat is an imperative for the security of governments, the military, businesses, and all other organisations and institutions that employ people. This paper presents a case prioritisation system that utilises a deep learning classification model trained on expert evaluated insider threat cases to label cases as ‘negligible’, ‘low’, ‘medium’, or ‘high’ threat level. This classification model enables a partnership between machine and human that focuses human effort for the greatest impact. To evaluate the models created, the authors created a metric called ‘detection accuracy rate’ that measured correct prediction and over- estimations of threat, with the best model achieving a 96% detection accuracy rate. © The Author(s) 2025 Published by Inderscience Publishers Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
TI  - 15th EAI International Conference on Digital Forensics and Cyber Crime, ICDF2C 2024
PY  - 2025
T2  - Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST
VL  - 614 LNICST
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007222398&partnerID=40&md5=e0a8c3ef4a190858dc5a462b7e8f52db
AB  - The proceedings contain 40 papers. The special focus in this conference is on Digital Forensics and Cyber Crime. The topics include: Deep Learning Methods for Intrusion Detection Systems on the CSE-CIC-IDS2018 Dataset: A Review; CTIMiner: Cyber Threat Intelligence Mining Using Adaptive Multi-task Adversarial Active Learning; Toward Forensic-Friendly AI: Integrating Blockchain with Federated Learning to Enhance AI Trustworthiness; The Hidden Realms of Router Apps: Forensic Analysis of TP-Link Tether and ASUS Router; ENF Match with Masking: A New Method for Searching with Sparse Signal; Lightweight Multi-tier IDS for UAV Networks: Enhancing UAV Zero-Day Attack Detection with Honeypot Threat Intelligence; reducing False Positives in Intrusion Detection System Alerts: A Novel Aggregation and Correlation Model; APTChaser: Cyber Threat Attribution via Attack Technique Modeling; what Do We Know About the Psychology of Insider Threats?; a Digital Profiling Triage Model for Industrial Espionage; Uncovering Fraudulent Patterns in USDT Transactions on the TRON Blockchain with EDA and Machine Learning Techniques; sky-Eye: Detect Multi-stage Cyber Attacks at the Bigger Picture; ATKHunter: Towards Automated Attack Detection by Behavior Pattern Learning; Investigating the Effectiveness of Bayesian Spam Filters in Detecting LLM-Modified Spam Mails; secureSem: Sensitive Text Classification Based on Semantic Feature Optimization; The Hidden Dangers of Publicly Accessible LLMs: A Case Study on Gab AI; biologically Sustainable Cyber-Physical Spaces: A Systematic Literature Review; Detecting Criminal Networks via Non-content Communication Data Analysis Techniques from the TRACY Project.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Abdi, M.
AU  - Prasad, P.
AU  - Balhasan, S.
AU  - Abdalgader, K.
AU  - Abdelnabi, A.
AU  - Hamad, A.
AU  - Al Jazwe, A.B.
AU  - Magomadov, I.
AU  - Al-Homoud, L.
AU  - Marei, N.
AU  - Hassan, Z.
AU  - Nagy Fathy Mohamed Mahmoud, S.
AU  - Lyakhovskaya, V.
TI  - Securing the Future: Al-Driven Cybersecurity Solutions for Oil and Gas Industry
PY  - 2025
DO  - 10.2118/224469-MS
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007039154&doi=10.2118%2F224469-MS&partnerID=40&md5=8531c25976df800bb213c4908841381c
AB  - In the ever-evolving landscape of cyber threats, the oil and gas industry face increasing challenges in safeguarding its critical infrastructure. This paper explores the multifaceted application of artificial intelligence (AI) to enhance cybersecurity measures within this sector. The primary objective is to improve threat detection, risk management, and response strategies, thereby fortifying defenses against sophisticated cyber-attacks. The scope encompasses examining various AI technologies, their real-world implementations, and their potential impact on the industry's cybersecurity posture. A comprehensive approach is employed, integrating machine learning algorithms, predictive analytics, and anomaly detection techniques. Data from numerous cybersecurity incidents within the oil and gas sector are utilized to train and test AI models. The process includes developing AI-driven tools for real-time threat detection and response, implementing advanced encryption methods to protect data integrity, and conducting behavioral analysis to identify potential insider threats. Furthermore, the study validates the effectiveness and reliability of proposed AI solutions through case studies and simulations, addressing the unique challenges of the oil and gas industry. Results indicate significant improvements in threat detection, risk management, and response strategies. AI models demonstrate high accuracy in anomaly detection, reducing false positives, and enabling quicker, more effective responses. Predictive analytics provide valuable insights into potential threats, allowing proactive measures to mitigate risks. Advanced encryption techniques ensure data integrity and confidentiality, while behavioral analysis offers critical insights into insider threats. Case studies highlight the practical benefits of AI-driven cybersecurity tools, enhancing the resilience and robustness of critical infrastructure. This paper presents novel AI-driven methodologies, significantly enhancing existing cybersecurity frameworks and contributing valuable solutions to mitigate cyber risks, protect vital assets, and ensure the operational integrity of critical infrastructure within the petroleum industry. © 2025, Society of Petroleum Engineers.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
TI  - 15th EAI International Conference on Digital Forensics and Cyber Crime, ICDF2C 2024
PY  - 2025
T2  - Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST
VL  - 613 LNICST
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006896036&partnerID=40&md5=48e5f16dcf65a61c320fcf744cd11689
AB  - The proceedings contain 40 papers. The special focus in this conference is on Digital Forensics and Cyber Crime. The topics include: Deep Learning Methods for Intrusion Detection Systems on the CSE-CIC-IDS2018 Dataset: A Review; CTIMiner: Cyber Threat Intelligence Mining Using Adaptive Multi-task Adversarial Active Learning; Toward Forensic-Friendly AI: Integrating Blockchain with Federated Learning to Enhance AI Trustworthiness; The Hidden Realms of Router Apps: Forensic Analysis of TP-Link Tether and ASUS Router; ENF Match with Masking: A New Method for Searching with Sparse Signal; Lightweight Multi-tier IDS for UAV Networks: Enhancing UAV Zero-Day Attack Detection with Honeypot Threat Intelligence; reducing False Positives in Intrusion Detection System Alerts: A Novel Aggregation and Correlation Model; APTChaser: Cyber Threat Attribution via Attack Technique Modeling; what Do We Know About the Psychology of Insider Threats?; a Digital Profiling Triage Model for Industrial Espionage; Uncovering Fraudulent Patterns in USDT Transactions on the TRON Blockchain with EDA and Machine Learning Techniques; sky-Eye: Detect Multi-stage Cyber Attacks at the Bigger Picture; ATKHunter: Towards Automated Attack Detection by Behavior Pattern Learning; Investigating the Effectiveness of Bayesian Spam Filters in Detecting LLM-Modified Spam Mails; secureSem: Sensitive Text Classification Based on Semantic Feature Optimization; The Hidden Dangers of Publicly Accessible LLMs: A Case Study on Gab AI; biologically Sustainable Cyber-Physical Spaces: A Systematic Literature Review; Detecting Criminal Networks via Non-content Communication Data Analysis Techniques from the TRACY Project.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Huralnyk, O.
AU  - Kwiecień, A.
AU  - Paiuk, V.
AU  - Klein, O.
AU  - Lyhun, O.
TI  - Method and Means of Critical Information Processing in Corporate Networks
PY  - 2025
T2  - CEUR Workshop Proceedings
VL  - 3963
SP  - 314
EP  - 328
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006422747&partnerID=40&md5=598e3b6190dd6554756689c23a3556d2
AB  - The article studies modern methods and means of processing critical information in corporate networks. Since the growth of data volumes increases the risk of data breaches, the main causes of such incidents are analyzed, in particular, unintentional personnel errors (misdelivery, misconfiguration) and abuse of privileges by insiders. Data Loss Prevention (DLP) technologies are considered as a key mechanism for data protection, including detection, monitoring, prevention and audit of information flows. A comparative analysis of different models of DLP systems (centralized, distributed, hybrid) and their application in the corporate environment has been carried out. Particular attention is paid to commercial solutions from leading manufacturers, their capabilities, advantages and disadvantages. The article focuses on the current challenges of DLP systems, such as the high frequency of false positives, limited capabilities for analyzing encrypted traffic, difficulties in detecting insider threats, and scalability issues. A review of recent research demonstrates promising approaches combining anomaly analysis, machine learning, attribute-based encryption (CP-ABE), and Zero Trust principles. The article discusses the peculiarities of using botnets to steal critical information in corporate networks. A solution for protecting information in case of botnet activity is proposed, based on the integration of data leakage prevention systems (DLP) - a module specially configured to neutralize botnet threats. The results of the study indicate the need for an integrated approach to information security, which includes a combination of technological, organizational and legal measures. This will significantly reduce the risks of data leakage and ensure reliable protection of critical information in the face of modern cyber threats. © 2025 Copyright for this paper by its authors.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Amod Agarkar, A.
AU  - Karyakarte, M.
AU  - Kulkarni, R.V.
AU  - Baug, V.
AU  - Abhang, S.P.
AU  - Sule, B.
TI  - Assessing the impact of user behavior and insider threats on critical infrastructure
PY  - 2025
T2  - Information Security Journal
DO  - 10.1080/19393555.2025.2502553
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005507776&doi=10.1080%2F19393555.2025.2502553&partnerID=40&md5=4b7810a7ae027d09520e314e3da17902
AB  - As infrastructure systems become increasingly interconnected and industrialized, they are increasingly exposed to a wide range of cyberthreats, the most venomous of which are insider threats. This study focuses on the human dimension of critical infrastructure security and assesses vulnerabilities in complex systems due to user behavior and insider threats. The proposed framework employs state-of-the-art machine learning approaches and data-driven methodologies to analyze user and insider behavior signals via anonymized logs, incident reports and expert interviews. This framework detected insider threats with a 92% True Positive Rate (also known as the system’s detection accuracy), which is far superior to the existing systems’ 85% True Positive Rate. Additionally, the proposed approach generated a False Positive Rate of 10%, a 5% reduction from the existing frameworks. It decreased the detection time by 30%. The sector-specific analyses revealed differences in threat probabilities in each sector, with marginally improved (up to 15%) risk profiles for the healthcare sector. The study combined threat impact modeling, which assesses systemic impacts and cascade effects, with risk profiling to obtain an integrated framework composed of behavioral analytics, adaptive security measures and organizational policies. © 2025 Taylor & Francis Group, LLC.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - BOOK
AU  - Vajjhala, N.R.
AU  - Strang, K.D.
TI  - Cybersecurity in Knowledge Management: Cyberthreats and Solutions
PY  - 2025
SP  - 1
EP  - 215
DO  - 10.1201/9781003498094
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005049877&doi=10.1201%2F9781003498094&partnerID=40&md5=9193ae77c68745a723d89443b5c0f1dc
AB  - In an era where digital transformation is vital across industries, protecting knowledge and information assets has become critical. Cybersecurity in Knowledge Management: Cyberthreats and Solutions explores the intersection of knowledge management and cybersecurity, offering an in-depth examination of the strategies, technologies, and frameworks necessary to safeguard organizational knowledge systems. As cyber threats grow more sophisticated, particularly within sectors such as digital marketing, supply chains, and higher education, this book examines methods for enhancing cybersecurity while maintaining the agility needed to foster innovation. By incorporating perspectives from artificial intelligence, machine learning, and human factors, this work provides a holistic approach to securing knowledge in today’s interconnected landscape. This book includes an analysis of AI and machine learning applications for cybersecurity, a comparative review of malware classification techniques, and real-world case studies illustrating cybersecurity breaches and insider threats affecting knowledge ecosystems. This book addresses unique challenges within the African digital space, explores social engineering tactics, and emphasizes the role of organizational culture in maintaining knowledge security. Key topics include cybersecurity requirements in digital marketing, the post-COVID impact on knowledge transfer in higher education, and the importance of regulatory compliance and cross-industry collaboration. With its multidisciplinary perspective, Cybersecurity in Knowledge Management: Cyberthreats and Solutions is ideal for professionals, researchers, and policymakers. This comprehensive guide equips readers with the insights needed to build resilient cybersecurity programs that protect essential knowledge assets, enabling organizations to meet today’s cybersecurity demands while maintaining a sustainable competitive advantage in an evolving digital environment. © 2025 selection and editorial matter, Narasimha Rao Vajjhala and Kenneth David Strang; individual chapters, the contributors.
M3  - Book
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Anju, A.
AU  - Adline Freeda, A.
AU  - Krithikaa Venket, K.
AU  - Kurian, B.
AU  - Sudha, D.
AU  - Mercy, W.
TI  - An Ensemble Method for Insider Threat Detection Based on User Activities Analysis Using Bi-LSTM and GA Optimization
PY  - 2025
T2  - Communications in Computer and Information Science
VL  - 2429 CCIS
SP  - 80
EP  - 87
DO  - 10.1007/978-3-031-86305-9_7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003910105&doi=10.1007%2F978-3-031-86305-9_7&partnerID=40&md5=843c385a7d892d981a3e2da548e96640
AB  - One of the main reasons why firms experience security breaches is insider threats. They are users or workers of an organization who carry out any malicious conduct with the intention of harming others. The majority of insider threat detection techniques currently in use depend on deep learning and machine learning techniques and have the following drawbacks: they need obvious feature engineering, which increases the number of false positives; they rely on established criteria or maintained patterns and fail to detect novel or unidentified threats they are highly computational and need a large amount of training data. For an improved client behavior-based insider threat identification system, this study proposes an integrated learning strategy to overcome the aforementioned limitations. An ensemble model Bidirectional long-short-term memory and uses a CNN, ANN with GA and Meta Learner also used to find the best solution by combining all models predictions. The first kernel selection for CNN is done using the fast global search method of the genetic algorithm. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Sridhar, A.P.
TI  - Unauthorized Deep Learning Techniques for Identifying Insider Risks in Standardized Cybersecurity Databases
PY  - 2025
SP  - 1178
EP  - 1183
DO  - 10.1109/IC363308.2025.10957272
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003905714&doi=10.1109%2FIC363308.2025.10957272&partnerID=40&md5=e682a50df424532aaf4aafdb0de60641
AB  - Analyzing computer organize movement is vital for numerous firms to reveal insider dangers early on. Crude framework logs are a classic case of this kind of spilling information, and it may grow much quicker than a human analyst's cognitive capacity. This article presents a one-of-a-kind online profound learning strategy for real-time, unsupervised distinguishing proof of abnormal arrange behaviour from framework logs. To assist investigators, survey conceivable illustrations of insider risk, our models increment interpretability by breaking down the irregularity scores into the commitments of specific client behaviour viewpoints. In terms of risk discovery review, our one-of-a-kind profound and repetitive neural arrange models beat inconsistency location baselines based on PCA, SVM, and Confinement Timberlands on the CERT Insider Danger Dataset form 6.2. The occasions classified as insider risk action for our best demonstrate had an average peculiarity score within the dataset's 95.53 percentile, illustrating how much our strategy can help analysts' workloads. One of the greatest concerns with cybersecurity security is insider assaults, and unused challenges are continuously coming up. The approaches utilized to handle these issues are regularly based on customary rule-based frameworks, which require labelled information and are not exceptionally flexible against the attack's ever-changing strategies. Profound learning could be a utilitarian special case to this generalization. It leverages the inalienable structure and complexity of cybersecurity information to distinguish unobtrusive peculiarities that in the long run point to malevolent behaviour on its claim, in this manner opening up modern roads for unsupervised insider danger location. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Sonekar, S.V.
AU  - Kshirsagar, P.R.
AU  - Unhelkar, B.
AU  - Chakrabarti, P.
AU  - Maram, B.
AU  - Upreti, K.
TI  - An Algorithmic Approach to Intrusion Detection in Ad Hoc Wireless Networks Based on Artificial Intelligence
PY  - 2025
SP  - 1357
EP  - 1361
DO  - 10.1109/IC363308.2025.10956232
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003901880&doi=10.1109%2FIC363308.2025.10956232&partnerID=40&md5=581b39352dc0b5200f60af0a4dcfb82a
AB  - The self-configured, autonomous, and framework-free modes of communication that mobile adhoc networks (MANETs) offer have revolutionized our culture. As a result, efforts have been made to explore ways to maximize the potential of MANETs through increased and improved utilization. Standards for AI have been developed thanks to the most recent release of new machine learning technologies. Different security-related issues from malware assaults affect mobile ad hoc networks (MANETs). Any node operates as a router to move data without centralized control, making nodes more vulnerable to threats from other nodes or attackers because of their brief existence. Because of this, MANET needs particular security policies to detect the incorrect entrance of misbehaving nodes. If all nodes are self-assured and correctly collaborate, the networks function better. The paper presents a practical artificial intelligence algorithm-based security system that uses AdaBoost and DT algorithms to recognize and identify packet falling nodes, classify information packets as normal or abnormal, and detect insider threats in real-time. The results showed that DT performed better than AdaBoost, with a 98% accurate prediction rate. Consequently, DT is better able to recognize damaging attacks in MANETs. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Ilampiray, P.
AU  - Thanga Ramya, S.T.
TI  - A-DSCNet: Implementing Attention-based Deep Serial Cascaded Network for Predicting Insider Threats using Human Behaviors
PY  - 2025
SP  - 1819
EP  - 1829
DO  - 10.1109/ICEARS64219.2025.10940183
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002722635&doi=10.1109%2FICEARS64219.2025.10940183&partnerID=40&md5=e0f0cc795b9eaae500ef8edd83b10e24
AB  - Insider threats are considered a major issue in the field of system engineering. For modern applications, which demand a seamless integration among humans and machines, human interactions along with the applications are assumed as a significant phase of operation. It generates security issues within the network while safeguarding the network from insider threats. Due to the development of technologies, vulnerabilities within the networks and third-party access from the external environment remain the primary keys for security issues. Among other security threats, insider attacks are similarly challenging as exterior threats. However, insider attacks are unrecognized for a long period, and currently no effective measures to address the security issues as well as to safeguard the network from insider threats. The primary issue faced by the current technology is to detect insider attacks within the cloud. If the information in the system gets lost, then negotiating with the cloud consumers becomes hard. Moreover, cloud networks are less trusted as they lack to guarantee of security and privacy to the data. Currently, various solutions are presented to ensure external privacy for cloud systems. Yet, the challenges due to internal or insider threats must be tackled. Thus, it is crucial to address various problems produced by the traditional insider threat detection model including human actions. So, a novel deep learning-based insider threat prediction model using human behavior is suggested here. Initially, insider thread prediction data utilized for the validation are collected from benchmark resources. Next, the collected data is provided for the insider threats prediction phase. In the insider threats prediction phase, a developed Attention-based Deep Serial Cascaded Network (A-DSCNet) is used to identify the insider threats. The developed A-DSCNet is the integrated version of Deep Belief Network (DBN) and Capsule Network (CapsNet). Finally, various analyses are executed to verify the effectualness of the recommended insider threats prediction framework over classical models. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Nair, S.S.
AU  - Lakshmikanthan, G.
AU  - Parthasarathy, J.
AU  - Dinesh, P.S.
AU  - Shanmugakani, K.
AU  - Jegajothi, B.
TI  - Enhancing Cloud Security with Machine Learning: Tackling Data Breaches and Insider Threats
PY  - 2025
SP  - 912
EP  - 917
DO  - 10.1109/ICEARS64219.2025.10940401
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002709042&doi=10.1109%2FICEARS64219.2025.10940401&partnerID=40&md5=11cee734c0e76fd0f91dabdc2b81edb7
AB  - Cloud computing remains susceptible to internal threats and data compromises, notwithstanding its foundational role in contemporary business operations within this age of automation. To mitigate this concern, a machine learning framework is suggested for the preemption of prospective threats. Most, breaches of organizational internal systems are concerns about user non-compliant behaviors aimed at messing up activity logs, which can be combatted using supervised models and change detection. There seems to be a class of threats that go undetected that the authors would refer to as behaviour patterns that do not follow standard operating behaviour for business. An interface of RF and LSTMs would be able to establish common patterns and knit rule-based threats to create business insights and acceptable threats. User and System exhaustion of RF was used to minimise covert system identifiers of users to examine access pattern data streams, which were unlimited in dimensional centers. Evaluation of detection of anomalous content, such as R- scoring, classification of log events as generic clustering, etc. It could prevail on the challenges of log records analysis and the checkpoints of Structural Semantic Communication principles. It can free up a range of security checkpoints by glaring at user access limits and ensuring multi-channel compliance. This approach would significantly strengthen data security on the Cloud by targeting high-risk actions across oriented sections of breaching data storage centers. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Huang, Z.
AU  - Li, X.
AU  - Cao, X.
AU  - Chen, K.
AU  - Wang, L.
AU  - Bo-Yee Liu, L.
TI  - IDU-Detector: A Synergistic Framework for Robust Masquerader Attack Detection
PY  - 2025
T2  - IEEE Internet of Things Journal
VL  - 12
IS  - 8
SP  - 9653
EP  - 9670
DO  - 10.1109/JIOT.2024.3503057
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002571586&doi=10.1109%2FJIOT.2024.3503057&partnerID=40&md5=8141482f0f2fa5c98425067143ab360d
AB  - In the current digital age, users store their personal information in corporate databases to access services, making data security and sensitive information protection central to enterprise security management. Given the extensive attack surface, system assets continuously face cyber security challenges, such as weak authentication, exploitation of system vulnerabilities, and malicious software. Through specific vulnerabilities, attackers may gain unauthorized system access, masquerading as legitimate users, and remaining hidden. Successful attacks can lead to the leakage of user privacy, disruption of business operations, significant financial losses, and damage to corporate reputation. The increasing complexity of attack vectors is blurring the boundaries between insider and external threats. To address this issue, this article introduces the IDU-Detector, an innovative threat detection framework that strategically integrates intrusion detection systems (IDSs) with user and entity behavior analytics (UEBA). This integration aims to monitor unauthorized access and malicious attacks within systems, bridging functional gaps between existing systems, ensuring continuous monitoring and real-time response of the network environment, and enhancing their collective effectiveness in identifying security threats. Additionally, the existing insider threat datasets exhibit significant deficiencies in both depth and comprehensiveness, lacking sufficient coverage of diverse attack vectors. This limitation hinders the ability of insider threat detection technologies to effectively address the growing complexity and expanding scope of sophisticated attack surfaces. To address these gaps, we propose new, more enriched and diverse datasets that includes a wider range of attack scenarios, thereby enhancing the adaptability and effectiveness of detection technologies in complex threat environments. We tested our framework on different datasets, the IDU-Detector achieved average accuracy rates of 98.96% and 99.12%. These results demonstrate the method’s effectiveness in detecting masquerader attacks and other malicious activities, significantly improving security protection and incident response speed, and providing a higher level of security assurance for asset safety. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Nasiruzzaman, M.
AU  - Ali, M.
AU  - Salam, I.
AU  - Miraz, M.H.
TI  - The Evolution of Zero Trust Architecture (ZTA) from Concept to Implementation
PY  - 2025
DO  - 10.1109/IT64745.2025.10930254
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001864259&doi=10.1109%2FIT64745.2025.10930254&partnerID=40&md5=bd4bf3cb99a8bc1a6f24698594fa867e
AB  - Zero Trust Architecture (ZTA) is one of the paradigm changes in cybersecurity, from the traditional perimeter-based model to perimeterless. This article studies the core concepts of ZTA, its beginning, a few use cases and future trends. Emphasising the always-verify and least privilege access, some key tenets of ZTA have grown to be integration technologies like Identity Management, Multi-Factor Authentication (MFA) and real-time analytics. ZTA is expected to strengthen cloud environments, education, work environments (including from home) while controlling other risks like lateral movement and insider threats. Despite ZTA's benefits, it comes with challenges in the form of complexity, performance overhead and vulnerabilities in the control plane. These require phased implementation and continuous refinement to keep up with evolving organisational needs and threat landscapes. Emerging technologies, such as Artificial Intelligence (AI) and Machine Learning (ML) will further automate policy enforcement and threat detection in keeping up with dynamic cyber threats. © 2025 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Sheik Abdullah, A.
AU  - Dhiman, S.
AU  - Ansari, A.
TI  - A Robust Model for Enabling Insider Threat Detection and Prevention: Techniques, Tools, and Applications
PY  - 2025
SP  - 133
EP  - 168
DO  - 10.1002/9781394268917.ch7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001271422&doi=10.1002%2F9781394268917.ch7&partnerID=40&md5=d5c2bc2725f1d82d71d3cb6959765d7c
AB  - In today’s era, cybersecurity is essential as data breaches and cyber-attacks become more prevalent. Insider threats, which are security risks from within an organization, involve employees or contractors who possess access to information and exploit it to harm the organization. Simultaneously, new methods and technologies are emerging that leverage tools like machine learning, artificial intelligence, and behavioral analytics to identify and mitigate insider threats accurately. As technology advances rapidly, malware also evolves in sophistication. This challenges cybersecurity professionals who strive to keep up with the changing landscape. Modern malware utilizes techniques, such as polymorphism and metamorphism, enabling it to modify its code to evade detection by traditional antivirus programs. Consequently, detecting and removing malware from compromised systems has become increasingly difficult for security experts. We can evolve these measures into more robust threat detection and prevention tools. This will enable us to better protect against potential security breaches and ensure the safety and security of our systems and data. © 2025 Scrivener Publishing LLC.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Yilmaz, S.
AU  - Şen, S.
AU  - Aydogan, E.
TI  - Exploring and Enhancing Placement of IDS in RPL: A Federated Learning-Based Approach
PY  - 2025
T2  - IEEE Internet of Things Journal
VL  - 12
IS  - 13
SP  - 22945
EP  - 22961
DO  - 10.1109/JIOT.2025.3553194
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000681738&doi=10.1109%2FJIOT.2025.3553194&partnerID=40&md5=ede2d4925508274be3322d58cedcdff7
AB  - In routing protocol for low power and lossy networks (RPL) security, intrusion detection (ID) plays a vital role, especially given its susceptibility to attacks, particularly those carried out by insider threats. While numerous studies in the literature have proposed ID systems (IDSs) utilizing diverse techniques, the placement of such systems within RPL topology remains largely unexplored. This study aims to address this gap by rigorously evaluating three ID architectures, considering central and distributed placement, across multiple criteria, including effectiveness, cost, privacy, and security. The findings underscore the significant impact of attacker position and the proximity of IDS to attackers on detection outcomes. Hence, alongside the evaluation of traditional ID architectures, this study explores the use of federated learning (FL) for improving ID within RPL networks. FL’s decentralized model training approach effectively addresses the impact of attacker position on IDS performance by ensuring the collection of relevant information from nodes regardless of their proximity to potential attackers. Moreover, this approach not only mitigates security concerns but also minimizes communication overhead among ID nodes. Consequently, FL reduces the need for extensive data transfer, thus mitigating the impact of packet loss and latency inherent in lossy networks. Additionally, the study investigates the effect of local data sharing on FL performance, clarifying the balance between effectiveness and security. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Besnaci, S.
AU  - Hafidi, M.
AU  - Lamia, M.
TI  - Behavior-Based Insider Threat Detection Using a Deep Neural Network
PY  - 2025
T2  - Communications in Computer and Information Science
VL  - 2305 CCIS
SP  - 189
EP  - 202
DO  - 10.1007/978-3-031-82156-1_15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000624536&doi=10.1007%2F978-3-031-82156-1_15&partnerID=40&md5=bf2772df0056e7e119ca011ee6f8e644
AB  - One of the toughest cybersecurity issues today are insider threats for which no good solution has been provided to limit their damage through commonly used security solutions. Which could cause serious damage to the assets of the organization. This article begins by presenting a comprehensive multidisciplinary survey of insider threats and the various AI technologies in use. Then, we proposed a method to detect internal threats by analyzing user behavior. A series of activities and events that are analyzed to extract features to effectively detect malicious activity from normal activity. The selected feature vectors are used to train the model. The convolutional neural network (CNN) is used during the implementation phase to detect insider threats of fixed-size feature vectors. The data used to conduct the experiments is public data related to internal threats cert r4.2. The experimental results of the proposed model show that it can successfully detect insider threats with an accuracy of 0.9558 in the best cases. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Hajdarevic, K.
TI  - Revolutionizing Vault Security with Smart IoT, Weight Analytics and Machine Learning
PY  - 2025
T2  - TEM Journal
VL  - 14
IS  - 1
SP  - 18
EP  - 27
DO  - 10.18421/TEM141-02
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000183129&doi=10.18421%2FTEM141-02&partnerID=40&md5=2499afac25c4eaf66f7a8ae66690fcdb
AB  - The persistent use of physical money, despite the rise of digital payment methods, poses security challenges for vaults storing banknotes and coins. Traditional vault security measures, including physical barriers, time locks, dual control systems, and surveillance, are susceptible to sophisticated attacks and insider threats. This paper introduces a novel approach to enhance vault security by incorporating smart Internet of Things (IoT) devices and machine learning algorithms to monitor the weight of banknotes on vault shelves. By tracking and analysing weight variations, this system aims to detect discrepancies and potential theft. The system employs various machine learning models, including Linear Regression, Lasso Regression, K-Nearest Neighbors (KNN), Support Vector Machines (SVM), and Random Forest, to predict the number of banknotes based on weight and denomination. The evaluation demonstrates that Linear Regression and Lasso Regression achieve the highest accuracy, making them the most effective models for this application. Challenges such as limited data, computational resource constraints, and the need for more refined features are discussed, alongside potential improvements like data augmentation and enhanced interpretability. This approach offers a significant advancement in vault security by integrating modern technology to safeguard physical money against theft and unauthorized access. © (2025), (UIKTEN - Association for Information Communication Technology Education and Science). All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Dahiya, P.
AU  - Kumar, V.
TI  - An Optimized Multi-kernel Based Extreme Learning Machine for Authentication Threat Detection with Feature Reduction Scheme in IoT
PY  - 2024
T2  - Wireless Personal Communications
VL  - 139
IS  - 3
C7  - 103106
SP  - 1451
EP  - 1475
DO  - 10.1007/s11277-024-11669-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212977939&doi=10.1007%2Fs11277-024-11669-0&partnerID=40&md5=4b4bbf99166df687a68d20022c8b2d85
AB  - Internet of Things (IoT) refers to a network of interconnected objects, computer systems, and physical or mechanical devices that are capable of sending and receiving data over a network without the intervention of a human. A growing number of undesirable security issues are occurring as a result of the rapid advancements in IoT infrastructures. IoT devices are therefore becoming more vulnerable to security threats and network attacks. IoT services and innovative ecosystem devices can be severely damaged as a result of these attacks and issues. So we propose a multi-kernel-based intensive learning machine model to improve security and overcome the above challenges. To enhance the performance of the insider threat detection model, significant feature sets are generated using correlation coefficient, random forest mean (RFM) reduction accuracy, and gain ratio. To obtain an optimal feature set, the features are combined using an appropriate mechanism (AND function). Afterward, the combined feature set is fed into a machine-learning model based on multi-kernel optimization (MKELM). MKELM is optimized using the Adaptive Crocodile Optimization Algorithm (ACOA) to increase its performance in this detection model. Java is used for the implementation of this proposed approach. In order to analyze performance, NSL-KDD 99 dataset and UNSW-NB15 dataset have been used. The performance of the proposed scheme is evaluated in terms of detection rate, precision, accuracy, recall, F-measure, and detection rate. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Tabassum, M.
AU  - Mahmood, S.
AU  - Bukhari, A.
AU  - Alshemaimri, B.
AU  - Daud, A.
AU  - Khalique, F.
TI  - Anomaly-based threat detection in smart health using machine learning
PY  - 2024
T2  - BMC Medical Informatics and Decision Making
VL  - 24
IS  - 1
C7  - 347
DO  - 10.1186/s12911-024-02760-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209683002&doi=10.1186%2Fs12911-024-02760-4&partnerID=40&md5=8f5d1b115bd44e07e07df3450c33f7be
AB  - Background: Anomaly detection is crucial in healthcare data due to challenges associated with the integration of smart technologies and healthcare. Anomaly in electronic health record can be associated with an insider trying to access and manipulate the data. This article focuses around the anomalies under different contexts. Methodology: This research has proposed methodology to secure Electronic Health Records (EHRs) within a complex environment. We have employed a systematic approach encompassing data preprocessing, labeling, modeling, and evaluation. Anomalies are not labelled thus a mechanism is required that predicts them with greater accuracy and less false positive results. This research utilized unsupervised machine learning algorithms that includes Isolation Forest and Local Outlier Factor clustering algorithms. By calculating anomaly scores and validating clustering through metrics like the Silhouette Score and Dunn Score, we enhanced the capacity to secure sensitive healthcare data evolving digital threats. Three variations of Isolation Forest (IForest)models (SVM, Decision Tree, and Random Forest) and three variations of Local Outlier Factor (LOF) models (SVM, Decision Tree, and Random Forest) are evaluated based on accuracy, sensitivity, specificity, and F1 Score. Results: Isolation Forest SVM achieves the highest accuracy of 99.21%, high sensitivity (99.75%) and specificity (99.32%), and a commendable F1 Score of 98.72%. The Isolation Forest Decision Tree also performs well with an accuracy of 98.92% and an F1 Score of 99.35%. However, the Isolation Forest Random Forest exhibits lower specificity (72.84%) than the other models. Conclusion: The experimental results reveal that Isolation Forest SVM emerges as the top performer showcasing the effectiveness of these models in anomaly detection tasks. The proposed methodology utilizing isolation forest and SVM produced better results by detecting anomalies with less false positives in this specific EHR of a hospital in North England. Furthermore the proposal is also able to identify new contextual anomalies that were not identified in the baseline methodology. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 24
ER  -

TY  - JOUR
AU  - Al-Shehari, T.
AU  - Kadrie, M.
AU  - Al-Mhiqani, M.N.
AU  - Alfakih, T.
AU  - AlSalman, H.
AU  - Uddin, M.
AU  - Sajid Ullah, S.S.
AU  - Dandoush, A.
TI  - Comparative evaluation of data imbalance addressing techniques for CNN-based insider threat detection
PY  - 2024
T2  - Scientific Reports
VL  - 14
IS  - 1
C7  - 24715
DO  - 10.1038/s41598-024-73510-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206962382&doi=10.1038%2Fs41598-024-73510-9&partnerID=40&md5=0290f8f4fb6ac4987e948556e85f7b27
AB  - Insider threats pose a significant challenge in cybersecurity, demanding advanced detection methods for effective risk mitigation. This paper presents a comparative evaluation of data imbalance addressing techniques for CNN-based insider threat detection. Specifically, we integrate Convolutional Neural Networks (CNN) with three popular data imbalance addressing techniques: Synthetic Minority Over-sampling Technique (SMOTE), Borderline-SMOTE, and Adaptive Synthetic Sampling (ADASYN). The objective is to enhance insider threat detection accuracy and robustness in imbalanced datasets common to cybersecurity domains. Our study addresses the lack of consensus in the literature regarding the superiority of data imbalance addressing techniques in this field. We analyze a human behavior-based dataset (i.e., CERT) that reports users’ Information Technology (IT) activities with a substantial number of samples to provide a clear conclusion on the effectiveness of these balancing techniques when coupled with CNN. Experimental results demonstrate that ADASYN, in conjunction with CNN, achieves a ROC curve of 96%, surpassing SMOTE and Borderline-SMOTE in enhancing detection accuracy in imbalanced datasets. We compare the results of these three hybrid models (CNN + imbalance addressing techniques) with state-of-the-art selective studies focusing on ROC, recall, and accuracy measures. Our findings contribute to the advancement of insider threat detection methodologies. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 10
ER  -

TY  - JOUR
AU  - Jaiswal, A.
AU  - Dwivedi, P.
AU  - Dewang, R.K.
TI  - Handling imbalance dataset issue in insider threat detection using machine learning methods
PY  - 2024
T2  - Computers and Electrical Engineering
VL  - 120
C7  - 109726
DO  - 10.1016/j.compeleceng.2024.109726
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205314377&doi=10.1016%2Fj.compeleceng.2024.109726&partnerID=40&md5=2187ab56ded2e6b9726c2a5693abee45
AB  - Insider threats, characterized by their baleful impact and substantial costs, arise from internal factors within organizations. These threats are rare and usually unnoticed, as the malicious actions are often submerged in numerous normal activities, causing dataset imbalance and making detection hard. To address these challenges, in this paper we propose a Two-Step Insider Threat Detection (TSITD) approach. First, it preprocesses the CERT r4.2 and r5.2 datasets into day-long sequences. Second, it handles the dataset imbalance and detects threats by forming various combinations of sampling techniques and classifiers, referred to as TSITD models. When we compare these TSITD models to baseline models, we observe a significant improvement in anomaly detection rate and balanced accuracy. The TSITD models also achieve higher rankings when evaluated using the Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) method. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Gong, Y.
AU  - Cui, S.
AU  - Liu, S.
AU  - Jiang, B.
AU  - Dong, C.
AU  - Lu, Z.
TI  - Graph-based insider threat detection: A survey
PY  - 2024
T2  - Computer Networks
VL  - 254
C7  - 110757
DO  - 10.1016/j.comnet.2024.110757
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203201619&doi=10.1016%2Fj.comnet.2024.110757&partnerID=40&md5=4b106b620fb404a0b1f466b060543edd
AB  - Insider threat detection has been a significant topic in recent years. However, as network technology develops, the intranet becomes more complex. Therefore, simply matching attack patterns or using traditional machine learning methods (Logistic Regression, Gaussian-NB, Random Forest, etc.) does not work well. On the other hand, the graph structure can better adapt to intranet data, thus graph-based insider threat detection methods have become mainstream. In order to study the design and effectiveness of graph-based insider threat detection, in this paper, we conduct a systematic and comprehensive survey of existing related research. Specifically, we provide a framework and a taxonomy based on the detection process, classifying existing work from three aspects: data collection, graph construction, and graph anomaly detection. We conduct a quantitative analysis of existing representative graph methods and find that the models with more information have better performance. In particular, we discuss the scalability of existing methods to large-scale networks and their feasibility in real environments. Based on the survey results, we propose 7 pain points in this field and provide specific future research directions. Our survey will provide future researchers with a complete solution. © 2024 Elsevier B.V.
M3  - Short survey
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Wei, Z.
AU  - Rauf, U.
AU  - Mohsen, F.
TI  - E-Watcher: insider threat monitoring and detection for enhanced security
PY  - 2024
T2  - Annales des Telecommunications/Annals of Telecommunications
VL  - 79
IS  - 11-12
SP  - 819
EP  - 831
DO  - 10.1007/s12243-024-01023-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189532048&doi=10.1007%2Fs12243-024-01023-7&partnerID=40&md5=7fb17cf5b15b0c1bd79053687aa5e818
AB  - Insider threats refer to harmful actions carried out by authorized users within an organization, posing the most damaging risks. The increasing number of these threats has revealed the inadequacy of traditional methods for detecting and mitigating insider threats. These existing approaches lack the ability to analyze activity-related information in detail, resulting in delayed detection of malicious intent. Additionally, current methods lack advancements in addressing noisy datasets or unknown scenarios, leading to under-fitting or over-fitting of the models. To address these, our paper presents a hybrid insider threat detection framework. We not only enhance prediction accuracy by incorporating a layer of statistical criteria on top of machine learning-based classification but also present optimal parameters to address over/under-fitting of models. We evaluate the performance of our framework using a real-life threat test dataset (CERT r4.2) and compare it to existing methods on the same dataset (Glasser and Lindauer 2013). Our initial evaluation demonstrates that our proposed framework achieves an accuracy of 98.48% in detecting insider threats, surpassing the performance of most of the existing methods. Additionally, our framework effectively handles potential bias and data imbalance issues that can arise in real-life scenarios. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 10
ER  -

TY  - JOUR
AU  - Song, S.
AU  - Gao, N.
AU  - Zhang, Y.
AU  - Ma, C.
TI  - BRITD: behavior rhythm insider threat detection with time awareness and user adaptation
PY  - 2024
T2  - Cybersecurity
VL  - 7
IS  - 1
C7  - 2
DO  - 10.1186/s42400-023-00190-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181041413&doi=10.1186%2Fs42400-023-00190-9&partnerID=40&md5=b3649a24531887e3bcd4a36cb22b906c
AB  - Researchers usually detect insider threats by analyzing user behavior. The time information of user behavior is an important concern in internal threat detection. Existing works on insider threat detection fail to make full use of the time information, which leads to their poor detection performance. In this paper, we propose a novel behavioral feature extraction scheme: we implicitly encode absolute time information in the behavioral feature sequences and use a feature sequence construction method taking covariance into account to make our scheme adaptive to users. We select Stacked Bidirectional LSTM and Feedforward Neural Network to build a deep learning-based insider threat detection model: Behavior Rhythm Insider Threat Detection (BRITD). BRITD is universally applicable to various insider threat scenarios, and it has good insider threat detection performance: it achieves an AUC of 0.9730 and a precision of 0.8072 with the CMU CERT dataset, which exceeds all baselines. Graphical Abstract: [Figure not available: see fulltext.] © 2024, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 16
ER  -

TY  - JOUR
AU  - El-Ghaish, H.
AU  - Miqrish, H.
AU  - Elmogy, A.
AU  - Elawady, W.
TI  - An adaptive nonlinear whale optimization multi-layer perceptron cyber intrusion detection framework
PY  - 2024
T2  - International Journal of Machine Learning and Cybernetics
VL  - 15
IS  - 10
SP  - 4801
EP  - 4814
DO  - 10.1007/s13042-024-02193-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192567359&doi=10.1007%2Fs13042-024-02193-5&partnerID=40&md5=0c9d9a95cff29841a58218506bab8254
AB  - The increasing prevalence of cyber threats has created a critical need for robust defense against such incidents. Many Cyber Intrusion Detection Systems (CIDSs), utilizing machine learning have been developed for this purpose. Although, these recent CIDSs have provided the capability to analyze vast amounts of data and identify malicious activities, there are still challenges to be tackled to enhance their effectiveness. The exponential growth of the search space is one of these challenges which makes finding an optimal solution computationally infeasible for large datasets. Furthermore, the weight space while searching for optimal weight is highly nonlinear. Motivated by the observed characteristics, complexities, and challenges in the field, this paper presents an innovative (CIDS) named ANWO-MLP (Adaptive Nonlinear Whale Optimization Multi-layer Perceptron). A novel feature selection method called ANWO-FS (Adaptive Nonlinear Whale Optimization-Feature Selection) is employed in the proposed CIDS to identify the most predictive features enabling robust MLP training even in the highly nonlinear weight spaces. The insider threat detection process is improved by investigating vital aspects of CIDS, including data processing, initiation, and output handling. We adopt ANWOA (previously proposed by us) to mitigate local stagnation, enable rapid convergence, optimize control parameters, and handle multiple objectives by initializing the weight vector in the ANWO-MLP training with minimal mean square error. Experiments conducted on three highly imbalanced datasets demonstrate an average efficacy rate of 98.33%. The details of the results below show the robustness, stability, and efficiency of the proposed ANWO-MLP compared to existing approaches. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 7
ER  -

TY  - JOUR
AU  - Tian, Z.
AU  - Shi, W.
AU  - Tan, Z.
AU  - Qiu, J.
AU  - Sun, Y.
AU  - Jiang, F.
AU  - Liu, Y.
TI  - Deep Learning and Dempster-Shafer Theory Based Insider Threat Detection
PY  - 2024
T2  - Mobile Networks and Applications
VL  - 29
IS  - 5
SP  - 1680
EP  - 1689
DO  - 10.1007/s11036-020-01656-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003230020&doi=10.1007%2Fs11036-020-01656-7&partnerID=40&md5=e95e891723b8b63bd027338db22fe820
AB  - Organizations’ own personnel now have a greater ability than ever before to misuse their access to critical organizational assets. Insider threat detection is a key component in identifying rare anomalies in context, which is a growing concern for many organizations. Existing perimeter security mechanisms are proving to be ineffective against insider threats. As a prospective filter for the human analysts, a new deep learning based insider threat detection method that uses the Dempster-Shafer theory is proposed to handle both accidental as well as intentional insider threats via organization’s channels of communication in real time. The long short-term memory (LSTM) architecture together with multi-head attention mechanism is applied in this work to detect anomalous network behavior patterns. Furthermore, belief is updated with Dempster’s conditional rule and utilized to fuse evidence to achieve enhanced prediction. The CERT Insider Threat Dataset v6.2 is used to train the behavior model. Through performance evaluation, our proposed method is proven to be effective as an insider threat detection technique. © Springer Science+Business Media, LLC, part of Springer Nature 2020.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - Asmar, M.
AU  - Tuqan, A.
TI  - Integrating machine learning for sustaining cybersecurity in digital banks
PY  - 2024
T2  - Heliyon
VL  - 10
IS  - 17
C7  - e37571
DO  - 10.1016/j.heliyon.2024.e37571
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203195089&doi=10.1016%2Fj.heliyon.2024.e37571&partnerID=40&md5=a9d8cafef9d1be6419ab17b64379d803
AB  - Cybersecurity continues to be an important concern for financial institutions given the technology's rapid development and increasing adoption of digital services. Effective safety measures must be adopted to safeguard sensitive financial data and protect clients from potential harm due to the rise in cyber threats that target digital organizations. The aim of this study is to investigates how machine learning algorithms are integrated into cyber security measures in the context of digital banking and its benefits and drawbacks. We initially provide a general overview of digital banks and the particular security concerns that differentiate them from conventional banks. Then, we explore the value of machine learning in strengthening cybersecurity defenses. We revealed that insider threats, distributed denial of service (DDoS) assaults, ransomware, phishing attacks, and social engineering are main cyberthreats that are digital banks exposed. We identify the appropriate machine learning algorithms such as support vector machines (SVM), recurrent neural networks (RNN), hidden markov models (HMM), and local outlier factor (LOF) that are used for detection and prevention cyberthreats. In addition, we provide a model that considers ethical concerns while constructing a cybersecurity framework to address potential vulnerabilities in digital banking systems. The advantages and disadvantages of incorporating machine learning into the cybersecurity strategy of digital banks are outlined using strengths, weaknesses, opportunities, threats (SWOT) analysis. This study seeks to provide a thorough knowledge of how machine learning may strengthen cybersecurity procedures, protect digital banks, and maintain customer trust in the ecosystem of digital banking. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 20
ER  -

TY  - JOUR
AU  - Deivakani, M.
AU  - Sahaya Sheela, M.S.
AU  - Priyadarsini, K.
AU  - Farhaoui, Y.
TI  - An intelligent security mechanism in mobile Ad-Hoc networks using precision probability genetic algorithms (PPGA) and deep learning technique (Stacked LSTM)
PY  - 2024
T2  - Sustainable Computing: Informatics and Systems
VL  - 43
C7  - 101021
DO  - 10.1016/j.suscom.2024.101021
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199567049&doi=10.1016%2Fj.suscom.2024.101021&partnerID=40&md5=c7b8c1040c3fa2b65de459771d64727a
AB  - The Mobile Ad-hoc Networks (MANETs) have gained a significant attention in the recent years due to their proliferation and huge application purposes. To defend from many types of modern cyber dangers like Distributed Denial of Service (DDoS) attacks, Advanced Persistent Threats (APTs), Insider Threats, Ransomware, Zero-Day Exploits, Social Engineering tactics, and etc is not easy when it comes to keeping MANETs security. These complex assaults focus on network infrastructure, take advantage of weaknesses in communication protocols and control user actions. Although there have been improvements in intrusion detection systems (IDS), it is still difficult to fully safeguard MANETs. The purpose of this research is to create advanced methods that can accurately find and decrease attacks inside MANETs. Applying Sensor-based Feature Extraction (SFE) to extract useful network features such as Received Signal Strength Indication (RSSI) and Time of Travel (TOT) from datasets NSL-KDD and CICIDS-2017. Utilizing the fresh method of Precise Probability Genetic Algorithm (PPGA) optimization for removing unrelated details, which enhances precision in detecting attacks. Predicting normal and attacking labels by applying Stacked Recurrent Long Short Term Memory (SRLSTM) method, fine-tuning classifier's parameters in every layer to improve outcomes. In order to authenticate and compare the suggested methods with current attack detection tactics, this study will make use of various evaluation measurements. The NSL-KDD, which is a benchmark dataset in network intrusion detection research, has a wide variety of network traffic data with instances that are labeled as normal and different attacks. CICIDS-2017 is similar because it contains an extensive dataset too - this includes real-world traces from network traffic where there's both regular activity and harmful actions. The purpose is to enhance the existing status of MANET security so as it can withstand more strongly against cyber dangers. According to the outcomes, it is analyzed that the attack detection accuracy has improved greatly 99 % when compared to other methods, as shown by the detailed assessment measurements. Better handling of big datasets with top detection accuracy reduces the time needed 8.9 s for training and testing models. Decrease in misclassification results and better ability to differentiate normal network actions from harmful intrusions. Improved resistance of MANETs to different cyber dangers, guaranteeing the safety and dependability of network communication in changing and non-centralized settings. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 15
ER  -

TY  - JOUR
AU  - Gayathri, R.G.
AU  - Sajjanhar, A.
AU  - Xiang, Y.
TI  - Hybrid deep learning model using SPCAGAN augmentation for insider threat analysis
PY  - 2024
T2  - Expert Systems with Applications
VL  - 249
C7  - 123533
DO  - 10.1016/j.eswa.2024.123533
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186342892&doi=10.1016%2Fj.eswa.2024.123533&partnerID=40&md5=3496dfde04a56a78265774060dd86b0f
AB  - Cyberattacks from within an organization's trusted entities are known as insider threats. Anomaly detection using deep learning requires comprehensive data, but insider threat data is not readily available due to confidentiality concerns of organizations. Therefore, there arises demand to generate synthetic data to explore enhanced approaches for threat analysis. We propose a linear manifold learning-based generative adversarial network, SPCAGAN, that takes input from heterogeneous data sources and adds a novel loss function to train the generator to produce high-quality data that closely resembles the original data distribution. Furthermore, we introduce a deep learning-based hybrid model for insider threat analysis. We provide extensive experiments for data synthesis, anomaly detection, adversarial robustness, and synthetic data quality analysis using benchmark datasets. In this context, empirical comparisons show that GAN-based oversampling is competitive with numerous typical oversampling regimes. For synthetic data generation, our SPCAGAN model overcame the problem of mode collapse and converged faster than previous GAN models. Results demonstrate that our proposed approach has a lower error, is more accurate, and generates substantially superior synthetic insider threat data than previous models. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 14
ER  -

TY  - JOUR
AU  - Farouk, M.
AU  - Sakr, R.H.
AU  - Hikal, N.
TI  - Identifying the most accurate machine learning classification technique to detect network threats
PY  - 2024
T2  - Neural Computing and Applications
VL  - 36
IS  - 16
SP  - 8977
EP  - 8994
DO  - 10.1007/s00521-024-09562-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186588747&doi=10.1007%2Fs00521-024-09562-9&partnerID=40&md5=72c0759796f4c88cfaf3c222717c5dc5
AB  - Insider threats have recently become one of the most urgent cybersecurity challenges facing numerous businesses, such as public infrastructure companies, major federal agencies, and state and local governments. Our purpose is to find the most accurate machine learning (ML) model to detect insider attacks. In the realm of machine learning, the most convenient classifier is usually selected after further evaluation trials of candidate models which can cause unseen data (test data set) to leak into models and create bias. Accordingly, overfitting occurs because of frequent training of models and tuning hyperparameters; the models perform well on the training set while failing to generalize effectively to unseen data. The validation data set and hyperparameter tuning are utilized in this study to prevent the issues mentioned above and to choose the best model from our candidate models. Furthermore, our approach guarantees that the selected model does not memorize data of the threats occurring in the local area network (LAN) through the usage of the NSL-KDD data set. The following results are gathered and analyzed: support vector machine (SVM), decision tree (DT), logistic regression (LR), adaptive boost (AdaBoost), gradient boosting (GB), random forests (RFs), and extremely randomized trees (ERTs). After analyzing the findings, we conclude that the AdaBoost model is the most accurate, with a DoS of 99%, a probe of 99%, access of 96%, and privilege of 97%, as well as an AUC of 0.992 for DoS, 0.986 for probe, 0.952 for access, and 0.954 for privilege. © The Author(s) 2024.
M3  - Review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 5
ER  -

TY  - CHAP
AU  - Madhuri, P.S.
AU  - Amutha, B.
AU  - Kumar, D.J.N.
TI  - Fortifying machine learning, data privacy, and secure collaboration: Privacy-preserving machine learning
PY  - 2024
SP  - 172
EP  - 191
DO  - 10.4018/979-8-3693-4159-9.ch011
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196592283&doi=10.4018%2F979-8-3693-4159-9.ch011&partnerID=40&md5=e89b064064b0e4d7ae46b5ce0224680f
AB  - The utilitarianism of machine learning (ML) techniques introduces an additional layer of security to ML applications. In the domain of cybersecurity, ML continuously evolves by analyzing data to identify patterns, thus enhancing the capacity to detect malware in encrypted traffic, recognize insider threats, predict online "bad neighborhoods" for safer browsing, and protect cloud-stored data by uncovering suspicious user behavior. Simultaneously, privacy-preserving techniques, exemplified by homomorphic encryption and multi-party computation, empower the training of ML models on sensitive data without exposing the raw information. Privacy-preserving techniques, notably statistical disclosure control (SDC), benefit data sharing. SDC seeks to mitigate the risk of disclosing confidential information by employing privacy-preserving techniques for data de-identification. Research integrates privacy-preserving techniques into ML, advancing diverse PPML for secure data analysis in academia and industry. © 2024, IGI Global. All rights reserved.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Bhaware, A.
AU  - Varshney, G.
AU  - Kour, J.
AU  - Bishnoi, T.
AU  - Jain, M.
AU  - Sharma, D.
TI  - A Privacy Preserving Context Sensitive Kernel
PY  - 2024
SP  - 20
EP  - 25
DO  - 10.1145/3649403.3656483
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195962071&doi=10.1145%2F3649403.3656483&partnerID=40&md5=98ef1e7c624760c374ee2a120aaa4f23
AB  - Insider threats and attacks have witnessed a concerning rise in recent years, posing significant risks and financial implications for businesses. Malicious insiders exploit memory dumping tools to leak data, resulting in a substantial surge in data breach incidents. Evaluating the true extent of damage caused by insider attacks proves challenging, particularly in defence scenarios. This research presents a novel architecture designed to prevent data leaks by intercepting memory dump calls and generating privacy-preserved context-sensitive dumps. By ensuring that such dumps do not con- tain significant sensitive data, the architecture mitigates the risk of data leakage by malicious insiders. In this approach, unauthorized attempts to generate memory dumps using popular tools like ProcDump are directed to the proposed program, which creates privacy-preserving context-sensitive dumps, convincingly resembling legitimate memory dumps generated by the original tools. The prevention of sensitive data leaks is achieved while upholding organizational privacy through the utilization of a deep learning model. The attacker is deceived as the memory dump generated contains only non-sensitive user information in the device. The feasibility and effectiveness of this innovative approach are demonstrated through a military use case within the proposed architecture. © 2024 Owner/Author.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Anju, A.
AU  - Marudhamuthu, M.
TI  - M-EOS: modified-equilibrium optimization-based stacked CNN for insider threat detection
PY  - 2024
T2  - Wireless Networks
VL  - 30
IS  - 4
SP  - 2819
EP  - 2838
DO  - 10.1007/s11276-024-03678-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187175091&doi=10.1007%2Fs11276-024-03678-5&partnerID=40&md5=02fac2830b28e50bf634df095d8a2053
AB  - Insider threats remain a serious anxiety for organizations, government agencies, and businesses. Normally, the most hazardous cyber attacks are formed by trusted insiders and not by malicious outsiders. The malicious behaviors resulting from unplanned or planned mishandling of resources, data, networks, and systems of an organization constitute an insider threat. The unsupervised behavioral anomaly detection methods are mostly developed by the traditional machine learning methods for identifying unusual or anomalous variations in user behavior. The insider threat mainly originates from an individual inside the organization who is a current or former employee who has access to sensitive information about the organization. For achieving an improvement over traditional methods, the Stacked Convolutional Neural Network- Attentional Bi-directional Gated Recurrent Unit model is proposed in this paper to detect insider threats. The CNN-Attentional BiGRU model utilizes the user activity logs and user information for time-series classification. Using the log files, the temporal data representations, and weekly and daily numerical features from various sub-models of CNN are learned by the stacked generalization. Based on the chosen feature vectors, a model is trained on the CERT insider threat dataset. The stacked CNN is combined with the Attentional BiGRU model to incorporate more complex features of the user activity logs and user data during each convolution operation without raising network parameters. Thus the classification performance is improved with less complexity. The non-linear time control, chaos-based strategy, update rules, and opposite-based learning strategies are evaluated for generating the Modified-Equilibrium Optimization. The simulation outputs obtained by the model are 92.52% accuracy, 98% Precision, 95% Recall, and 96% F1-score. Thus, the proposed model has reached higher detection performance. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 7
ER  -

TY  - JOUR
AU  - He, Y.
AU  - Han, G.
AU  - Li, A.
AU  - Taleb, T.
AU  - Wang, C.
AU  - Yu, H.
TI  - A Federated Deep Reinforcement Learning-Based Trust Model in Underwater Acoustic Sensor Networks
PY  - 2024
T2  - IEEE Transactions on Mobile Computing
VL  - 23
IS  - 5
SP  - 5150
EP  - 5161
DO  - 10.1109/TMC.2023.3301825
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166769636&doi=10.1109%2FTMC.2023.3301825&partnerID=40&md5=6d7f62b6dc95799b07058d0fc01e6bd0
AB  - Underwater acoustic sensor networks (UASNs) have been widely deployed in many areas, such as marine ranching, naval applications, and marine disaster warning systems. The security of UASNs, particularly insider threats, is of growing concern. Internal attacks carried out via compromised normal nodes are more damaging and stealthy than external attacks, such as signal stealing, data decryption, and identity forgery. As a security mechanism for internal threat detection based on interaction data, trust models have proven to enhance the security of UASNs. However, traditional trust models lack sufficient scalability when faced with movable underwater devices, heterogeneous network environments, and variable attack patterns. Therefore, in this paper, a novel trust model based on federated deep reinforcement learning is proposed for UASNs. First, the evidence acquisition mechanism, including communication, energy, and data evidence, is improved based on existing ones to better accommodate the topological dynamics of UASNs. Second, acquired trust evidence is fed into the corresponding deep reinforcement learning-based local trust model to accomplish trust prediction and model training. Finally, a federated learning-based update method periodically aggregates and updates the parameters of the local models. The experimental results prove that the proposed scheme exhibits satisfactory performance in terms of improving trust prediction accuracy and energy efficiency. © 2002-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 25
ER  -

TY  - JOUR
AU  - Xiao, H.
AU  - Zhu, Y.
AU  - Zhang, B.
AU  - Lu, Z.
AU  - Du, D.
AU  - Liu, Y.
TI  - Unveiling shadows: A comprehensive framework for insider threat detection based on statistical and sequential analysis
PY  - 2024
T2  - Computers and Security
VL  - 138
C7  - 103665
DO  - 10.1016/j.cose.2023.103665
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182624731&doi=10.1016%2Fj.cose.2023.103665&partnerID=40&md5=f032f55d31f0a0852654a0bec58486ec
AB  - With the increasing importance of internal information security, detecting insider threats has become a critical issue to safeguard organizations' information systems. However, most of the previous studies either overlook temporal relationships or have difficulty attaining accurate performance. One of the primary factors contributing to this challenge is their approach, which lacks a holistic perspective. To our knowledge, none of these studies has considered the integration of statistical and sequential information in addressing this issue. Therefore, we propose a comprehensive framework for insider threat detection based on statistical and sequential analysis to address this challenge. Leveraging the strengths of both statistical analysis and sequential analysis, we deploy an efficient implementation for analyzing and modeling user data based on convolutional attention and a transformer encoder, referred to as CATE. First, user behavior logs are consolidated from diverse sources and preprocessed into a suitable format for subsequent analysis. Then, two parallel analysis modules analyze user data in two different dimensions. The analysis modules are entirely constructed using a neural network for its high adaptability and efficient integration of information from distinct dimensions. Specifically, a subnetwork structure based on convolutional attention is designed to effectively learn statistical information, while a separate subnetwork structure based on transformers is tailored for learning sequential information. Finally, we perform a series of solid experiments utilizing the publicly available CERT dataset to evaluate our framework's effectiveness and robustness in detecting insider threats and identifying malicious scenarios. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 13
ER  -

TY  - JOUR
AU  - Pennada, P.S.S.
AU  - Nayak, S.K.
AU  - Vamsikrishna, M.V.
TI  - ENHANCED INSIDER THREAT DETECTION THROUGH MACHINE LEARNING APPROACH WITH IMBALANCED DATA RESOLUTION
PY  - 2024
T2  - Journal of Theoretical and Applied Information Technology
VL  - 102
IS  - 3
SP  - 914
EP  - 926
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185518759&partnerID=40&md5=3357162e90dc686cc2356d277256f046
AB  - An insider threat is the risk that person inside an organization may pose to the company’s security, data, or resources. Insider threat detection is a crucial component of a comprehensive cybersecurity strategy. By identifying and mitigating risks from within the organization, businesses can better protect their assets, maintain trust, and ensure compliance with legal and regulatory requirements. This paper addresses the detection of insider threats using machine learning algorithms. A famous CERT dataset was used for the experiments. The collected dataset is largely imbalanced. The ML algorithms cannot perform well with imbalanced datasets. So, data imbalance can be resolved by using three over sampling techniques namely random oversample, smote, adasyn and three under sampling techniques namely random under sample, Cluster centroids and Edited Nearest Neighbors. Later, five ML algorithms namely Logistic Regression, Adaboost, Decision Tree, Random Forest and Naïve Bayes applied to the datasets generated through over sampling and under sampling techniques. To further increase the performance of the model, an ensemble learning is proposed along with principal component analysis. The experimental results demonstrated that the proposed model surpassed the performance of existing models for insider threat detection. © Little Lion Scientific.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Sánchez Sánchez, P.M.
AU  - Huertas Celdrán, A.
AU  - Buendía Rubio, J.R.
AU  - Bovet, G.
AU  - Martínez Pérez, G.
TI  - Robust Federated Learning for execution time-based device model identification under label-flipping attack
PY  - 2024
T2  - Cluster Computing
VL  - 27
IS  - 1
SP  - 313
EP  - 324
DO  - 10.1007/s10586-022-03949-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145312752&doi=10.1007%2Fs10586-022-03949-w&partnerID=40&md5=ceef5256916fd244cda54b69e2394953
AB  - The computing device deployment explosion experienced in recent years, motivated by the advances of technologies such as Internet-of-Things (IoT) and 5G, has led to a global scenario with increasing cybersecurity risks and threats. Among them, device spoofing and impersonation cyberattacks stand out due to their impact and, usually, low complexity required to be launched. To solve this issue, several solutions have emerged to identify device models and types based on the combination of behavioral fingerprinting and Machine/Deep Learning (ML/DL) techniques. However, these solutions are not appropriate for scenarios where data privacy and protection are a must, as they require data centralization for processing. In this context, newer approaches such as Federated Learning (FL) have not been fully explored yet, especially when malicious clients are present in the scenario setup. The present work analyzes and compares the device model identification performance of a centralized DL model with an FL one while using execution time-based events. For experimental purposes, a dataset containing execution-time features of 55 Raspberry Pis belonging to four different models has been collected and published. Using this dataset, the proposed solution achieved 0.9999 accuracy in both setups, centralized and federated, showing no performance decrease while preserving data privacy. Later, the impact of a label-flipping attack during the federated model training is evaluated using several aggregation mechanisms as countermeasures. Zeno and coordinate-wise median aggregation show the best performance, although their performance greatly degrades when the percentage of fully malicious clients (all training samples poisoned) grows over 50%. © The Author(s) 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Iskhakova, A.
TI  - Detection of internal security incidents in cyber-physical systems
PY  - 2024
T2  - E3S Web of Conferences
VL  - 471
C7  - 04022
DO  - 10.1051/e3sconf/202447104022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183290056&doi=10.1051%2Fe3sconf%2F202447104022&partnerID=40&md5=5a089ba38c38590e140cc32632b2a2bd
AB  - This paper addresses the issue of internal security breaches in cyber-physical systems framing it as an anomaly detection problem within the framework of machine learning models. The use of powerful mathematical apparatus embedded in the structure of machine learning models, including models based on artificial neural networks, allows building an autonomous system for detecting internal security breaches with minimal reliance on expert assessments. The determination of user abnormality is made on the basis of average data on log entries of actions in the system identified as abnormal, as well as on statistical data on the number of such entries for each user. The results presented here demonstrate the successful application of these models to the task of identifying insider threats to system access subjects. © The Authors, published by EDP Sciences. This is an open access article distributed under the terms of the Creative Commons Attribution License 4.0 (https://creativecommons.org/licenses/by/4.0/).
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Mehmood, R.
AU  - Singh, P.
AU  - Jeffery, Z.
TI  - Unsupervised Learning for Insider Threat Prediction: A Behavioral Analysis Approach
PY  - 2024
DO  - 10.1109/SIN63213.2024.10871807
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000022552&doi=10.1109%2FSIN63213.2024.10871807&partnerID=40&md5=b7d48bf78520cc978ec46412fa96aa62
AB  - Most of the devastating cyber-attacks are caused by insiders with access privileges inside an organization. The main reason of insider attacks being more effective is that they don't have many security barriers before they get into the critical resources of the system. Different machine learning techniques have been previously utilized to identify insider threats within cy-bersecurity domain whereas research done in predicting insider attacks is not significant. Moreover, machine learning models used for prediction and detection face a critical limitation as they require training on labeled datasets, rendering them less effective for real-time data streams which lack threat presence indicators. This work presents an unsupervised machine learning approach that predicts insider threat using behavior analysis for real-time threat data. Patterns are identified in user behavior, to make predictions about benign and malicious insiders. Features are selected by analyzing activities performed. Selected features are utilized to feed machine learning model which extracts anomalous behavior among users, using anomalies in their activity patterns followed by learning methods for threat detection. A dataset that contains selected features from CERT r4.2 is used to make predictions. The performance of Isolation Forest (iForest) is compared with other algorithms of the same category including One-class SVM, Local Outlier Factor (LOF) and DBSCAN to evaluate the new approach. The iForest shows the best performance accuracy 80 percent and recall 84.2 percent. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Kalli, K.
AU  - Jagadeesh, S.
AU  - Suresh Kumar, K.
AU  - Chandrika, B.A.
AU  - Kranthi Kumar, M.
AU  - Rajalingam, P.
TI  - Detecting and Mitigating Insider Threat Attacks in Cloud using Machine Learning
PY  - 2024
SP  - 466
EP  - 471
DO  - 10.1109/ICCCMLA63077.2024.10871803
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219548172&doi=10.1109%2FICCCMLA63077.2024.10871803&partnerID=40&md5=229b13576828094254c758d08cfc8f24
AB  - The proliferation of smart devices has led to an exponential increase in cyber threats, posing significant challenges to cybersecurity, particularly with the centralized nature of cloud computing. Insider threats, leveraging their privileged access, exacerbate these risks, potentially resulting in valuable data breaches. To address this, a novel approach leveraging machine learning is proposed to detect and classify insider threats, aiming to enhance accuracy through ensemble learning techniques. The study utilizes a customized dataset sourced from multiple files of the CERT dataset, reflecting real-world scenarios.Evaluation of Machine learning algorithms, including Decision Tree classifier, Naive Bayes, KNN Classifier, Logistic Regression, and SVM are evaluated on this dataset. Among these, Support Vector Machine (SVM) emerges as the top performer, achieving an impressive accuracy rate of 98 %. This outcome underscores the efficacy of SVM in identifying and classifying insider threats, highlighting its potential as a key component in cybersecurity frameworks. Implementing such approaches can enhance organizations' resilience against insider threats, safeguarding sensitive data and mitigating potential risks to business operations. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Tabassum, S.
AU  - Ramana, K.
TI  - Detecting and Responding to Cloud Privilege Escalation Attacks Using Machine Learning
PY  - 2024
SP  - 382
EP  - 387
DO  - 10.1109/ICCCMLA63077.2024.10871721
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219505588&doi=10.1109%2FICCCMLA63077.2024.10871721&partnerID=40&md5=e6fc95257b1b6bd314054d0f21bef1e6
AB  - The field of cloud computing has created as an extremely productive region for complete innovative work, drawing in critical consideration from proficient organizations and organizations the same. The quick multiplication of PCs, information organizations, and other basic applications has brought about a more prominent accentuation on network safety. This exploration utilizes state of the art ML procedures to distinguish and forestall honor acceleration dangers, consequently supporting cloud security. Strong insurances are fundamental since utilizing cloud administrations builds the risk of these attacks. To work on generally speaking security, the review targets shortcomings in representative access freedoms in cloud settings utilizing ML methods like LightGBM, RF, AdaBoost, and XGBoost. This empowers ongoing discovery and relief of honor acceleration endeavors while adjusting quickly to evolving dangers. Moreover, a 'soft' Voting Classifier that joins forecasts from RF, DT, and SVM supports framework execution considerably further. The blend of a simple to-utilize Flask framework with SQLite gives secure information exchange and sign-in usefulness while enhancing client testing for true arrangement. This far reaching technique not just further develops client and business information security and encourages distributed computing trust, however it likewise helps cloud specialist co-ops' and associations' trust in their ability to keep a protected web-based climate. Among the proposed calculations, the Voting Classifier scored the best execution accuracy of 96.45 %, while LightGBM accomplished 94 %. The leftover accuracy scores are as per the following: RF (95 %), AdaBoost (95 %), and XGBoost (9 4 %). © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Mahesh, B.L.
AU  - Kaur, S.
TI  - Exploring Machine Learning Algorithms for Detecting Cyber Attacks and Threats
PY  - 2024
SP  - 892
EP  - 899
DO  - 10.1109/ICCES63552.2024.10860108
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218424102&doi=10.1109%2FICCES63552.2024.10860108&partnerID=40&md5=6ba82286d2e43231d1c15e640b53ac9a
AB  - Securing systems, networks, and information amid cyber threats involves a blend of machine learning and cybersecurity, which uses machine learning to identify abnormal behaviors, classify malicious software, authenticate user identities, and predict possible security breaches. This paper presents a detailed review and analysis of applying machine learning in beefing up cybersecurity defenses and it outlines various machine learning methods such as decision trees, support vector machines, neural networks, and Long Short-Term Memory Models illustrating their efficiency in recognizing diverse cyber threats in several datasets and attack scenarios. In this Analysis, a real-time phishing dataset was used, the Support Vector Machine (SVM) model demonstrated exceptional accuracy of 94%, surpassing other tested algorithms. This study addresses important challenges of cybersecurity which include: the complex nature of cyber-attacks, high rates of false positives and difficulties experienced when analyzing encrypted data. The role of advanced solutions in automated threat detection and response processes is underscored by the work. It also incorporates global threat intelligence feeds that would improve adaptive defense strategies using these advanced machine learning approaches. Finally, upcoming trends are discussed like quantum computing integration into cryptographic protocols and insider threats identification through behavioral analysis as well as user profiling. This paper synthesizes existing research while proposing future directions, intending to guide the development of resilient cybersecurity frameworks that can protect digital ecosystems from emerging threats. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Pennada, P.S.S.
AU  - Nayak, S.K.
AU  - Vamsikrishna, M.V.
TI  - Enhancing Insider Threat Detection with Machine Learning Techniques
PY  - 2024
DO  - 10.1109/ICIICS63763.2024.10860057
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218184965&doi=10.1109%2FICIICS63763.2024.10860057&partnerID=40&md5=8af1a9d62fdb1b75d7d3add34c56e6bd
AB  - Insider threats pose significant risks to organizations by compromising sensitive data and resources. Detecting these threats effectively necessitates robust machine learning (ML) techniques capable of managing complex and imbalanced datasets. This paper explores the performance of various ML models, including Logistic Regression, Decision Trees, Random Forest, SVM, KNN, Naïve Bayes, Adaboost, and XGBoost, using the widely recognized CERT dataset. By addressing data imbalance challenges through techniques such as SMOTE, the importance of a balanced dataset is highlighted. The results demonstrated that Random Forest and Adaboost achieved the highest accuracy of 97.5%, underscoring their effectiveness in insider threat detection. This research contributes to enhancing insider threat detection methodologies and provides a structured analysis of model performance, paving the way for more reliable organizational security strategies. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Chen, C.-C.
AU  - Pao, H.-K.
TI  - Reconsider Time Series Analysis for Insider Threat Detection
PY  - 2024
SP  - 1558
EP  - 1565
DO  - 10.1109/BigData62323.2024.10825829
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218040205&doi=10.1109%2FBigData62323.2024.10825829&partnerID=40&md5=88ab75275d23628c416b5e5153483878
AB  - Insider threat detection (ITD) presents a significant challenge in cybersecurity, particularly within large and complex organizations. Traditionally, ITD has been overshadowed by the focus of external threats, resulting in less attention and development in this critical area. Conventional ITD approaches often rely heavily on event-driven approaches. On top of that, researchers developed various rule-based methods to conquer the tasks. Based on that, we often ignore the intrinsic temporal relationships that are naturally built in between events that occur in different moments. For instance, we may easily understand events with causality such as one anomalous event followed by another specific event to complete a malicious action; however, may not be aware of events that occur around 9 am every morning during working hours. In our opinion, we attempt to re-consider the temporal behavior to extract the information hidden in cyberspace activities. Specifically, some effective sentence embeddings can assist us in providing informative internal representations to summarize temporal behaviors in the temporal activity sequences to make the right judgment on insider threat detection. In this paper, we propose a novel methodology for insider threat detection that emphasizes temporal relationship modeling on top of already-matured event sequence analysis to effectively catch insider threats. The proposed approach leverages contrastive sentence embeddings to learn users' intentions in sequences, followed by the deployment of a user-level and event-level Contrastive Learning (euCL) model to incorporate temporal behaviors with user behavior embeddings. To validate the proposed methodology, we conduct extensive analyses and experiments using the publicly available CERT dataset. The results demonstrate the effectiveness and robustness of the proposed method in detecting insider threats and identifying malicious scenarios, highlighting its potential for enhancing cybersecurity measures in complex organizational environments. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Tiwary, P.
AU  - Madhubalan, A.
AU  - Gautam, A.
AU  - Darji, R.
TI  - Attention to Patterns is all you need for Insider threat detection
PY  - 2024
DO  - 10.1109/ICAMAC62387.2024.10828982
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217409926&doi=10.1109%2FICAMAC62387.2024.10828982&partnerID=40&md5=3d548814386c8dc6a429ece373d528a6
AB  - Insider threats pose a significant and often underestimated risk to organizations. Traditional anomaly detection methods relying on simplistic patterns and lacking temporal awareness struggle to capture the nuances of user behavior, leading to missed detections and false alarms. This research proposes a novel approach that leverages the power of deep learning models to capture complex, hierarchical patterns in user behavior, enabling the early detection of malicious insider activity. The proposed approach introduces two distinct architectures: Time-Distributed Deep Learning Architecture (TD-CNN-LSTM) and Contextually Aware Attention-Based Architecture (TD-CNN-Attention). These architectures combine CNNs with LSTMs or attention mechanisms to extract both spatial and temporal features from user access data, capturing intricate patterns across different timescales. Additionally, they incorporate user information such as psychometrics and organizational data, providing a holistic view of user behavior and context. Through extensive evaluation, both architectures demonstrate significant improvements in accuracy and F1 score compared to existing insider threat detection solutions. The attention-based model in particular emerges as a state-of-the-art approach with superior performance capabilities. This research marks a significant step forward in the field of insider threat detection, paving the way for organizations to better secure their critical assets and safeguard their future in the ever-changing cybersecurity landscape. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Manikandan, S.P.
AU  - Kumar, K.
AU  - Harsha Vardhan, T.S.
AU  - Thanigaivel, G.
AU  - Venkataramanaiah, B.
AU  - Vijaya Vardan Reddy, S.P.
TI  - Detecting Insider Threats in Cybersecurity Using Machine Learning
PY  - 2024
SP  - 152
EP  - 158
DO  - 10.1109/ICICNIS64247.2024.10823353
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217167198&doi=10.1109%2FICICNIS64247.2024.10823353&partnerID=40&md5=fea8e2d0867303aac0a97bfba45a9c23
AB  - Threats in cyber security increasing now a days. In order to detect insider threats in cyber security environments, this research investigates the creation of a Network Intrusion Detection System (NIDS) that makes use of machine learning techniques. In order to identify suspicious activity and unauthorized access, the suggested system examines network traffic. The NIDS minimizes false positives and achieves high accuracy by using ensemble models, particularly Decision Trees and Logistic Regression, which are optimized by Grid Search. The simulation findings show that, in comparison to independent methods, integrating models produces a more robust and dependable detection mechanism. From Denial-of-Service (DoS) attacks to increasingly sophisticated insider threats, the NIDS continuously demonstrated a high detection accuracy while maintaining a controllable false positive rate. This feature emphasizes how useful machine learning models are for improving NIDS's responsiveness and flexibility. The system's appropriateness for deployment in expansive, dynamic network environments is demonstrated by simulation results, which validate its capacity to expand and sustain performance even in the face of high network traffic. The technique, simulation results, and future directions-such as real-time integration and improved scalability for bigger networks-are covered in the research. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Pennada, P.S.S.
AU  - Nayak, S.K.
AU  - Vamsikrishna, M.V.
TI  - Comprehensive Review of Insider Threat Detection: Models, Datasets, and Metrics for Effective Threat Identification
PY  - 2024
SP  - 46
EP  - 51
DO  - 10.1109/ICDICI62993.2024.10810954
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216711158&doi=10.1109%2FICDICI62993.2024.10810954&partnerID=40&md5=227fc6d61074edc8d16d7e9af4f141d2
AB  - This research study presents a comprehensive review of Insider Threat Detection (ITD) models, highlighting the transition from traditional methods to advanced machine learning (ML), deep learning (DL), and hybrid approaches for enhanced threat detection. As ITD evolves to address the challenges posed by Big Data, ML and DL techniques have gained prominence, though they require careful model selection, data preprocessing, and ensembling to optimize performance. The inclusion of hybrid methods, such as the Hybrid Anomaly Checker, which combines statistical and ML-based techniques like the Local Outlier Factor (LoF), enhances the precision of anomaly detection by analyzing individual user behaviors. The review emphasizes the use of advanced datasets like CERT r4.2 and a wide range of evaluation metrics, including True Positive Rate (TPR), Matthews Correlation Coefficient (MCC), and Time to Detection (TTD), to provide a more comprehensive model performance analysis. These metrics ensure robust and reliable ITD systems that are better equipped to handle evolving insider threats. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
TI  - 8th International Conference on Innovative Technologies in Intelligent Systems and Industrial Applications, CITISIA 2023
PY  - 2024
T2  - Lecture Notes in Electrical Engineering
VL  - 117 LNEE
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215700007&partnerID=40&md5=c96f77fc975ad851a9659e72b990fe63
AB  - The proceedings contain 38 papers. The special focus in this conference is on Innovative Technologies in Intelligent Systems and Industrial Applications. The topics include: Privacy Techniques in Health Data Mining; network Segmentation and Its Advancement in Containing Insider Threats; constructing a Proactive Cyber Resilient Culture for Better Business Outcomes; the Application of Zero Trust Architecture to Mitigate Password Compromise in Accessing Cloud Services; enhancing Banking Security: A Collaborative Framework to Combat Cybercrime and Secure Financial Transactions; host-Based Intrusion Detection Systems for Resource Constrained Environments: A Review; access Control for Secure Remote Patient Monitoring; advanced Persistent Threats—Techniques, Detection and Defences; Edge-AI Addresses the Big Data Challenges of IoT in the Cloud Edge; analysis of the Complexity and Risk to the Government eHealth System When Adopting the Cloud Services; unified Medical Data Management on the Cloud: Leveraging Blockchain for Multi-source Integration; blockchain and Cloud Security—A Review; machine Learning-Powered Blockchain in Vehicular Ad-Hoc Networks; evaluation of the Next Generation Firewall with Breach and Attack Simulation; implementing a Usable Hybrid Project Management Model for Local Government; organisational Challenges, Risks, and Success Factors When Implementing Agile Methodologies Post Covid-19; Exploring Security and Data Privacy Issues in Industrial Internet of Things (IIoT)—A Review; agile Implementations in Cyber Security: Issues Arising and Recommendations; using Artificial Intelligence to Defend Internet of Things for Smart City Networks; smart Home IoT Devices Influence or Impact on Elderly’s Life: A Review; analysis and Detection of IoT Botnets Using Machine Learning; helmet Detection for Motorcycle Ignition: A Computer Vision and Android-Based Approach.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Ullah, M.W.
AU  - Alam, M.T.
AU  - Sultana, T.
AU  - Rahman, M.M.
AU  - Faraji, M.R.
AU  - Ahmed, M.F.
TI  - A systematic review on information security policies in the USA banking system and global banking: Risks, rewards, and future trends
PY  - 2024
T2  - Edelweiss Applied Science and Technology
VL  - 8
IS  - 6
SP  - 8437
EP  - 8453
DO  - 10.55214/25768484.v8i6.3816
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215379157&doi=10.55214%2F25768484.v8i6.3816&partnerID=40&md5=fae8955756e8c143de5ce016ee7faddd
AB  - This study aims to examine the current state of information security policies and practices in the United States banking sector while drawing comparisons to global banking systems. The research specifically addresses risks, benefits, and future trends, providing insights for strengthening information security frameworks worldwide. The study adopts a qualitative research approach, utilizing secondary data sources, including scholarly journals, research articles, televised news, and online platforms. A systematic review was conducted using global databases such as Science Direct, Scopus, Web of Science, PubMed, DOAJ, and Google Scholar in alignment with the PRISMA 2020 guidelines. The research incorporated specific keyword phrases to identify relevant literature, with additional exclusion criteria applied to eliminate incomplete, inconsistent, or non-English publications. The final review included 125 papers and 20 reports. The findings highlight that the U.S. banking sector faces a dynamic landscape of cybersecurity risks, including phishing attacks, ransomware, regulatory non-compliance, and insider threats. Despite these risks, robust information security frameworks offer significant rewards, such as improved customer trust, fraud detection through AI and machine learning, and financial stability. The study underscores the regulatory landscape in the U.S., particularly frameworks like the Gramm-Leach-Bliley Act and collaboration initiatives such as the CISA and FS-ISAC, which enhance preparedness against emerging cyber threats. Comparative analysis with global banking systems revealed key challenges, including the evolving cyber threat landscape, compliance with international data privacy standards, and the need for cross-border cooperation. While the U.S. banking system demonstrates a strong regulatory foundation, the study identifies areas requiring improvement, such as proactive employee training, adoption of advanced cybersecurity technologies, and international cooperation. The study's implications emphasize the need for proactive risk management and continual innovation to address emerging threats. Recommendations include implementing multi-factor authentication, leveraging AI and blockchain technologies, and prioritizing cybersecurity awareness programs for employees. However, limitations include reliance on secondary data, which may omit recent developments, and a focus on the U.S. context, limiting global generalizability. Future research should incorporate primary data collection and expand the scope to include quantitative analyses of cybersecurity investments and outcomes. This research provides policymakers, banking regulators, and industry stakeholders with actionable insights to bolster information security resilience and adapt to the rapidly evolving financial landscape. © 2024 by the authors; licensee Learning Gate.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Algabri, M.
AU  - Alsabri, A.A.
AU  - Al-Azzani, A.M.
AU  - Alhrazi, F.
AU  - Alsabry, A.
AU  - Al-Shalabi, A.A.
TI  - Deep Learning and Blockchain for Detection and Prevention Abuse of Privileges
PY  - 2024
DO  - 10.1109/ICETI63946.2024.10777144
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214976143&doi=10.1109%2FICETI63946.2024.10777144&partnerID=40&md5=3a0c8b64814e69d44b95b6bf4ccf80e0
AB  - Privilege abuse within organizations is a major concern because it can lead to security breaches caused by malicious actions or behavior from employees. It is one of the key sources of insider threats in organizational systems. This paper presents an integrated approach to detecting and preventing privilege abuse by employees, focusing on identifying malicious activities. This is achieved by combining artificial intelligence and blockchain technology. RNN is used to analyze malicious behavior, while blockchain ensures a secure, decentralized ledger to prevent abuse. The goal is to combine the RNN model with blockchain technology to detect and prevent privilege abuse. The LSTM model was implemented as an API to identify any malicious activity by employees, and the classification results were stored on the blockchain to ensure security, trust, and data integrity. Experiments using the CERT r4.2 dataset demonstrate that the proposed approach outperforms current state-of-the-art techniques, achieving a classification accuracy of 98.75% with low false positives and false negatives in detecting insider threats. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Petrovski, A.
AU  - Kotenko, I.
AU  - Arifeen, M.
AU  - Abramenko, G.
AU  - Sobolev, P.
TI  - Insider Threat Detection Within Operational Technology Using Digital Twins
PY  - 2024
T2  - Lecture Notes in Networks and Systems
VL  - 1210 LNNS
SP  - 25
EP  - 34
DO  - 10.1007/978-3-031-77411-9_3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214005426&doi=10.1007%2F978-3-031-77411-9_3&partnerID=40&md5=b5806c9bdbea356620a389d50dacce70
AB  - Managing unintentional insider threat is a growing challenge in digital industries because the biggest threat to operational technologies (OT) originates internally, irrespective of the type or size of the organisation. Data breaches and other advanced persistent threats are often caused by users with legitimate access to systems who often make genuine mistakes. This paper highlights the necessity to bring forward a more proactive approach in terms of understanding, raising awareness, and tackling unintentional insider threats. A novel effective method of securing OT systems against insider threats based on data-driven modelling and machine learning has been suggested, tested and trialled using a digital twin that provides a secure and conducive environment for addressing operational challenges in the era of Industry 4.0/5.0. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CHAP
AU  - Natarajan, G.
AU  - Sundaravadivazhagan, S.
AU  - Elakkiya, E.
AU  - Rakesh, R.
TI  - Leveraging Artificial Intelligence and Machine Learning for Advanced Threat Detection in Smart Manufacturing
PY  - 2024
SP  - 101
EP  - 119
DO  - 10.1201/9781032694375-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213967915&doi=10.1201%2F9781032694375-6&partnerID=40&md5=e70f86176d5b52b739aa57d750ca9393
AB  - Smart manufacturing systems offer various benefits in terms of efficiency and productivity as they get better, becoming more automated and networked. However, this rapid rise also raises new issues, chief among them being security. This chapter examines the application of machine learning (ML) and artificial intelligence (AI) techniques to enhanced threat detection in the framework of smart manufacturing. Systems may adapt, acquire knowledge, and react in real time to new threats when AI and ML technologies are used in smart industrial settings. The methods and tools used to develop and implement AI and ML techniques for threat detection in smart manufacturing facilities are covered in detail in this chapter, which emphasizes the significance of these tools for identifying sophisticated and subtle threats which might defy conventional security measures. This chapter covers the essential elements of AI and ML threat detection, such as feature selection, model training, data collection and preprocessing, and ongoing model adjustment. It additionally examines a variety of hazards, including supply chain attacks, insider threats, and vulnerabilities in internet of things devices, highlighting the importance of a multipronged strategy for threat identification. The chapter looks at case studies and practical implementations that show how AI and ML may be used to reduce risks, minimize downtime, and ensure the integrity of smart manufacturing processes. It looks into how these technologies may strengthen network security, anomaly detection, and predictive maintenance while safeguarding important resources and production procedures. Ultimately, this chapter highlights how important AI and ML are to enhancing the security of smart manufacturing by offering a proactive defence against new threats. By utilizing advanced analytics and automation, organizations can safeguard the continuity and stability of their smart manufacturing systems within a highly interconnected and delicate digital ecosystem. © 2025 Taylor and Francis Group, LLC.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - CHAP
AU  - Singh, K.
AU  - Gautam, S.
TI  - Security challenges in big data analytics
PY  - 2024
SP  - 69
EP  - 89
DO  - 10.1049/PBHE063E_ch4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213565457&doi=10.1049%2FPBHE063E_ch4&partnerID=40&md5=318ac4d9daa159a308393eba0002d9e8
AB  - The introduction of Big Data analytics has completely changed how businesses get insights from enormous and varied information. However, as data volume, velocity, and diversity increase, so do the security issues related to its processing, storage, and analysis. This chapter gives a general overview of the major security issues that businesses using big data analytics must deal with. The article starts by talking about the problem of data leaks and unauthorized access. The security and integrity of data have become a top priority as large datasets are being stored in remote locations. Data breaches, identity theft, and severe financial losses may all result from unauthorized access. To reduce these risks, it is essential to have reliable authentication and access control systems. The chapter also examines the dangers presented by insider threats. Those with privileged access to big data repositories, such as employees or contractors, may purposefully or unintentionally breach data security. To create accountability and identify internal risks, effective monitoring and auditing are necessary. This chapter's third difficulty is related to data encryption. Big Data's immense scale often makes the usage of encryption methods for data in transit and at rest necessary. It may be difficult to scale up encryption without sacrificing performance, however. In Big Data analytics, finding the ideal balance between security and performance is crucial. The study then addresses the topic of data lineage and provenance. To ensure that data is reliable, it is essential to understand its origin and history. Big Data settings sometimes do not have thorough systems for monitoring data history, which makes it difficult to find data manipulation or inaccuracies. The chapter also emphasizes the difficulty of adhering to data privacy laws like GDPR and CCPA. Big Data analytics companies must traverse a complicated web of legal and regulatory regulations, which might differ across nations. A never-ending difficulty is ensuring compliance while gaining useful insights from data. The chapter also discusses how adversarial assaults are a growing danger for machine learning models employed in Big Data analytics. Attackers have the ability to alter input data to trick machine learning systems, producing false results. An active study topic in the discipline is creating resilient models that can withstand such assaults. In conclusion, this chapter offers a summary of the many security issues that Big Data analytics raises. Addressing these issues is crucial to preserve data, uphold trust, and guarantee compliance with changing data protection requirements as firms continue to use big data to gain a competitive advantage. It is crucial to have comprehensive security plans that include people, systems, and data in order to reduce the dangers related to Big Data analytics. © The Institution of Engineering and Technology and its licensors 2025.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Atıcı, S.
AU  - Tuna, G.
TI  - Impact of cybersecurity attacks on electrical system operation
PY  - 2024
SP  - 117
EP  - 160
DO  - 10.1016/B978-0-443-14066-2.00008-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211840567&doi=10.1016%2FB978-0-443-14066-2.00008-6&partnerID=40&md5=3cc68d3c5d726038e563360c3ed3d397
AB  - The security of electrical system operations is of paramount importance for the daily functioning of modern societies and industrial activities. This study comprehensively examines cybersecurity threats that could impact electrical system operations and their implications. The reliability, continuity, and stability of electrical infrastructure play a critical role in ensuring public safety, infrastructure integrity, and economic stability. Cyberattacks can significantly jeopardize electrical systems, leading to disruptions, data loss, and economic losses. Furthermore, such attacks can have implications for national security. The study emphasizes why the cybersecurity of electrical system operations is so crucial and addresses various types of cyber threats. It delves into real-life examples to understand the impact of cyberattacks on electrical systems. These examples underscore the critical nature of cybersecurity measures. In addition, the study discusses cybersecurity frameworks, standards, and best practices that can be employed to safeguard electrical system operations. These encompass measures such as employee training, secure design, security hardening, and security assessments. Finally, it explores future challenges and emerging threats, emphasizing the need for proactive strategies to secure electrical infrastructure. Adapting to rapidly evolving technologies, addressing IoT and interconnectedness, dealing with Artificial Intelligence and machine learning threats, securing the supply chain, and mitigating insider threats are some of the areas covered. This study not only highlights the criticality of keeping electrical systems secure but also provides insights into the measures and best practices to protect them. It underscores the importance of preparedness for future threats and challenges in securing electrical system operations. © 2025 Elsevier Inc. All rights reserved.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - CONF
TI  - 2024 International Conference on Advances in Computing Research on Science Engineering and Technology, ACROSET 2024
PY  - 2024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211471394&partnerID=40&md5=879915f8b7afe808415723e93109ef7a
AB  - The proceedings contain 197 papers. The topics discussed include: analyzing the human element in cybersecurity breaches with a focus on social engineering tactics and the risks posed by insider threats; design and development of real-time image based fire detection using OpenCV and HSV; the role of low-dimensional neural networks in solving complex inverse problems; transformative potential IoT sensor frameworks for real-time Alzheimer's detection and monitoring in elderly populations; decoding the Devanagari - handwritten Hindi recognition using deep learning methodology; countering the rise of AI-generated content with innovative detection strategies and large language models; a method to reduce the incidence of wheat leaf diseases; and an extensive analysis of pattern identification and categorization.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Bhattarai, S.
AU  - Paudel, P.
AU  - Li, Z.
AU  - Luo, B.
AU  - Li, F.
TI  - Robust Privacy-Preserving Classification for Lensless Images
PY  - 2024
SP  - 371
EP  - 379
DO  - 10.1109/MASS62177.2024.00056
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210249757&doi=10.1109%2FMASS62177.2024.00056&partnerID=40&md5=e6b672ca2df028c681f28c5c8b32127f
AB  - The increasing demand for image and video data processing, driven by wearable devices, Internet-of-Things, and augmented/virtual reality applications, raises privacy concerns with traditional centralized image classification methods requiring users to upload their data to a cloud server. Recently, lensless imaging devices have emerged as a promising privacy-preserving solution, where image reconstruction requires knowledge of the device's PSF, kept secret from adversaries. However, existing lensless-image-based approaches remain vulnerable to insider threats and new attacks leveraging GAN for PSF estimation. To address these challenges, we propose a novel framework called PPLiC. By transforming raw lensless images into protected sensor measurements, it supports all classification tasks while defending against malicious insiders and GAN-based PSF estimation attacks. PPLiC employs a learning-based approach to identify DCT coefficients with minimal impact on classification accuracy, leveraging the squeeze-and -excitation block, and introduces pseudo-random noises to a small fraction of these coefficients. The index of the selected coefficients and the seed for generating pseudo-random noise collectively serve as the protection key. PPLiC supports classification by utilizing only the selected coefficients, while the reconstruction of the original image requires full knowledge of the protection key. We implemented PPLiC and tested its effectiveness with real-world and simulated lensless images. PPLiC achieves the best satisfying classification performance with an average accuracy of 84.17% and 95.5% on the FlatCam face and simulated DeepFire datasets, respectively. Meanwhile, it offers strong privacy protection since no meaningful image can be reconstructed from the protected sensor measurement using either the original or the GAN-estimated PSF. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Qiang Wang, Z.
AU  - Wang, H.
AU  - El Saddik, A.
TI  - FedITD: A Federated Parameter-Efficient Tuning With Pre-Trained Large Language Models and Transfer Learning Framework for Insider Threat Detection
PY  - 2024
T2  - IEEE Access
VL  - 12
SP  - 160396
EP  - 160417
DO  - 10.1109/ACCESS.2024.3482988
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207781039&doi=10.1109%2FACCESS.2024.3482988&partnerID=40&md5=88fb56f49ef6d7b4272d0db0a6786f37
AB  - Insider threats cause greater losses than external attacks, prompting organizations to invest in detection systems. However, there exist challenges: 1) Security and privacy concerns prevent data sharing, making it difficult to train robust models and identify new attacks. 2) The diversity and uniqueness of organizations require localized models, as a universal solution could be more effective. 3) High resource costs, delays, and data security concerns complicate building effective detection systems. This paper introduces FedITD, a flexible, hierarchy, and federated framework with local real-time detection systems, combining Large Language Models (LLM), Federated Learning (FL), Parameter Efficient Tuning (PETuning), and Transfer Learning (TF) for insider threat detection. FedITD uses FL to protect privacy while indirect integrating client information and employs PETuning methods (Adapter, BitFit, LoRA) with LLMs (BERT, RoBERTa, XLNet, DistilBERT) to reduce resource use and time delay. FedITD customizes client models and optimizes performance via transfer learning without central data transfer, further enhancing the detection of new attacks. FedITD outperforms other federated learning methods and its performance is very close to the best centrally trained method. Extensive experiment results show FedITD's superior performance, adaptability to varied data, and reduction of resource costs, achieving an optimal balance in detection capabilities across source data, unlabeled local data, and global data. Alternative PETuning implementations are also explored in this paper. © 2024 The Authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 9
ER  -

TY  - CONF
AU  - Kong, W.
AU  - Li, X.
AU  - Yuan, K.
AU  - Song, Y.
TI  - PAUP: a pre-awareness insider threat detection method based on user psychoanalysis
PY  - 2024
T2  - Proceedings of SPIE - The International Society for Optical Engineering
VL  - 13291
C7  - 132914P
DO  - 10.1117/12.3033591
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207695258&doi=10.1117%2F12.3033591&partnerID=40&md5=c249c846813c88b8beae563c77540fc0
AB  - Internal personnel within an organization often have privileged access to critical systems and sensitive information. They are familiar with the internal network structure, business processes, and security measures, which can lead to insider threats that are more insidious, long-term, destructive and diverse, posing a serious threat to enterprises and organizations. However, existing models for detecting insider threats primarily focus on modeling user behavior information but seldom take into account the valuable information from the psychological personality of insider personnel for threat detection. To address this limitation and better analyze the impact of user attributes on insider threats, a new direction for insider threat user analysis is proposed. This involves analyzing and visualizing the relationship between users' personalities and the execution of insider threat behaviors, using data analysis. Additionally, a decision tree model is constructed to realize insider threat detection based on user psychology, using feature_importance, a relative importance metric of features generated in the decision tree decision-making process, to judge the importance of different personality traits for insider threat detection. To further enhance the detection process, an insider threat user clustering method based on Fuzzy C-Means clustering is realized, and the groups are divided according to the user's psychological assessment scores to realize the early perceived localization of risky users. These approaches provide new ideas for finding new research directions in the field of insider threat. © 2024 SPIE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Zewdie, M.
AU  - Girma, A.
AU  - Sitote, T.M.
TI  - Deep Neural Networks for Detecting Insider Threats and Social Engineering Attacks
PY  - 2024
DO  - 10.1109/ICECET61485.2024.10698519
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207406851&doi=10.1109%2FICECET61485.2024.10698519&partnerID=40&md5=e8a39068c071ac9dec02066ce59d94ff
AB  - Cybersecurity (CS) plays a crucial role in protecting valuable and sensitive organizational data, systems, computers, and networks from unauthorized access. However, the incressing prevalence of insider threats and social engineering attack (SEA) presents significant challenges in effectively detecting and mitigating of these risks. A yearly report from 2023 highlighted that despite 90% of companies implementing multiple security measures, they still experienced an average loss of 16 million per incident. The detection capabilities of existing detection methods, which are primarily network-based or host-based intrusion detection, have limitations. This article aims to enhance detection methods through a comprehensive analysis of network and host level insiders' behavior along with Deep Learning approaches. This proposed method of detection provide a unified and holistic detection. Insider threats, whether intentional or unintentional, also create vulnerabilities to external threats and attacks such as phishing and SEA attacks. By addressing the gap in insider threat detection, the proposed comprehensive analysis of insider network and host level activities will enhance detection performance and reduce security costs by compact the existing fragmented detection approaches. As a result the false positive and false negative alarms will reduce the cost of detection and mitigate business operation disturbances. Since insiders interact with network devices and computers as users, integrating their host and network behaviors' into the detection methods offer both enhanced detection capabilities and a unified detection. To evaluate the proposed detection method, an Auto-encoder Deep Learning model will be developed, and public network and host intrusion detesets will be utilized. Evaluation metrics such as Accuracy, precision, recall, and F1- score will be employed. Preliminary analysis results have shown the proposed compre-hensive behavior analysis with Deep Learning (DL) method promising outcomes for detecting insider threats and social engineering attacks (SEAs). © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Liu, M.
AU  - Zhao, Y.
AU  - Han, H.
AU  - Zhang, J.
TI  - Detecting Potential Malicious Insiders Based on Sentiment Profile
PY  - 2024
SP  - 156
EP  - 162
DO  - 10.1109/JCICE61382.2024.00040
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207061572&doi=10.1109%2FJCICE61382.2024.00040&partnerID=40&md5=ae5f846ed5fd21d7e9a3cc3504229d2e
AB  - The number of malicious insiders continues to rise, and the detection of insider threats is becoming increasingly challenging. Existing work mainly focuses on modeling user behaviors (e.g. reading/writing file) to detect abnormal insiders. However, it is almost impossible to stop malicious insiders immediately when they carried out incidents. In this paper, we propose a novel insider threat detection framework that can prevent the occurrence of threats by early detection-observing the signs before the incident-of the potential malicious insiders. Unlike traditional sentiment analysis, this framework uses aspect-based sentiment analysis to capture the employees's fine-grained information. Specifically, our approach combines deep learning techniques (e.g. attention mechanism) to build a sentiment profile for each employee and uses the profile to carry out multidimensional anomaly detection and threat ranking. Extensive experimental evaluations over the public dataset have demonstrated that our method can actively detect malicious insiders with extremely malicious emotional tendencies. Furthermore, the profiles generated by our framework can also be used to complement the existing anomaly system based on users' behavior, enabling the creation of a more comprehensive insider threat defense system. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Cui, L.
AU  - Wang, Y.
AU  - Long, Z.
AU  - Zhang, J.
AU  - Shen, W.
AU  - Wang, J.
TI  - Insider Threat Detection Based on Personalized User Modeling
PY  - 2024
SP  - 868
EP  - 873
DO  - 10.1109/CISAT62382.2024.10695344
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207052715&doi=10.1109%2FCISAT62382.2024.10695344&partnerID=40&md5=113d549552038993e4cb5251b1a28627
AB  - In the information age, internal threats have become a major security challenge for enterprises and organizations. Traditional methods of detecting internal threats, due to their limitations, struggle to address the complex and variable scenarios of internal threats. To solve this problem, this paper proposes an internal threat detection model based on personalized modeling, ITDPUB. First, user behavior sequences are constructed by integrating user information to represent user activities. Then, a language model is used to perform feature learning on these behavior sequences to capture the underlying patterns in user behavior. Finally, a bidirectional long short-term memory (BiLSTM) network is employed to detect internal threats based on the extracted user features. Experimental results on the CERT insider threat dataset indicate that ITDPUB achieves a high AUC score, effectively improving the accuracy of internal threat detection. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Almusawy, B.
AU  - Alrammahi, A.A.H.
TI  - Insider Detection Using Combination of Machine Learning and Expert Policies
PY  - 2024
T2  - International Journal of Electrical and Electronic Engineering and Telecommunications
VL  - 13
IS  - 5
SP  - 389
EP  - 396
DO  - 10.18178/ijeetc.13.5.389-396
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204434509&doi=10.18178%2Fijeetc.13.5.389-396&partnerID=40&md5=d5658e4bd8643283d685b8fdcd91b985
AB  - Today, organizations of all sizes face many difficulties in protecting their data, systems, and tools. One issue of particular concern is the insider threat. Insiders seek to use their privileges to undermine data confidentiality, validity, and availability. Any sabotage committed by someone within a company significantly harms the company’s integrity, credibility, and financial profits. Automated feature extraction methods face challenges when used to classify data due to their tendency sometimes to return inaccurate results, leading to overfitting. Furthermore, analyzing irregular data requires extensive manual feature detection. We propose an algorithm that represents an expert system that detects insiders and determines their risk level as well. After that, the decisive step will be to intersect the results obtained from a classification using multiple algorithms with those obtained from the internal detection algorithm using expert rules. This research uses several classification methods that can deal with this type of data to predict the status of insiders within a computer network. The main goal of this study is to improve the accuracy and efficiency of identifying insiders within a computer network. Model performance evaluation includes important parameters such as precision, recall, and F1 score. The highest classification accuracy is obtained at 0.99, and after combining these results with the results of the proposed algorithm, the accuracy is 100%. These results highlight the remarkable ability of these models to detect internal states accurately, providing encouraging possibilities for improving cyber security within a computer network. © © 2024 by the authors. This is an open access article distributed under the Creative Commons Attribution License (CC BY-NC-ND 4.0), which permits use, distribution and reproduction in any medium, provided that the article is properly cited, the use is noncommercial and no modifications or adaptations are made.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Abdallah, H.E.-E.
AU  - Abd-Elkader, H.H.
AU  - Mohamed, K.K.
AU  - Abd-Elmoniem, M.
AU  - El-Assal, N.W.
AU  - Mohamed, S.M.
AU  - Said, S.A.
AU  - Salem, S.A.
TI  - Performance Evaluation Framework for Insider Threat Detection Using Machine Learning
PY  - 2024
SP  - 1
EP  - 6
DO  - 10.1109/IMSA61967.2024.10652829
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204383227&doi=10.1109%2FIMSA61967.2024.10652829&partnerID=40&md5=31e38299cc29b24875128a4753046a95
AB  - Nowadays, malicious behavior identification is considered a significant and challenging issue in cybersecurity. To mitigate this problem, an effective detection system can be a promising candidate to facilitate precise and rapid detection of a malicious insider. In this paper, a performance evaluation framework for insider threat detection using machine learning is proposed. This framework employs the effects of several machine learning models to assist in identifying insider threats. The proposed framework applied XGboost, SVM, RF, KNN, MLP, and LR to detect insider threats. The machine learning framework is evaluated across the CERT r5.2 dataset. After that, the results of these models are compared with evaluation metrics to determine which model is the most effective for insider detection at different granularity levels. Furthermore, we have empirically shown that XGBoost outperforms competitive algorithms and can achieve a range precision of 95.24%-97.85%, recall of 97.34%-99.30%, F1 score of 96.79%-98.81 %, and an AUC of 97.04%-98.63% for insider detection. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Femi-Oyewole, F.
AU  - Osamor, V.
AU  - Okunbor, D.
TI  - Survey on Predictive Algorithms to Detect Insider Threat on a Network Using Different Combination of Machine Learning Algorithms
PY  - 2024
DO  - 10.1109/SEB4SDG60871.2024.10630366
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202961953&doi=10.1109%2FSEB4SDG60871.2024.10630366&partnerID=40&md5=5dd9f4d620048caa7f0015fb3d2443c6
AB  - This study explores the efficacy of predictive algorithms for insider threat detection in organizational networks. Leveraging machine learning and deep learning techniques, the research identifies state-of-the-art models and assesses challenges associated with scalability and imbalanced datasets. Following the Prisma International Standards methodology, 531 articles were initially retrieved, with 59 high-quality articles selected for detailed analysis. The findings reveal a multifaceted approach, with 58.8% proposing new models, 23.5% implementing and evaluating, and 17.6% lacking explicit metrics. SVM and RNNs emerged as frequently used algorithms, reflecting versatility and effectiveness in network traffic analysis for insider threat detection. The study provides insights into current trends, challenges, and potential avenues for future research in the realm of insider threat detection. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Bani Ahmad, A.Y.A.
TI  - CS Challenge in Creating AI-Integrated System
PY  - 2024
SP  - 1515
EP  - 1520
DO  - 10.1109/ICACITE60783.2024.10617153
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201812863&doi=10.1109%2FICACITE60783.2024.10617153&partnerID=40&md5=9eb1abcd8502e30e0e0429dffa7a866f
AB  - Recent developments have integrated it into most of the systems of accounting. It has changed the face of finance with new operational efficiency and quality of service like never before. However, even as this advance sets in, it presents different cybersecurity challenges that need to be addressed on an emergency basis. This paper looks into all the major cybersecurity challenges that an AI-integrated accounting system may have to face, elaborating upon them in detail in order to present critical problems and applicable strategies of risk minimization. Integration of AI with the accounting system would bring out a new set of weaknesses that, if once pinpointed by any potential attacker, would easily let an organization fall for threats like data breaches, unauthorized access, and manipulation of financial records. The major challenges involved will include the security and integrity of AI-driven platforms over which the very sensitive financial data is going to be processed and stored. Such systems, therefore, become highly vulnerable to adversarial attacks and exploitation of AI algorithmic vulnerabilities, which may culminate in fraudulent activities and financial losses, for systems that rely a lot on the accurate functioning of these algorithmic machine learning models. More importantly, with the present-day integrated accounting systems through AI, the risk for more alarming cyber threats is pretty high-when one system is vulnerable to attacks, or worse still gets attacked, the damage might cascade across networks. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - CHAP
AU  - Nassir, N.F.M.
AU  - Abdul Rauf, U.F.A.
AU  - Zainol, Z.
AU  - Ghani, K.A.
TI  - Insider Threat Prediction Techniques: A Systematic Review Paper
PY  - 2024
T2  - SpringerBriefs in Applied Sciences and Technology
VL  - Part F3223
SP  - 119
EP  - 126
DO  - 10.1007/978-3-031-63326-3_15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201318999&doi=10.1007%2F978-3-031-63326-3_15&partnerID=40&md5=9a5cf6f8f5c43ad17499f022eb8a7fd7
AB  - The aim of this study is to increase comprehension and provide a systematic review of insider threat prediction techniques explored by previous researchers. The advantages and disadvantages of machine learning techniques, statistical techniques, hybrid techniques, and knowledge-based techniques are highlighted. In addition, prospective work obstacles and suggestions have been discussed. This study examined insider threat prediction trends in scholarly articles published between 2007 and 2022. Researchers, practitioners, and policymakers who are interested in predicting insider threats should find this study beneficial. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Rajendran, T.
AU  - Mohamed Imtiaz, N.
AU  - Jagadeesh, K.
AU  - Sampathkumar, B.
TI  - Cybersecurity Threat Detection Using Deep Learning and Anomaly Detection Techniques
PY  - 2024
DO  - 10.1109/ICKECS61492.2024.10617347
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201288431&doi=10.1109%2FICKECS61492.2024.10617347&partnerID=40&md5=d584e8a96d75a4325ecb79148a0b57cd
AB  - Through the use of combined deep learning and anomaly detection approaches, this research investigates the area of cybersecurity threat detection. The study proves the framework's extraordinary success in recognizing as well as mitigating diverse cyber dangers, including insider threats and zero-day attacks, through practical testing and case studies. The framework establishes itself as a proactive cybersecurity solution adaptive to the changing threat landscape due to its high accuracy of 95%, low amount of false positives 5%, and quick reaction times. The recommendations cover user training, scalability, regulatory compliance, including cross-disciplinary collaboration. Behavioral analysis, AI explainability, IoT security, and countering quantum computing concerns should be the main areas of future research. These revelations help the cybersecurity industry become more resilient and well-prepared. In this research investigation, experiments on threat detection were conducted using deep learning algorithms, with a specific focus on Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). The findings of the study reveal that a detection accuracy of 93% was achieved by CNN, while a higher accuracy of 96% in threat detection was exhibited by RNN. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 14
ER  -

TY  - CONF
AU  - Ņikiforova, O.
AU  - Zabiniako, V.
TI  - Beyond Information System User Behavior Models: The Power of User Groups in Preventing Insider Attacks
PY  - 2024
T2  - Lecture Notes in Networks and Systems
VL  - 1065 LNNS
SP  - 670
EP  - 684
DO  - 10.1007/978-3-031-66329-1_43
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200965926&doi=10.1007%2F978-3-031-66329-1_43&partnerID=40&md5=a946963cac7709d9eb0893f68cf1358d
AB  - Traditional information security methods, such as access control and firewalls, cannot always provide effective protection against internal threats. Analysis of user behavior allows us to identify anomalous actions that may indicate an attempt to gain unauthorized access to information or commit other illegal actions. The most common sign about suspicious user behavior is changing system usage patterns, atypical data queries, an attempt to access unallowed resources, sudden change in workload, etc. Various methods can be used to analyze user behavior, such as collection and analysis of data about user actions in the system and application of machine learning methods to identify anomalous patterns. All these methods analyze the behavior of individual users relative to their usual behavior. Such an analysis may be inaccurate if it is determined that the user regularly makes unauthorized use of information systems. This paper proposes grouping users according to their behavior patterns and analyze the behavior of each individual user against the behavior that is expected for the group. Then, by excluding user behavior data from the group’s expected behavior pattern, the behavior pattern of the individual user can be analyzed against the behavior of the remained users in the group. The novelty consists in obtaining more precise behavioral analyzes by introducing the concept of subgroups (groups consisting of the users remaining after the extraction of the respective user, which is analyzed against expected behavior model of its group). © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Gopi, A.
AU  - Aravinth, S.S.
AU  - Charishma, N.
AU  - Sravani, B.
AU  - Gayatri, N.
AU  - Gowtham, K.
TI  - A Holistic Approach with Behavioral Anomaly Detection (BAD) for Mitigating Insider Threats in Cloud Environments
PY  - 2024
DO  - 10.1109/ICCDS60734.2024.10560376
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197849244&doi=10.1109%2FICCDS60734.2024.10560376&partnerID=40&md5=d6d45a5c8e01be73de280a18b9ef2149
AB  - Insider threats remain a critical concern in cloud environments, necessitating robust strategies for detection and mitigation. This paper proposes a holistic approach that integrates Behavioral Anomaly Detection (BAD) with existing security measures to mitigate insider threats effectively. BAD focuses on identifying abnormal behaviors that deviate from established patterns, making it a valuable tool for detecting insider threats. The holistic approach combines BAD with other security mechanisms such as access control, encryption, and user monitoring to create a comprehensive defense strategy. The key advantage of this approach is its ability to adapt to the dynamic nature of insider threats. By continuously analyzing user behavior and identifying anomalies, the system can detect potential threats early, allowing for timely intervention. Moreover, the holistic approach reduces the number of false positives compared to using BAD in isolation, thereby improving the efficiency of threat detection. To demonstrate the effectiveness of the approach, we provide a detailed implementation plan and showcase case studies from real-world cloud environments. Our evaluation results indicate that the holistic approach significantly enhances the security posture of cloud environments against insider threats. By leveraging BAD and integrating it into a holistic security framework, organizations can better protect their sensitive data and infrastructure from insider threats. This research contributes to the field of cloud security by providing a practical and effective strategy for mitigating insider threats. It also opens up avenues for future research, such as exploring the integration of machine learning techniques to enhance BAD's detection capabilities further. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Dixit, N.
AU  - Gupta, R.
AU  - Yadav, P.
TI  - User Behavior Analysis to Detect Insider Threat by Using Machine Learning Algorithms
PY  - 2024
DO  - 10.1109/ICIPTM59628.2024.10563542
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197666789&doi=10.1109%2FICIPTM59628.2024.10563542&partnerID=40&md5=f2f8daed70b2a0a981496cba32f1f684
AB  - Insider threats, in which someone within an organization poses a risk, are widely regarded as the most dangerous in cybersecurity. Many analysts are working hard to identify and prevent these risks. However, the most difficult aspect of cybersecurity is determining which computers and users are affected. These computers are connected to servers or monitored by them, but there are no clear indications that attackers are targeting specific users. It is critical for the organization to defend against both internal and external cyberattacks. Cyber security measures should be up to date is critical for protecting our organizations. External threats can be identified easily but to identify insider threats is a complex task. Recently, there has been an increased emphasis on computer security, particularly in developing internal risk detection systems. Artificial intelligence, Internet of Things, distributed computing, data mining, portable ledgers, and data discovery are some of the advanced methods that have gained popularity for mitigating insider risk. Each of these approaches is unique and takes insider threats into account to a varying degree. In this paper, we use different machine learning models to find out the insiders. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Ali, G.
AU  - Mijwil, M.M.
AU  - Buruga, B.A.
AU  - Abotaleb, M.
TI  - A Comprehensive Review on Cybersecurity Issues and Their Mitigation Measures in FinTech
PY  - 2024
T2  - Iraqi Journal for Computer Science and Mathematics
VL  - 5
IS  - 3
SP  - 45
EP  - 91
DO  - 10.52866/ijcsm.2024.05.03.004
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197614819&doi=10.52866%2Fijcsm.2024.05.03.004&partnerID=40&md5=8569ab5344a2b59d93e3fd05f60bc9cc
AB  - The fourth industrial revolution has seen the evolution and wide adoption of game-changing and disruptive innovation "financial technologies (FinTech)" around the globe. However, the security of FinTech systems and networks remains critical. This paper comprehensively reviews the evolving landscape of cybersecurity issues within the FinTech sector and explores effective mitigation measures. Four independent researchers reviewed relevant literature from IEEE Xplore Digital Library, ScienceDirect, Taylor & Francis, Emerald Insight, Springer, SAGE, Wiley Online Library, Hindawi, MDPI, ACM Digital Library, IGI Global, and Google Scholar. The research paper begins by examining the history and evolution of FinTech, drivers for the growth of FinTech, segments of the FinTech industry, FinTech ecosystem, FinTech business model, and FinTech application. Subsequently, it then delves into an analysis of the most pressing cybersecurity issues confronting FinTech firms, such as privacy concerns, data breaches, malware attacks, hacking, insider threats, identity theft, social engineering attacks, distributed denial-of-service attacks, and others. In response to these cybersecurity issues, the paper evaluates various mitigation strategies and best practices adopted by FinTech firms and regulatory bodies globally. These measures include technological solutions such as authentication and access control mechanisms, cryptography, big data analytics, intrusion detection/prevention systems, regular data backup, artificial intelligence and machine learning, cloud computing technologies, blockchain technologies, and fraud detection and prevention systems. The paper also emphasizes the importance of FinTech regulatory sandboxes, regulatory compliance, basic security training, continuous monitoring of threats, zero-trust policy, robust cybersecurity culture, regular testing, and stringent security policies to strengthen the FinTech ecosystem's cyber resilience. Based on empirical research, industry reports, and regulatory guidelines, this review brings together existing information and highlights upcoming trends in FinTech cybersecurity. It emphasizes the importance of a collaborative strategy combining industry stakeholders, regulators, legislators, and cybersecurity specialists to address the growing cyber threat situation successfully. Ultimately, this research will help develop robust security mechanisms for FinTech systems and networks to achieve sustainable financial inclusion. © 2024 College of Education, Al-Iraqia University. All rights reserved.
M3  - Review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 12
ER  -

TY  - JOUR
TI  - 18th International Conference on Risks and Security of Internet and Systems, CRiSIS 2023
PY  - 2024
T2  - Lecture Notes in Computer Science
VL  - 14529 LNCS
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197596821&partnerID=40&md5=32e801abccd52d872fc7363a30cbabed
AB  - The proceedings contain 18 papers. The special focus in this conference is on Risks and Security of Internet and Systems. The topics include: EHRVault: A Secure, Patient-Centric, Privacy-Preserving and Blockchain-Based Platform for EHR Management; smart Contracts for a Secure and Privacy-Preserving Smart Grid; formalizing for Proving the System Safety of the Software Component for a Small Sized Guided Transport System; A New Efficient PUF-Based Mutual Authentication Scheme for Drones; Towards a B-Method Framework for Smart Contract Verification: The Case of ACTUS Financial Contracts; A Review of the Progressive Odyssey of AI-Driven Intrusion Detection Within Embedded Systems; preface; a Collaborative Real-Time Object Detection and Data Association Framework for Autonomous Robots Using Federated Graph Neural Network; VAE-GAN for Robust IoT Malware Detection and Classification in Intelligent Urban Environments: An Image Analysis Approach; securing Autonomous Vehicles: Fundamentals, Challenges, and Perspectives; improvement and Evaluation of Resilience of Adaptive Cruise Control Against Spoofing Attacks Using Intrusion Detection System; A Novel Software Defined Security Framework for SDN; FERROMOBILE and Security for Low Moment of Traffic Level Crossing; experimental Toolkit for Manipulating Executable Packing; deep Learning-Based Outliers Detection in Compressed Trajectories; a Process-Centric Approach to Insider Threats Identification in Information Systems.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Altuwaijiri, R.
AU  - Alshaher, H.
TI  - Insider Threat Detection: Exploring User Event Behavior Analytics and Machine Learning in Security Reviews
PY  - 2024
T2  - Journal of Cybersecurity and Information Management
VL  - 13
IS  - 2
SP  - 171
EP  - 181
DO  - 10.54216/JCIM.130213
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196153160&doi=10.54216%2FJCIM.130213&partnerID=40&md5=fc41a61f032ffcf36edf43f3971b5e9e
AB  - With the exponential increase in technology use, insider threats are also growing in scale and importance, becoming one of the biggest challenges for government and corporate information security. Recent research shows that insider threats are more costly than external threats, making it critical for organizations to protect their information security. Effective insider threat detection requires the use of the latest models and technologies. Although a large number of insider threats have been discovered, the field is still limited by many issues, such as data imbalance, false positives, and a lack of accurate data, which require further research. This survey investigates the existing approaches and technologies for insider threat detection. It finds and summarizes relevant studies from different databases, followed by a detailed comparison. It also examines the types of data used and the machine learning models employed to detect these threats. It discusses the challenges researchers face in detecting insider threats and future trends in the field. © 2024, American Scientific Publishing Group (ASPG). All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Ņikiforova, O.
AU  - Zabiniako, V.
TI  - Towards Validation of Insider Threat Identification Algorithm with Synthetic Data
PY  - 2024
T2  - CEUR Workshop Proceedings
VL  - 3698
SP  - 48
EP  - 57
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195490379&partnerID=40&md5=b83eff9f956435de0c0d9248a9929cca
AB  - This paper addresses the challenge of detecting insider threats in cybersecurity by proposing behavior model-driven approaches. It argues that existing datasets are incapable to capture nuanced user activities accurately and proposes an enhanced dataset generated by more elegant structure. The paper discusses the evolving threat situations and the need for proactive cybersecurity measures, presents a taxonomy of insiders, and emphasizes the importance of behavior-driven approaches. It mentions existing datasets limitations and introduces the proposed data generator structure, explaining its components and implementation logic. The paper illustrates a use case showcasing the application of generated data for insider threat identification. It concludes by stressing the significance of behavior-driven approaches and high-quality datasets in enhancing detection capabilities against insider threats. © 2024 Copyright for this paper by its authors.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Alshebli, S.
AU  - Alshehhi, M.
AU  - Yeun, C.Y.
TI  - Investigating How Data Poising Attacks Can Impact An EEG-Based Federated Learning Model
PY  - 2024
DO  - 10.1109/ICCR61006.2024.10532875
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195146138&doi=10.1109%2FICCR61006.2024.10532875&partnerID=40&md5=ec4704a7f2bd452c98b13a144bf4a489
AB  - Detecting potential security threats from individuals within an organization can be achieved using an Electroencephalogram (EEG), which captures the brain's electrical activity. The concept is based on the premise that certain brainwave patterns might be associated with malicious intentions or deceptive behaviors. Recent research on insider threat detection has utilized traditional machine learning classifiers to recognize patterns in brainwave data that correlate with malicious intent. However, these methods pose privacy and data security concerns because they require access to all user data. A recently introduced framework, Federated Learning (FL), offers a solution to this problem. FL aims to develop a global model classifier without the need to access users' local data, thus safeguarding their privacy and sensitive information. Thus, we developed an FL-based insider threat detection model trained on a dataset that contains the EEG signals of 17 participants captured from five electrodes across five power bands using the Emotiv Insight. The model's accuracy within our framework attained a rate of (94.71%) for MLP. However, this method faces potential security threats and attacks, as clients could act maliciously, or external malicious actors might disrupt the network. Therefore, we additionally explore the data poisoning attacks, emphasizing label-flipping scenarios within our federated learning system for EEG-based insider threat detection and illustrating how factors such as the number of poisoned clients and the percentage of poisoning affect an FL-based system. Based on our findings, a higher number of poisoned clients is much more damaging to FL-based systems and should thus be a focal point of consideration in the security design process of these systems. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Alsereidi, M.
AU  - Awadallah, A.
AU  - Alkaabi, A.
AU  - Yoon, S.
AU  - Yeun, C.Y.
TI  - Data Poisoning Against Federated Learning: Comparative Analysis Under Label-Flipping Attacks and GAN-Generated EEG Data
PY  - 2024
DO  - 10.1109/ICCR61006.2024.10533012
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195113375&doi=10.1109%2FICCR61006.2024.10533012&partnerID=40&md5=bccaa67ef29ac3d84d6f1eb97a148dd6
AB  - Federated Learning (FL) has emerged as a privacy-preserving machine learning approach, enabling collaborative model training across devices while maintaining the decentralization of raw data. This paper investigates the application of FL in insider threat detection, a critical aspect of organizational security that addresses potential risks posed by individuals with access to sensitive data. We focus on using Electroencephalogram (EEG) data to identify malicious intentions, which consists of highly sensitive brain signals that we aim to safeguard by employing FL. Despite its advantages, FL still encounters a rising threat from data poisoning attacks. This study investigates the resilience of our FL model against label-flipping attacks, utilizing three classifiers: Multiplayer Perceptron (MLP), Convolutional Neural Network (CNN), and an ensemble learning classifier, the Voting Classifier (VC). Due to insufficient EEG data, a Generative Adversarial Network (GAN) model is utilized to augment and increase the size of the data. Our findings reveal that VC demonstrates the highest performance with an accuracy of 95% for the original dataset. In contrast, CNN is the sole classifier that outperformed others with the GAN-generated dataset, achieving an accuracy of 93.5%. Furthermore, we examine various cases and scenarios of label-flipping, demonstrating that compromising one client (device) in an FL framework has the least overall performance degradation on the model, emphasizing the efficacy of FL in fostering collaborative learning. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Lavanya, P.
AU  - H, H.
AU  - Shankar Sriram, V.S.
TI  - Mitigating Insider Threat: A Neural Network Approach for Enhanced Security
PY  - 2024
T2  - IEEE Access
VL  - 12
SP  - 73752
EP  - 73768
DO  - 10.1109/ACCESS.2024.3404814
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194036092&doi=10.1109%2FACCESS.2024.3404814&partnerID=40&md5=dbf86586a58ac532c68f1c90fdcc1a9f
AB  - Detecting insider threats is the foremost challenge in many institutions because of the abnormal behavior of legitimate access and network crawling in the Internet of Things (IoT) environment. The insider activities of the institution's data are submerged in many regular activities, leading to a data imbalance problem. Existing insider threat detection techniques often fail to address the data imbalance problem in the insider threat data of IoT-enabled institutions, thereby causing deterioration in detection performance. Thus, this paper presents a novel Enhanced Bidirectional Generative Adversarial Network (EBiGAN) for adversarial sample generation and a Deep Neural Network (DNN) with the Probability of Improvement (PI) acquisition function of Bayesian optimization to detect insiders in an IoT enabled institutions. The proposed model involves three modules: (1) Improved PCA for extracting user functionality samples and outlier estimators of k-means for grouping scenario-based user functional data. (2) Bidirectional GAN with an additional discriminator to ensure the quality of the generated samples (3) The PI acquisition function of Bayesian Optimization for tuning the hyperparameter to improve the performance of the DNN model for insider threat detection to secure IoT-enabled institutions. The performance of the Enhanced BiGAN and DNN-PI was evaluated using a benchmark institutional dataset. The experimental results show that the proposed model identifies the suspicious behavior of insiders with a high detection rate and minimal false alarm rate in an IoT infrastructure. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 7
ER  -

TY  - JOUR
AU  - Zhu, X.
AU  - Dong, J.
AU  - Qi, J.
AU  - Zhou, Z.
AU  - Dong, Z.
AU  - Sun, Y.
AU  - Wang, M.
TI  - AUTH: An Adversarial Autoencoder Based Unsupervised Insider Threat Detection Scheme for Multisource Logs
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 9
SP  - 10954
EP  - 10965
DO  - 10.1109/TII.2024.3393491
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194034580&doi=10.1109%2FTII.2024.3393491&partnerID=40&md5=3918bb9a397e946c322f95f07c3be02d
AB  - Deep learning has shown broad research prospects in addressing insider threats, a serious problem currently facing industrial information systems. Although deep learning is able to capture effective feature representations from complex multidimensional data, there are still issues such as strong stealth of insider threat behavior and the imbalance data that need to be solved. Therefore, we propose an adversarial Autoencoder based Unsupervised insider Threat detection scHeme (AUTH). Compared to other methods, AUTH fully considers the role of time feature and event feature in threat detection. In addition, in order to improve the performance of autoencoder models to detect covert threat behaviors, AUTH drives a temporal convolutional network and long short-term memory network-based Adversarial Autoencoder (TL-AAE). Generative Adversarial Theory is introduced to solve the problem of uncertainty in the latent feature of the encoder. Finally, with the sufficient experiments on public datasets, we demonstrate that the usefulness of adding time features and the proposed TL-AAE model to improve threat detection performance. Compared with the baseline, AUTH obtains the area under curve value of 0.932, which is 4.95% higher than the highest result obtained by the baseline. In addition, AUTH obtains the EER value of 0.146, which is 12.57% lower than the lowest result of the baseline. © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Ramasami, S.
AU  - Maheswari, P.
TI  - Securing Electronic Health Records from Insider Threats in Smart City Healthcare Cloud Using Machine Learning Approach
PY  - 2024
SP  - 643
EP  - 648
DO  - 10.1109/ICICV62344.2024.00107
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193247275&doi=10.1109%2FICICV62344.2024.00107&partnerID=40&md5=9daa33bb5fbde507cdb3f494e07894b5
AB  - In recent years, healthcare in smart cities is considered as significant to create a more resilient and well-informed healthcare ecosystem. The integration of cloud computing in healthcare industry has facilitated the storage and sharing of electronic health records (EHRs), enabling seamless access to medical information. However, this transition to cloud-based systems has introduced new security challenges, particularly the risk of insider threats. Insiders with authorized access to cloud-based EHR systems, such as healthcare professionals and cloud service providers, may exploit vulnerabilities or misuse sensitive patient data, leading to privacy breaches and unauthorized disclosure. This research work presents an innovative approach to securing EHRs from insider threats in the cloud using Gaussian Mixture Model and Classification algorithms. These techniques analyze user behaviour patterns and detect anomalous activities that may indicate insider threats. Here UK hospital electronic patient health record data set is used to conduct the experiments. The proposed approach comprises two key stages. In the initial stage, the unsupervised Gaussian Mixture Model is utilized to find the abnormal patterns in the dataset and label each record in the dataset as normal or anomaly. The second stage involves different supervised classification algorithms namely SVM, KNN, DT, NB and RF are used to classify the new instance. The results demonstrate that the Random Forest (RF) achieves high accuracy in detecting insider threats with an accuracy of 99.97%. The findings of this research contribute to the field of healthcare data security by offering an intelligent and proactive solution for mitigating insider threats to cloud-based EHRs in Smart city environments. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Xiao, F.
AU  - Hong, W.
AU  - Yin, J.
AU  - Wang, H.
AU  - Cao, J.
AU  - Zhang, Y.
TI  - A Study on Historical Behaviour Enabled Insider Threat Prediction
PY  - 2024
T2  - Lecture Notes in Computer Science
VL  - 14333 LNCS
SP  - 464
EP  - 476
DO  - 10.1007/978-981-97-2387-4_31
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192824495&doi=10.1007%2F978-981-97-2387-4_31&partnerID=40&md5=6403fa3a41b94eaaab4560a70d49d92e
AB  - Insider threats have been the major challenges in cybersecurity in recent years since they come from authorized individuals and usually cause significant losses once succeeded. Researchers have been trying to solve this problem by discovering the malicious activities that have already happened, which offers not much help for the prevention of those threats. In this paper, we propose a novel problem setting that focuses on predicting whether an individual would be a malicious insider in a future day based on their daily behavioral records of the previous several days, which could assist cybersecurity specialists in better allocating managerial resources. We investigate seven traditional machine learning methods and two deep learning methods, evaluating their performance on the CERT-r4.2 dataset for this specific task. Results show that the random forest algorithm tops the ranking list with f1 = 0.8447 in the best case, and deep learning models are not necessarily better than machine learning models for this specific problem setting. Further study shows that the historical records from the previous four days around can offer the most predicting power compared with other length settings. We publish our codes on GitHub: https://github.com/mybingxf/insider-threat-prediction. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - D, D.
AU  - Dhanya, C.J.
AU  - S, S.
AU  - Padmavathi, G.
AU  - Suthishni, D.N.P.
TI  - Cloud Insider Threat Detection using Deep Learning Models
PY  - 2024
SP  - 434
EP  - 438
DO  - 10.23919/INDIACom61295.2024.10498767
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191710095&doi=10.23919%2FINDIACom61295.2024.10498767&partnerID=40&md5=49f5817ea5fa0fe06dcf65a8da0a230a
AB  - Insider attacks are a major threat to cloud security since they can harm organizational assets and have overlapping security mechanisms. Therefore, insider threat detection in the cloud environment is necessary to compromise such attacks. Past research applied machine learning and Deep Learning (DL) techniques for recognizing insider threats in the cloud. The self-learning capabilities in network layers of deep learning could enhance and handle class imbalance problems in detecting and recognizing cloud insider threats. In this paper, the pre-processed insider threat data is obtained by applying various data preprocessing techniques, including data integrity, data transformation, and data sampling using Synthetic-Minority Over-sampling Technique (SMOTE) to deal with the issue of the imbalanced dataset. The balanced data obtained from preprocessing algorithms are classified using DL algorithms, including Conventional Neural networks (CNN) and Long Short-Term Memory (LSTM) for cloud Insider Threat Detection. The experimental result shows that the performance of CNN with SMOTE-based balanced data outperforms LSTM with SMOTE regarding the accuracy, f-score, precision, and recall for detecting cloud insider threats. © 2024 Bharati Vidyapeeth, New Delhi.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 5
ER  -

TY  - CONF
AU  - Kothari, N.
AU  - Bhardwaj, C.
AU  - Mishra, S.
AU  - Satapathy, S.K.
AU  - Cho, S.-B.
AU  - Mallick, P.K.
TI  - Towards Insider Threat Resilience: A Proposed Mitigation Model
PY  - 2024
SP  - 62
EP  - 67
DO  - 10.1109/ESIC60604.2024.10481615
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190958305&doi=10.1109%2FESIC60604.2024.10481615&partnerID=40&md5=2a86a41e5ca6e5150a65afcd893f6e6b
AB  - Businesses are increasingly concerned about insider threats, which highlights the need for effective mitigation strategies. This paper examines the variety of insider threats and provides a thorough plan for lowering this risk. Examining different internal threat types and their motives may help organizations identify any possible weak points. This paper also looks at technological advancements like user behavior analytics and anomaly detection as well as organizational practices like security culture promotion and employee training. It is advised to create a comprehensive framework for preventing insider threats that incorporates technology controls, organizational procedures, and human factors. In the implementation, a Windows application developed with Flutter and Dart takes user-input IP addresses to modify a Python script file using file handling. It also handles file name and path changes in the script, converts it into an executable file, and stores it with a data file. The application includes pages for inputting IP addresses, selecting files, and protecting the script. After protection, the executable file is saved in an executable folder, which can be further converted into a steganography file. This research focuses on evaluating the file's behaviour on different networks to enhance security. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Padiet, P.
AU  - Islam, R.
AU  - Khan, M.A.
TI  - Users’ Scenario-Base for Analysing Insider Threat Detection Based on User’s Downloads Activity Logs
PY  - 2024
T2  - Lecture Notes in Networks and Systems
VL  - 920 LNNS
SP  - 457
EP  - 472
DO  - 10.1007/978-3-031-53963-3_30
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189368278&doi=10.1007%2F978-3-031-53963-3_30&partnerID=40&md5=6ea675b270244a4bd4765ce5ad9f3886
AB  - The persistence and growth of insider threats pose a significant challenge to the information security community. Malicious insiders have been identified as one of the most detrimental threats to sensitive data including systems of enterprises and government agencies. Detecting insider threats presents a unique set of challenges, including dealing with large and imbalanced datasets and limited availability of ground truth information. Insider threats pose a serious risk to organizations, financial institutions, and government agencies. Former and current employees often exploit their trusted positions to disrupt regular organizational functions or unlawfully disclose classified or confidential information for personal or group gain. These actions can lead to severe financial, reputational, and operational consequences for the affected entities. To address this pressing issue, the research presented in this paper proposes a user-centric approach for insider threat detection. This approach focuses on leveraging downloads activity logs to analyse and detect patterns associated with insider threats. By examining user behaviours related to downloading activities, valuable insights to gained, and existing detection techniques can be enhanced. The proposed methodology aims to provide practical solutions for identifying and mitigating potential insider threats within organisations. Among the selected classifiers, RandomTree exhibited the highest accuracy rate of 0.981%, making it the most suitable option for the insider threat detection system. The accuracy rate indicates the overall correctness of the model’s predictions, with a higher value indicating a better performance in classifying instances correctly. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - He, D.
AU  - Lv, X.
AU  - Xu, X.
AU  - Chan, S.
AU  - Choo, K.-K.R.
TI  - Double-Layer Detection of Internal Threat in Enterprise Systems Based on Deep Learning
PY  - 2024
T2  - IEEE Transactions on Information Forensics and Security
VL  - 19
SP  - 4741
EP  - 4751
DO  - 10.1109/TIFS.2024.3372771
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187388933&doi=10.1109%2FTIFS.2024.3372771&partnerID=40&md5=314aee23db3f54fcdd097ac8e9af400a
AB  - In recent years, phishing email-mediated attacks are proliferating. When victims are enterprise employees, internal security of the enterprise systems will also be threatened. Currently, blockchain technology can effectively improve the security and privacy of traditional email, but attacks initiated from within are still fatal. Therefore, we propose a double-layer detection framework in this paper. Firstly, from the perspective of individual security, Long Short-Term Memory (LSTM) and extreme gradient boosting tree (XGBoost) are used to build a phishing email detection model. The model generalization ability and precision rate are improved by adding a custom loss function in the training process. Then, from the perspective of group security, Bidirectional LSTM and Attention mechanism are used to build an insider threat detection model. Our model has better results for multi-domain time series and anomaly detection in comparison to different models and existing insider threat detection models. We test the effectiveness of the proposed framework through real phishing email cases and insider threat attack events on our simulation verification platform. The experimental results demonstrate that our proposed framework can protect enterprise systems from phishing attacks and insider threats. We also point out that this framework can be applied to mitigate the increasingly serious blockchain security threats. © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 12
ER  -

TY  - JOUR
AU  - Al-Shehari, T.
AU  - Rosaci, D.
AU  - Al-Razgan, M.
AU  - Alfakih, T.
AU  - Kadrie, M.
AU  - Afzal, H.
AU  - Nawaz, R.
TI  - Enhancing Insider Threat Detection in Imbalanced Cybersecurity Settings Using the Density-Based Local Outlier Factor Algorithm
PY  - 2024
T2  - IEEE Access
VL  - 12
SP  - 34820
EP  - 34834
DO  - 10.1109/ACCESS.2024.3373694
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187367230&doi=10.1109%2FACCESS.2024.3373694&partnerID=40&md5=18255cd73bf677cbd96805e04df0f8e2
AB  - In today's interconnected world, cybersecurity has emerged as a critical domain for ensuring the integrity, confidentiality, and availability of digital assets. Within this sphere, insider threats represent a unique and particularly insidious class of security risks, originating not from external hackers but from within the organization itself. These threats are perpetrated by individuals with inside information concerning the organization's security practices, data, and computer systems. Traditional security measures like firewalls, intrusion detection systems, and antivirus software are often inadequate for tackling insider threats effectively, owing to their focus on external threats. This inadequacy underscores the urgent need for the development and implementation of more sophisticated, targeted detection techniques for insider threats. In response to this challenge, our research introduces an innovative approach that employs the Density-Based Local Outlier Factor (DBLOF) algorithm, fine-tuned to specifically tackle the challenges posed by the imbalanced nature of the CERT r4.2 insider threat dataset. This dataset is characterized by a highly skewed distribution, with a significant majority of benign instances and only a minimal proportion of malicious activities. Conventional detection algorithms often fail to effectively identify these rare but dangerous instances, leading to a high rate of false negatives. Our methodology capitalizes on the algorithm's ability to focus on the local density deviation of data points, thereby enabling the precise identification of outliers that are indicative of potential insider threats. Through rigorous testing and validation processes, we have achieved outstanding results, with an of F-score 98%. These remarkable outcomes not only affirm the effectiveness of the DBLOF algorithm as a powerful tool for combating insider threats but also contribute valuable insights to the broader academic and professional discourse on cybersecurity. Importantly, our findings have practical implications, offering organizations actionable recommendations for boosting their internal security mechanisms against the complex and evolving landscape of insider threats. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 19
ER  -

TY  - JOUR
AU  - Alzaabi, F.R.
AU  - Mehmood, A.
TI  - A Review of Recent Advances, Challenges, and Opportunities in Malicious Insider Threat Detection Using Machine Learning Methods
PY  - 2024
T2  - IEEE Access
VL  - 12
SP  - 30907
EP  - 30927
DO  - 10.1109/ACCESS.2024.3369906
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186958158&doi=10.1109%2FACCESS.2024.3369906&partnerID=40&md5=b90f8089c55639231ad528f7f57514e8
AB  - Insider threat detection has become a paramount concern in modern times where organizations strive to safeguard their sensitive information and critical assets from malicious actions by individuals with privileged access. This survey paper provides a comprehensive overview of insider threat detection, highlighting its significance in the current landscape of cybersecurity. The review encompasses a broad spectrum of methodologies and techniques, with a particular focus on classical machine-learning approaches and their limitations in effectively addressing the intricacies of insider threats. Furthermore, the survey explores the utilization of modern deep learning and natural language processing (NLP) based methods as promising alternatives, shedding light on their advantages over traditional methods. The comprehensive analysis of results from experiments utilizing NLP and large language models to detect malicious insider threats on the CMU CERT dataset reveals promising insights. Studies surveyed in this paper indicate that these advanced techniques demonstrate notable efficacy in identifying suspicious activities and anomalous behaviors associated with insider threats within organizational systems. Additionally, the survey underscores the potential of NLP and large language model-based approaches, which can enhance threat detection by deciphering textual and contextual information. In the conclusion section, the paper offers valuable insights into the future directions of insider threat detection. It advocates for the integration of more sophisticated time-series-based techniques, recognizing the importance of temporal patterns in insider threat behaviors. These recommendations reflect the evolving nature of insider threats and emphasize the need for proactive, data-driven strategies to safeguard organizations against internal security breaches. In conclusion, this survey not only underscores the urgency of addressing insider threats but also provides a roadmap for the adoption of advanced methodologies to enhance detection and mitigation capabilities in contemporary cybersecurity paradigms. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 94
ER  -

TY  - CONF
AU  - Bhuvaneswari, R.
AU  - Kumar, E.K.
AU  - Padmasini, A.
AU  - Varma, K.V.P.
TI  - Insider threat detection of ransomware using AutoML
PY  - 2024
VL  - 1
SP  - 724
EP  - 733
DO  - 10.1201/9781003393580-107
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186642388&doi=10.1201%2F9781003393580-107&partnerID=40&md5=e973f00238cbef62f26ff7d77712160f
AB  - Insider threats are one of the biggest issues that modern-day organizations and many large-scale companies face. The inside threats are caused by the insiders who are authorized individuals, also may have proper access to sensitive and secret information, and may be aware of the weaknesses in the implemented systems and operational procedures. And, it is confirmed that these insider threats have already shown their great damaging power in securing important information and because of this, organizations require more proactive and modern-day solutions to support existing cybersecurity tools in order to detect and prevent them. Conventional interruption recognition frameworks neglect to be powerful in insider threats because of the absence of a wide range of information for insider ways of behaving. All things considered; a more complex and standard technique is expected to have a more profound comprehension of the ways that insiders speak with the information framework. Ransomware hackers appear to be adopting new methods in response to tightening security. Automated machine learning has been utilised in this work for detection of ransomware and we also included the ensembling method for a few algorithms that are suitable for the given dataset. © 2024 The Author(s).
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Kawalkar, S.A.
AU  - Bhoyar, D.B.
TI  - Design of an Efficient Cloud Security Model through Federated Learning, Blockchain, AI-Driven Policies, and Zero Trust Frameworks
PY  - 2024
T2  - International Journal of Intelligent Systems and Applications in Engineering
VL  - 12
IS  - 10s
SP  - 378
EP  - 388
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185117699&partnerID=40&md5=51740b6032ca8b9722863e72e3d4cba7
AB  - In the current era of cloud computing where most of the Organizations are shifting from local Infrastructure to Cloud network and hence Cloud security where most of sensitive data is stored is one of the key concerns for highly scalable and critical network deployments. As there is high increase in the use of cloud networks and computing because of simple Virtual machines and containers, the necessity for strong and stringent security measures to protect against complex cyber-attacks is very important than it was few years before.. Traditional cloud security models often grapple with limitations such as centralized data vulnerabilities, static security policies, and inadequate access control mechanisms. Cyber-attacks are getting complex and impacting organization with critical information and business loss. Dark Web attacks are more sophisticated and impacting tactically via various ways and mechanisms on cloud. The paper surveys the state-of-the-art in cloud n etwork and infrastructure security models and essentially evaluates their performance based on various risks, threats, vulnerabilities and empirical dataset collection and samples. The paper discusses the advantages and disadvantages of each model and highlights their suitability for different types of attacks. To address these challenges, this research introduces a groundbreaking complex and stringent security techniques and security framework, synergizing Federated Learning, Blockchain technology, AI-Driven Security Policy Management, and Zero Trust Network Access (ZTNA) principles. The proposed model leverages Federated Learning to decentralize machine learning processes, thereby safeguarding data privacy and minimizing the risks associated with centralized data repositories. Concurrently, the integration of Blockchain technology ensures immutable and transparent transaction records, enhancing the integrity and trustworthiness of cloud interactions. Complementing these, AI-Driven Security Policy Management, employing algorithms like Reinforcement Learning and Decision Trees, automates the generation and implementation of dynamic security policies. This AI-based approach is adept at responding to evolving threats and adapting to changing network conditions in real-time scenarios. Furthermore, the adoption of Zero Trust principles, operationalized through Software-Defined Perimeter frameworks, enforces a stringent 'never trust, always verify' approach. This paradigm shift is critical in fortifying access controls, effectively mitigating the risks of unauthorized access and insider threats. The interplay of these technologies culminates in a robust, resilient cloud security architecture sets. Empirical evaluation in varied cloud scenarios showcases notable enhancements in security metrics. The integrated model outperforms existing methods, achieving a 3.5% increase in precision, 4.9% in accuracy, 2.4% in recall, 3.5% in Area Under the Curve (AUC), and 1.9% in specificity, alongside a 4.5% reduction in response delay. These improvements signal a significant leap in cloud network security, offering a comprehensive solution to contemporary cyber threats. The impact of this work is profound, paving the way for more secure, reliable, and efficient cloud computing environments. © 2024, Ismail Saritas. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 14
ER  -

TY  - CONF
AU  - Ņikiforova, O.
AU  - Zabiniako, V.
AU  - Kornienko, J.
TI  - E-Step Control: Solution for Processing and Analysis of IS Users Activities in the Context of Insider Threat Identification Based on Markov Chain
PY  - 2024
T2  - Lecture Notes in Networks and Systems
VL  - 822
SP  - 345
EP  - 359
DO  - 10.1007/978-3-031-47721-8_23
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182516916&doi=10.1007%2F978-3-031-47721-8_23&partnerID=40&md5=6d232d31e1cac831ca1d749fdd3c565c
AB  - As the digitalization of everyday life develops and the use of information technology in various business domains increases with it, the demand for the existence of automatic tools for information protection and security also increases. In recent decades, information technology specialists have learned to sufficiently protect information systems against the evil actions of external attackers and to identify potential points, where systems can be hacked, but information systems insiders’ threats for unauthorized use of information are increasing. One of the approaches to reduce the risk of unauthorized data use by internal users of information systems is to base the monitoring of information systems usage on the analysis of users behaviour. The authors of the paper have implemented such an approach in the product “e-StepControl”, in which the work of each user in the information system can be analysed according to the typical behaviour model of this individual, and in cases where the user acts differently from the expected behaviour, a security incident can be identified due to the unexpected (therefore, suspicious) activity of the user. Also, such security incidents can be identified by comparing the behaviour of an individual user with other users with the same or similar behaviour within the information system usage, in other word—with the expected behaviour of the representatives of this user’s group or class. This grouping of users is essentially the machine learning-based performance of the task of clustering users of information systems according to such parameters as the activities performed by the user and their regularity, the sequence of activities to be performed, attributes of users and user sessions. Both individual and group user behaviour models can serve to identify security incidents, which are further confirmed or rejected by a security specialist by drawing relevant conclusions. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Besnaci, S.
AU  - Hafidi, M.
AU  - Lamia, M.
TI  - Log Analysis for Feature Engineering and Application of a Boosting Algorithm to Detect Insider Threats
PY  - 2024
T2  - Communications in Computer and Information Science
VL  - 1940 CCIS
SP  - 268
EP  - 284
DO  - 10.1007/978-3-031-46335-8_21
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177199842&doi=10.1007%2F978-3-031-46335-8_21&partnerID=40&md5=b087593f348655bf24576dc2733aa653
AB  - The insider threat has captured the attention of a large number of researchers, as a sensitive and critical issue for most organizations in today’s digital world. It is also a major source of information security and can cause more damage and financial loss than any other threat. In this article, we’ve used feature engineering for features that represent users’ day-to-day activities. We tried different machine learning models such as random forest, xgboost and Catboost. Since the data used to detect malicious activity is unbalanced, the target audience is small. We used KMeansSmote to balance the classes of learning so that the algorithms can learn both classes well. And we used the catboost algorithm to identify the malicious user. The dataset used to evaluate this model is Cert v4.2. CatBoost outperformed other models with the highest F1-score of 95%. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Shelke, P.
AU  - Hämäläinen, T.
TI  - Analysing Multidimensional Strategies for Cyber Threat Detection in Security Monitoring
PY  - 2024
T2  - European Conference on Information Warfare and Security, ECCWS
SP  - 748
EP  - 755
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021484533&partnerID=40&md5=195b60a1421a6523c39ab46e4483eb64
AB  - The escalating risk of cyber threats requires continuous advances in security monitoring techniques. This survey paper provides a comprehensive overview of recent research into novel methods for cyber threat detection, encompassing diverse approaches such as machine learning, artificial intelligence, behavioral analysis and anomaly detection. Machine learning plays a central role in cyber threat detection, highlighting the effectiveness of deep neural networks in identifying evolving threats. Their adaptability to changing attack patterns is emphasized, underlining their importance for real-time security monitoring. In parallel, ensemble learning is explored, combining multiple models to improve overall detection accuracy and create a robust defense against a spectrum of cyber threats. The literature reviewed highlights the importance of behavioral analysis, with a novel approach that integrates user behaviour profiling with anomaly detection. This has proven effective in identifying suspicious activity within a network, particularly insider threats and stealthy attacks. Another behavioral framework using User and Entity Behavior Analytics (UEBA) is presented for enhanced anomaly detection, highlighting the importance of context-aware monitoring in improving threat detection accuracy. Collaborative defense mechanisms emerge as a major focus of the research papers reviewed, exploring the potential of sharing threat information between organisations to enhance collective security monitoring. Their findings underscore the importance of a collaborative approach to staying ahead of rapidly evolving cyber threats. Some types of cyber-attacks are also analysed in the context of a security operations centre (SOC) monitoring environment using a security information and event management (SIEM) tool - Splunk. In conclusion, this survey paper synthesizes recent advances in cyber threat detection methods in security monitoring that integrate machine learning, behavioral analysis, and collaborative defense strategies. As cyber threats continue to evolve, these novel methods provide valuable insights for researchers, practitioners, and organisations seeking to strengthen their cybersecurity defenses. This concise overview emphasises the multi-dimensional approach required to secure digital ecosystems, providing a concise yet comprehensive guide to modern cyber threat detection strategies. © 2024 Curran Associates Inc.. All rights reserved.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 5
ER  -

TY  - CONF
AU  - Singh, S.K.
AU  - Bhambu, P.
AU  - Sandhu, A.
AU  - Kumar, A.
AU  - Sharma, D.
AU  - Pandey, A.
TI  - Achieving Cloud Security Solutions based on Machine Learning and Past Information
PY  - 2024
DO  - 10.1109/ARIIA63345.2024.11051704
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012099961&doi=10.1109%2FARIIA63345.2024.11051704&partnerID=40&md5=4a512a1dad80c5284aadd13efe824e8f
AB  - In recent years, the proliferation of cloud computing has revolutionized the way businesses operate, offering unparalleled scalability, flexibility, and cost-effectiveness. However, this rapid adoption of cloud services has also raised significant security concerns, stemming from the decentralized nature of cloud infrastructures and the increasing sophistication of cyber threats. Traditional security measures are often inadequate to address the dynamic and evolving nature of these threats, necessitating the integration of cutting-edge technologies such as machine learning. This paper presents a comprehensive review of cloud security solutions leveraging machine learning techniques. It begins by elucidating the unique security challenges posed by cloud environments, including data breaches, insider threats, and distributed denial-of-service (DDoS) attacks. Subsequently, it examines the fundamental principles of machine learning and its applicability to cloud security, highlighting its capacity to detect anomalies, predict potential threats, and automate incident response. The research rapid adoption of cloud computing has revolutionized the way businesses operate and store data. With this increased reliance on cloud services, the need for robust cloud security has never been greater. Traditional security measures are often insufficient to protect cloud-based assets from evolving cyber threats. This research explores the role of machine learning in enhancing cloud security, examining its applications, benefits, challenges, and prospects. Furthermore, the paper examines the challenges and limitations associated with the adoption of machine learning in cloud security, such as data privacy concerns, model interpretability, and adversarial attacks. It also discusses emerging trends and future directions in this field, including the integration of explainable AI techniques, federated learning approaches, and the convergence of machine learning with other cybersecurity technologies. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Zhong, C.
AU  - Pourbehzadi, M.
AU  - Javidi, G.
TI  - Insider Detection based on Behavior Sequences: A Transformer Approach
PY  - 2024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010830083&partnerID=40&md5=368e30f17018f9fa8102424557c869eb
AB  - Insider threats pose a unique challenge to organizational security. Traditional security measures struggle to distinguish malicious intent from benign behavior, exacerbated by the complexity of organizational data. While machine learning and deep learning offer promise in detecting insider threats, they often lack transparency in decision-making. To address these challenges, this paper introduces a transformer-based insider detection system developed within the Action Design Research framework. Emphasizing iterative development and practical relevance, our approach enhances both detection accuracy and explainability. Following structured stages of Diagnosis, Design, Implementation, and Evolution ensures that the system continually evolves to meet practical security needs, providing clearer insights into the decision-making process behind the detection of insider threats. © 2024 International Conference on Information Systems. All Rights Reserved.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Manavadaria, M.S.
AU  - Srinivas, T.A.S.
AU  - Ahamed, S.K.
AU  - Amshavalli, M.
AU  - Nadaf, A.B.
AU  - Bhoopathy, V.
TI  - Anomaly Detection Algorithms in Cybersecurity
PY  - 2024
SP  - 293
EP  - 314
DO  - 10.4018/979-8-3693-7540-2.ch013
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010552985&doi=10.4018%2F979-8-3693-7540-2.ch013&partnerID=40&md5=1db3ee91e64ee0d24588437fd2ec66f8
AB  - In Anomaly Detection Algorithms in Cybersecurity, this chapter go over the fundamentals of the algorithms and techniques used to spot cyber threats. These methods include statistical, machine learning, deep learning, and clustering. In order to find statistical outliers, traditional anomaly detection employs Gaussian Mixture Models, which model the system's normal behavior. In order to improve their anomaly detection abilities, SVM and RF learn on tagged datasets. Using autoencoders for complicated and multidimensional data sets, deep learning has stabilized anomaly detection. K- Means and DBSCAN are two alternatives that can cluster data points and find outliers. This chapter takes a look at the algorithms and how they're utilized for identifying insider threats, fraud, malware, and network intrusions. In order to improve cybersecurity anomaly detection methods and safeguard against a wide variety of digital threats, this chapter takes a look at existing algorithms and methodology, analyzes their uses, problems, and potential future developments. © 2025 by IGI Global Scientific Publishing. All rights reserved.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Kim, Y.
AU  - Kim, D.-H.
AU  - Kim, Y.-G.
TI  - Transfer Learning-Based Robust Insider Threat Detection
PY  - 2024
T2  - Proceedings of the IEEE International Conference on Trust, Security and Privacy in Computing and Communications, TrustCom
IS  - 2024
SP  - 2287
EP  - 2292
DO  - 10.1109/TrustCom63139.2024.00315
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006477680&doi=10.1109%2FTrustCom63139.2024.00315&partnerID=40&md5=79146303267f48ce00e67211d41941c5
AB  - A malicious insider's threats who has access to the organization's systems and is familiar with security policies are difficult to detect and can cause significant financial damage. A reconstruction-based anomaly detection method leveraging deep learning is one method for detecting insider threats. The method is employed to solve a data imbalance problem caused by the scarcity of abnormal data in real environments. The method trains a deep learning model to reconstruct normal data received from all users. After training, the model reconstructs normal data more accurately than abnormal data, and the reconstruction-based anomaly detection method can detect anomalies based on the reconstruction difference between normal and abnormal data. However, existing reconstruction-based anomaly detection methods train on all users' normal data using the same network parameters. Consequently, if a behavior is normal for one user but abnormal for another, the reconstruction model learns this behavior as normal because the reconstruction model trains only on normal behaviors. Since normal behaviors differ for each user depending on their position, role, and other factors within the organization, it is necessary to develop methods for detecting abnormal behaviors specific to each user. To address this problem, we propose a transfer learning-based insider threat detection method. The proposed method consists of 1) a pre-trained encoder that outputs latent representations of normal data for all users and 2) user-specific decoders assigned to each user, which are trained on the corresponding user's normal data to reconstruct their normal data. We evaluate the proposed method's detection rate (DR) and area under the curve (AUC) on the CERT dataset and compare it with a deep learning model trained on normal data from all users. The experimental results show that the proposed method achieves higher DR and AUC than the deep learning model. These results indicate that the proposed method enhances insider threat detection performance by enabling the detection of user-specific abnormal behaviors. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - He, M.
AU  - Li, W.
AU  - Xu, Z.
TI  - A Lower-Cost Insider Threat Detection Framework Based on User Cluster and Behavior Feature Analysis
PY  - 2024
SP  - 19
EP  - 26
DO  - 10.1109/SpaCCS63173.2024.00010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004789865&doi=10.1109%2FSpaCCS63173.2024.00010&partnerID=40&md5=9e6d6b6aee207a90a325c6a48391d617
AB  - Insider threat are actions by insiders that violate an organization's security policies, and have become a serious challenge to organizational security in digital and cloud-based environments nowadays. As a result, insider threat detection has become one of the key strategies to secure organizational information assets. However, existing methods are costly to maintain a model for each user, and in order to maintain a high detection accuracy, these methods are overly sensitive to user behavior, which leads to a high false positive and negatively affects the detection of user behavior. In this paper, we propose a lower-cost insider threat detection framework (LITD) based on user cluster and user behavior analysis. LITD clusters user classes according to user behavioral features, and trains deep learning models for each user class instead of a single user, thereby reducing the detection cost. In addition, we design a log content detection model to detect threatening information in specific log content. A risk detection and assessment model is built to use a risk list for final determination, and it significantly reduces the false positive while ensuring detection accuracy based on the combined assessment of multiple risks. A series of experiments are conducted using the publicly available CERT dataset, the results show that LITD outperforms state-of-the-art methods in the four metrics of Accuracy, Precision, Recall, and False Positive Rate (FPR), with the FPR metric being considerably lower. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Kumar Gandam, V.
AU  - Aravind, E.
TI  - Enhancing Cloud Security: A Novel Intrusion Detection System Using Deep Learning Algorithms
PY  - 2024
SP  - 457
EP  - 462
DO  - 10.1109/ISRITI64779.2024.10963477
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004414092&doi=10.1109%2FISRITI64779.2024.10963477&partnerID=40&md5=9d374885f2f7b0d64f9fff64869bcab7
AB  - The intrinsic qualities of Cloud Computing (CC), including scalability and adaptability, have led to its adoption by several sectors. Nevertheless, cloud providers continue to face substantial challenges related to security, even though these benefits are undeniable. Unauthorized entrée, data breaches, and insider threats are some of the new dangers that CC introduces. Attackers find cloud systems appealing due to their common infrastructure. Tackling these security concerns requires the inclusion of strong security systems. Intrusion Detection Systems (IDS) are one such method that is essential for protecting cloud environments and networks. IDS keep tabs on every system and network activity. A lot of people have been looking at ways to improve IDS performance using ML and DL techniques as of late. Machine learning and deep learning algorithms have proven themselves capable of sifting through mountains of data and producing reliable forecasts. Using these methods, IDS can adjust to new threats, find past attacks, and cut down on false positives. This paper presents a new intrusion detection system (IDS) model that incorporates DL methods such as the Morlet Wavelet Kernel Function. An MLSTM classifier is suggested for the purpose of identifying breaches in the IoT-Cloud setting. Jarratt-Butterfly optimization algorithm (JBOA) selects the relevant features to increase classification accuracy. The suggested model is tested using known methodologies in terms of various parameters using the comprehensive intrusion dataset BoT-IoT. Through the use of simulations, the results prove that the suggested research classical outperforms the state-of-the-art models. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Balaji, V.
AU  - Kumar, B.P.
AU  - Lokamanya, G.
AU  - Rammohan, B.
AU  - Rakesh, S.
AU  - Nethaji, M.
TI  - Strengthening Cloud Security For Unauthorized Access Prevention
PY  - 2024
DO  - 10.1109/ICEECT61758.2024.10738875
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003871024&doi=10.1109%2FICEECT61758.2024.10738875&partnerID=40&md5=36c163a60806001e0070caadb0d90d37
AB  - Due to the increased frequency of recent attacks, there are serious cyber security issues as a result of smart device usage. Cloud computing has brought about major changes in the commercial world. Centralization, however, increases the danger of important data breaches and makes it impossible to deploy dispersed services like security systems due to the massive volume of data that is transmitted between businesses and cloud service providers. Insider attacks are a serious risk to the business since they can cause more damage and have greater access. Finding different strange events that could point to anomalies and security issues with privilege escalation is the aim of this technique. Through the use of ensemble learning to combine multiple models, the strategy can improve machine learning outcomes and prediction performance. The proposed standard uses a modified dataset taken from the CERT dataset to assess the Support Vector Machine (SVM) machine learning technique for insider attack classification. Utilizing patterns of behavior and activity, such as resource usage, file access times, and login times, the system builds a profile of typical behavior and looks for deviations. This strategy can assist companies in identifying insider threats early on and avert serious harm to their priceless resources and data. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Abourida, O.
AU  - Nashaat, M.
AU  - El-Din Saad, N.G.
TI  - Deep Learning-Driven User Legitimacy Prediction Using Keystroke and Mouse Behavioural Dynamics
PY  - 2024
DO  - 10.1109/ICCA62237.2024.10928042
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002213463&doi=10.1109%2FICCA62237.2024.10928042&partnerID=40&md5=cfb740a36f890d0d7509130f30516129
AB  - Continuous authentication, based on behavioral dynamics such as keystroke and mouse movement patterns, has emerged as a promising solution to detect insider threats and ensure real-time security in sensitive systems. This paper presents a comprehensive comparison of traditional machine learning methods, including Random Forest (RF), K-Nearest Neighbors (KNN), Logistic Regression (LR), and XGBoost, against deep learning models like Deep Feedforward Neural Networks (DFFNN) and Long Short-Term Memory (LSTM) networks. Both keystroke and mouse dynamics datasets were used to evaluate model performance. The LSTM model consistently outperformed all other approaches, achieving the highest accuracy and precision, particularly on the keystroke dynamics dataset with an accuracy of 88%. Additionally, we highlight the decision time of each model, crucial for real-time authentication systems. Our findings emphasize the advantage of deep learning models in handling sequential data, while traditional models showed slower response times and lower accuracy. The paper concludes with a discussion on the potential for combining both keystroke and mouse dynamics for enhanced continuous authentication. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Bin Suhaimi, H.H.
AU  - Zubair, H.T.
TI  - Data Leakage Detection in Cloud Computing Environment
PY  - 2024
SP  - 7
EP  - 12
DO  - 10.1109/CyberComp60759.2024.10913619
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001557389&doi=10.1109%2FCyberComp60759.2024.10913619&partnerID=40&md5=b8909e68e867e35282907e94d471ff62
AB  - Insider threats pose critical security threats through the possession of privileged and access to valuable information and resources. Data leakage is one of the significant challenges faced in cloud computing environments, emphasising the criticality of data protection across various sectors such as education, finance, healthcare, and more. Cloud computing offers numerous advantages, including reliable data storage and transfer, yet it also presents significant risks, including data breaches, server failures, and malicious insider threats. This paper's primary objective is to evaluate the effectiveness of data leakage detection methods, particularly focusing on insider threats. Through the exploration of machine learning models and anomaly detection techniques, the study seeks to identify the most effective strategies for mitigating unauthorised data exposure. The research encom-passes a comprehensive analysis of current security measures, identification of vulnerabilities, and the proposition of enhanced detection methods. By examining real-world data leakage incidents and employing advanced detection tools, the findings aim to contribute to the development of more robust data protection frameworks. This research is poised to offer valuable insights and recommendations that will aid organisations in leveraging cloud services securely and efficiently, thereby enhancing their overall data security posture. The study not only underscores the importance of the CIA triad-Confidentiality, Integrity, and Availability-but also highlights the significance of innovative detection methods such as machine learning algorithms and behavioural analytics in safeguarding sensitive information in the ever-evolving landscape of cloud computing. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
TI  - 10th International Conference on Engineering and Emerging Technologies, ICEET 2024
PY  - 2024
T2  - International Conference on Engineering and Emerging Technologies, ICEET
IS  - 2024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001347986&partnerID=40&md5=0e2599497622f07dcd31510ed063298a
AB  - The proceedings contain 146 papers. The topics discussed include: secure image encryption u sing dynamic block segmentation and adaptive pixel modification with chaotic masking; classifying malicious insider threats based on user activity and behavioral profile using machine learning; securing local e-commerce businesses against cyber-attacks using deep learning algorithms; a novel two-step hybrid quantum watermarking technique; enhancing power system protection with machine learning: a smart and reliable approach for insulator inspection; a hybrid framework for digital experimental reports: integrating Chaoxing platform in experimental education; enhancing video projector connectivity and management with a low-cost solution; improving data center operational reliability and energy efficiency through hot-standby based ITE cooling system redundancy; and viability study based on saturation resource in data centers.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Alzaabi, F.R.
AU  - Mehmood, A.
TI  - Classifying Malicious Insider Threats Based On User Activity and Behavioral Profile Using Machine Learning
PY  - 2024
T2  - International Conference on Engineering and Emerging Technologies, ICEET
IS  - 2024
DO  - 10.1109/ICEET65156.2024.10913767
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001233584&doi=10.1109%2FICEET65156.2024.10913767&partnerID=40&md5=d1fb229392eee7a8eebe249cdae15372
AB  - Detecting malicious insider threats is a critical concern for organizations due to the potential for significant damage and the subtle nature of such activities. Insider threats are inherently complex to identify because malicious actions often masquerade as legitimate behavior, making traditional detection methods insufficient. Current approaches frequently rely on limited data sources and fail to capture the multifaceted aspects of user behavior, leading to gaps in threat detection. In this paper, we propose a novel methodology that addresses these challenges by integrating advanced natural language processing techniques, statistical feature analysis, and psychometric profiling. We lever-age textual content from user communications and web activities, apply statistical analyses on temporal and frequency-based be-havioral data, and incorporate users' psychometric profiles based on OCEAN scores to create comprehensive behavioral profiles. An isolation forest model is utilized as an anomaly detector to identify malicious activities and the users responsible. Our iterative approach assesses the contribution of each data source to detection efficacy, and we employ dimensionality reduction techniques to refine feature importance. Experimental results demonstrate that our integrated model significantly outperforms existing methods, effectively enhancing the detection of malicious insider activities by addressing the limitations of current approaches. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Peng, L.
AU  - Feng, J.
AU  - Huang, Y.
AU  - Zhou, H.
AU  - Qin, H.
AU  - Qiu, F.
TI  - MITD: A Multi-Dimensional Insider Threat Detection Framework Based On Deep Learning
PY  - 2024
DO  - 10.1109/CISP-BMEI64163.2024.10906151
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001045063&doi=10.1109%2FCISP-BMEI64163.2024.10906151&partnerID=40&md5=efa9e3c7037fd2e5ba8391a45efa7a44
AB  - In this paper, we propose a multi-dimensional insider threat detection framework (MITD), which aims to improve the accuracy of detection by comprehensively analyzing user behavior patterns. We combine statistical features and behavioral sequences and use sequence pattern recognition, graph structure information mining, and adaptive feature extraction methods. It can reveal user behavior from multiple dimensions. Then, we intelligently fuse the extracted multi-dimensional features to generate a comprehensive feature representation. It is further fused with statistical features through two strategies: concat and bitwise addition. Experimental results based on the CERT r4.2 dataset show that the MITD framework significantly improves in terms of accuracy, precision, recall, and F1 score, reaching 93.2% accuracy and 93.5% recall. The results show that the MITD framework effectively improves the performance of insider threat detection and has great potential in practical applications. © 2024 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Shannaq, B.
AU  - Talab, M.A.
AU  - Shakir, M.
AU  - Sheker, M.T.
AU  - Farhan, A.M.
TI  - Machine learning model for managing the insider attacks in big data
PY  - 2023
T2  - AIP Conference Proceedings
VL  - 3015
IS  - 1
C7  - 020013
DO  - 10.1063/5.0188358
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182567216&doi=10.1063%2F5.0188358&partnerID=40&md5=814053aa8d531e30eb67edf7a296704d
AB  - In order to formalize information and knowledge about people, devices, applications, and services in the network system, this study provided a model for displaying large data and insider threats. The work's contribution relates to the further advancement of information security theory and practices. extending the types of characteristics needed to identify insiders In order to tackle the issue of insider identification in a huge quantity of data and identify insiders to obtain the greatest performance indicators, a novel way for integrating two classes of algorithms based on expert rules and machine learning methods is given. By enhancing the techniques, models, and algorithms for identifying CN insiders, the obtained findings demonstrate a relative improvement in the security of the chosen computer Network System (NS). employing big data processing and machine learning techniques on 2.1%. © 2023 Author(s).
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 17
ER  -

TY  - JOUR
AU  - Thatha, V.N.
AU  - Mantena, S.V.
AU  - Reddy, C.S.R.
AU  - Chintamaneni, P.
AU  - Pulugu, R.
AU  - Desanamukula, V.S.
TI  - Enhancing Privacy Protection in Online Federated Learning: A Method for Secure Face Image De-Identification Using a Modified Diffie-Hellman Algorithm
PY  - 2023
T2  - Mathematical Modelling of Engineering Problems
VL  - 10
IS  - 6
SP  - 2265
EP  - 2273
DO  - 10.18280/mmep.100642
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184154765&doi=10.18280%2Fmmep.100642&partnerID=40&md5=8667f0e2bc2dce8d784de8e047b50d3e
AB  - The proliferation of face images, alongside their widespread dissemination and easy accessibility through social media, underscores a pressing challenge to personal identification information protection. Conversely, advancements in identity-agnostic computer vision technologies offer valuable benefits, necessitating cautious utilization of face images to safeguard individual privacy. ‘Face de-identification’, or ‘face anonymization’, refers to the process of altering an original face image to a nearidentical one that obscures the subject's actual identity. Existing de-identification strategies, despite considerable efforts, often fall short in photo-realism or fail to strike an optimal balance between privacy and utility. This study proposes an approach for generating de-identified facial images using instances, addressing the potential privacy breaches and identity exposure associated with facial features. The proposed system involves a two-stage training process. Initially, a federated learning framework is suggested, enabling knowledge amalgamation through the mutual exchange of model parameters among clients during federated training, devoid of data sharing. Subsequently, sensitive information is secured using an enhanced version of the Diffie-Hellman algorithm coupled with a genetic algorithm. In the event of data loss or corruption, an optimized genetic algorithm (OGA) is employed to successfully restore the data, thereby offering protection against potential insider threats in federated learning. The decryption process is then executed as if the user had initiated the request. Experimental results demonstrate that the proposed federated learning approach delivers performance equivalent to centralized learning, thereby validating the practicality and effectiveness of the suggested architecture. Specifically, a model of the federated learning-deep convolutional neural network (FL-DCNN) achieved an accuracy of 95.2%, precision and F1-score of 95%, recall of 96%, and a final specificity of 96.80%. © 2023 IIETA. This article is published by IIETA and is licensed under the CC BY 4.0 license (http://creativecommons.org/licenses/by/4.0/). All Rights Reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Sun, Q.
AU  - Zhou, C.
TI  - Insider Threat Detection Based on Deep Clustering of Multi-Source Behavioral Events
PY  - 2023
T2  - Applied Sciences (Switzerland)
VL  - 13
IS  - 24
C7  - 13021
DO  - 10.3390/app132413021
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182758643&doi=10.3390%2Fapp132413021&partnerID=40&md5=7bc07f32129d4affbec06ea71888f8a3
AB  - With the continuous advancement of enterprise digitization, insider threats have become one of the primary cybersecurity concerns for organizations. Therefore, it is of great significance to develop an effective insider threat detection mechanism to ensure the security of enterprises. Most methods rely on artificial feature engineering and input the extracted user behavior features into a clustering-based unsupervised machine learning model for insider threat detection. However, feature extraction is independent of clustering-based unsupervised machine learning. As a result, user behavior features are not the most appropriate for clustering-based unsupervised machine learning, and thus, they reduce the insider threat detection accuracy. This paper proposes an insider threat detection method based on the deep clustering of multi-source behavioral events. On the one hand, the proposed method constructs an end-to-end deep clustering network and automatically learns the user behavior feature expression from multi-source behavioral event sequences. On the other hand, a deep clustering objective function is presented to jointly optimize the learning of feature representations and the clustering task for insider threat detection. This optimization can adjust the optimal user behavior features for the clustering model to improve the insider threat detection accuracy. The experimental results show that the proposed end-to-end insider threat detection model can accurately identify insider threats based on abnormal multi-source user behaviors in enterprise networks. © 2023 by the authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 15
ER  -

TY  - JOUR
AU  - Amiri-Zarandi, M.
AU  - Karimipour, H.
AU  - Dara, R.A.
TI  - A federated and explainable approach for insider threat detection in IoT
PY  - 2023
T2  - Internet of Things (The Netherlands)
VL  - 24
C7  - 100965
DO  - 10.1016/j.iot.2023.100965
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174156807&doi=10.1016%2Fj.iot.2023.100965&partnerID=40&md5=f7cef37709822f8f56b901a97f677e9a
AB  - An insider threat is a malicious action launched by authorized personnel inside the organization. Since insider actions may only leave a small digital footprint in the system, it is considered a major cybersecurity challenge in different applications. Along with the rapid growth of the Internet of Things (IoT) and the extensive attack surface in this technology, many concerns have been raised regarding the potential insider threats in IoT environments. Several studies have been conducted on Machine Learning (ML)-based insider threat detection solutions which are focused on the models’ performance while the trustability of these models is neglected. Trustworthy Learning refers to a new trend in ML that focuses on ways to ensure that the data collection and data analysis procedures in ML techniques follow ethical applications and are trustable to human users. This approach enforces the acceptance and successful adoption of ML-based solutions. This study aims to propose an improved trustworthy insider threat detection method that ensures two of the trustworthy learning requirements: Privacy and Explainability. The proposed solution protects the privacy of the utilized data and is capable of explaining why certain behaviors are detected as a threat. The proposed solution also leverages data collaboration between different data owners to increase the volume of data used in the training process and enhance the performance of the ML model. Experimental results show the proposed solution outperforms the learning models trained by individual data holders. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 14
ER  -

TY  - JOUR
AU  - Van Bossuyt, D.L.
AU  - Hale, B.
AU  - Arlitt, R.
AU  - Papakonstantinou, N.
TI  - Zero-Trust for the System Design Lifecycle
PY  - 2023
T2  - Journal of Computing and Information Science in Engineering
VL  - 23
IS  - 6
C7  - 060812
DO  - 10.1115/1.4062597
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173951276&doi=10.1115%2F1.4062597&partnerID=40&md5=56e3b659fa8c4e7c6b2766bd00f29c6c
AB  - In an age of worsening global threat landscape and accelerating uncertainty, the design and manufacture of systems must increase resilience and robustness across both the system itself and the entire systems design process. We generally trust our colleagues after initial clearance/background checks; and systems to function as intended and within operating parameters after safety engineering review, verification, validation, and/ or system qualification testing. This approach has led to increased insider threat impacts; thus, we suggest moving to the "trust, but verify"approach embodied by the Zero-Trust paradigm. Zero-Trust is increasingly adopted for network security but has not seen wide adoption in systems design and operation. Achieving the goal of Zero-Trust throughout the systems lifecycle will help to ensure that no single bad actor-whether human or machine learning/artificial intelligence (ML/AI)-can induce failure anywhere in a system's lifecycle. Additionally, while ML/AI and their associated risks are already entrenched within the operations phase of many systems' lifecycles, ML/AI is gaining traction during the design phase. For example, generative design algorithms are increasingly popular, but there is less understanding of potential risks. Adopting the Zero-Trust philosophy helps ensure robust and resilient design, manufacture, operations, maintenance, upgrade, and disposal of systems. We outline the rewards and challenges of implementing Zero-Trust and propose the framework for Zero-Trust for the system design lifecycle. This article highlights several areas of ongoing research with focus on high priority areas where the community should focus efforts. © 2023 by ASME.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 8
ER  -

TY  - CONF
AU  - Li, Y.
TI  - Improved Insider Threat Detection Method of University Cluster System based on Log-Clustering
PY  - 2023
SP  - 236
EP  - 241
DO  - 10.1145/3627377.3627414
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180125797&doi=10.1145%2F3627377.3627414&partnerID=40&md5=6b24873a2d687757174d43efc2fda8e5
AB  - In response to the low accuracy issue of the log-based clustering method for insider threat detection in university cluster systems, this study proposes an improved log-based clustering method for insider threat detection. Firstly, when dividing logs into log sequences, we consider the differences between different users. We classify the logs based on user accounts and use a sliding window approach to divide the classified logs into labeled log sequences for subsequent clustering learning. This approach takes into account the behavioral pattern differences between different users. Additionally, in practical applications, the output results of the model are manually inspected, misjudgments are marked, and the model is iterated using the labeled data to improve its accuracy. Experimental results demonstrate that the improved internal threat detection method effectively enhances the detection accuracy and is more suitable for real-world production environments. © 2023 ACM.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Attou, H.
AU  - Mohy-Eddine, M.
AU  - Guezzaz, A.
AU  - Benkirane, S.
AU  - Azrour, M.
AU  - Alabdulatif, A.
AU  - Almusallam, N.
TI  - Towards an Intelligent Intrusion Detection System to Detect Malicious Activities in Cloud Computing
PY  - 2023
T2  - Applied Sciences (Switzerland)
VL  - 13
IS  - 17
C7  - 9588
DO  - 10.3390/app13179588
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170361487&doi=10.3390%2Fapp13179588&partnerID=40&md5=acc6c1c811233fa0156cb35f489a9545
AB  - Several sectors have embraced Cloud Computing (CC) due to its inherent characteristics, such as scalability and flexibility. However, despite these advantages, security concerns remain a significant challenge for cloud providers. CC introduces new vulnerabilities, including unauthorized access, data breaches, and insider threats. The shared infrastructure of cloud systems makes them attractive targets for attackers. The integration of robust security mechanisms becomes crucial to address these security challenges. One such mechanism is an Intrusion Detection System (IDS), which is fundamental in safeguarding networks and cloud environments. An IDS monitors network traffic and system activities. In recent years, researchers have explored the use of Machine Learning (ML) and Deep Learning (DL) approaches to enhance the performance of IDS. ML and DL algorithms have demonstrated their ability to analyze large volumes of data and make accurate predictions. By leveraging these techniques, IDSs can adapt to evolving threats, detect previous attacks, and reduce false positives. This article proposes a novel IDS model based on DL algorithms like the Radial Basis Function Neural Network (RBFNN) and Random Forest (RF). The RF classifier is used for feature selection, and the RBFNN algorithm is used to detect intrusion in CC environments. Moreover, the datasets Bot-IoT and NSL-KDD have been utilized to validate our suggested approach. To evaluate the impact of our approach on an imbalanced dataset, we relied on Matthew’s Correlation Coefficient (MCC) as a normalized measure. Our method achieves accuracy (ACC) higher than 92% using the minimum features, and we managed to increase the MCC from 28% to 93%. The contributions of this study are twofold. Firstly, it presents a novel IDS model that leverages DL algorithms, demonstrating an improved ACC higher than 92% using minimal features and a substantial increase in MCC from 28% to 93%. Secondly, it addresses the security challenges specific to CC environments, offering a promising solution to enhance security in cloud systems. By integrating the proposed IDS model into cloud environments, cloud providers can benefit from enhanced security measures, effectively mitigating unauthorized access and potential data breaches. The utilization of DL algorithms, RBFNN, and RF has shown remarkable potential in detecting intrusions and strengthening the overall security posture of CC. © 2023 by the authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 77
ER  -

TY  - JOUR
AU  - Xiao, J.
AU  - Yang, L.
AU  - Zhong, F.
AU  - Wang, X.
AU  - Chen, H.
AU  - Li, D.
TI  - Robust Anomaly-Based Insider Threat Detection Using Graph Neural Network
PY  - 2023
T2  - IEEE Transactions on Network and Service Management
VL  - 20
IS  - 3
SP  - 3717
EP  - 3733
DO  - 10.1109/TNSM.2022.3222635
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142793470&doi=10.1109%2FTNSM.2022.3222635&partnerID=40&md5=f25bf7f95979b9c8e5590e433701a48f
AB  - Misuse or malicious access to critical assets of information systems by insiders usually causes significant loss to organizations. The issue of insider threat detection for information systems has received many researchers' attention in both security and data mining fields, and a lot of related research results were presented. However, there are still many challenges in capturing the behavior difference between malicious insiders and normal users accurately, such as lack of labeled insider threats, the subtle and adaptive nature of insider threats, complexity, heterogeneity, sparsity of the underlying data, etc. To detect insider threats with large and complex audit data, a Multi-Edge Weight Relational Graph Neural Network method (MEWRGNN) for robust anomaly detection is proposed in this paper. Unlike most existing approaches, the MEWRGNN adopts several graph neural networks to capture the contextual relationship of user behaviors over a period of time, which is a critical factor for achieving accurate anomaly identification. The MEWRGNN achieves a certain degree of interpretability through ranking the contribution of different edge-representation features. Evaluation experimental results demonstrate that the MEWRGNN can learn a model from limited sample data sets, and achieve quick and accurate insider threat detection performance. In addition, other feature ranking results allow providing security analysts with understandable insights for investigating the detected insider threats. © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 21
ER  -

TY  - JOUR
AU  - Pal, P.
AU  - Chattopadhyay, P.
AU  - Swarnkar, M.
TI  - Temporal feature aggregation with attention for insider threat detection from activity logs
PY  - 2023
T2  - Expert Systems with Applications
VL  - 224
C7  - 119925
DO  - 10.1016/j.eswa.2023.119925
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151406791&doi=10.1016%2Fj.eswa.2023.119925&partnerID=40&md5=334147e5fc302e3c3714730e7ed5153d
AB  - Nowadays, insider attacks are emerging as one of the top cybersecurity threats. However, the detection of insider threats is a more arduous task for many reasons. A significant cause is the availability of various data types related to insider activities and their possible behavioral drift. Another major reason is that threat activities rarely happen within any organizational environment and usually remain submerged within a massive amount of normal activities thereby creating data imbalance issues. Any insider threat event requires three major components to get materialized: proper motivation, suitable opportunity and a minimum skill set. The simultaneous occurrence of all these elements is rarely found in organizational environment compared to regular activity traits, and the data imbalance thus caused makes accurate detection of threat activities quite challenging. Existing insider threat detection techniques are mainly divided into statistical rule-based, machine learning-based, and deep learning-based methods. Although recent deep learning methods have been found to extract intrinsic behavioral properties from users’ activity patterns more effectively than traditional rule-based and machine-learning methods by utilizing their multilayer architecture. But sporadic approaches prioritize critical sections of activity patterns in their detection scheme. Also, rare methods focused on taking advantage of multiple deep learning-based feature extraction models together in their detection process. Finally, rare methods have adequately focused on data imbalance issues, especially over the unequal proportion of different categories of threat instances. In this paper, we proposed an insider threat detection approach using an ensemble of stacked-LSTM and stacked-GRU-based attention models. Our models are first trained on the user's single-day sequential activity logs. Then a stacked ensemble of trained attention models is used to extract the user's single-day activity information in the form of the feature vector, which is finally used for classification. To address the data imbalance issues, we propose a new equally-weighted random sampling approach for balancing the population of the different categories of threat patterns. We randomly undersample the nonmalicious instances followed by random oversampling of the different categories of threat instances in an equally-weighted manner so that the training models can learn the behavioral characteristics of the different types of insider activity patterns without getting biased towards any particular type, which is a major limitation of random oversampling and random undersampling-based techniques. Experiments have been performed on the different versions of the CMU CERT insider threat datasets. For robust evaluation, stratified division-based train-test sets have been used based on different categories of insider activities. An average AUC of 0.99 on CMU CERT v4.2 and v5.2 datasets and 0.97 on its v6.2 dataset shows the robustness of the proposed approach in detecting insider threats. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 34
ER  -

TY  - JOUR
AU  - Adun, I.J.
AU  - Amadin, F.I.
TI  - A Hybrid Supervised Machine Learning Model for the Prediction of Insider Threats
PY  - 2023
T2  - NIPES - Journal of Science and Technology Research
VL  - 5
IS  - 3
SP  - 169
EP  - 179
DO  - 10.5281/zenodo.8313125
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196159346&doi=10.5281%2Fzenodo.8313125&partnerID=40&md5=6c6c93d93145f8dca6a52ded46a981f7
AB  - The quest and sensitivity of organizational resources has permeated need for information confidentiality while ensuring availability and integrity are met, if organizations are to thrive and survive. To fend off malicious insider, organizations have implemented strategies, policies and techniques to manage malicious insider attacks. Machine Learning (ML) algorithms are implemented as learning paradigms, having the ability to learn from prior instances. ML present intelligent implicitly designed models having the capability of predicting possible outcomes from machine learning dataset based on perceived features which might be computationally explored. Hybrid Supervised Machine Learning Model for the Prediction of Insider Threats (HSMLM-IT) has been designed, simulated and validated utilizing Support Vector Machine (SVM) for label classification and Adaptive Neuro Fuzzy Inference System (ANFSI) for predictive learning. The SVM blocks provides a classification accuracy of 92% and precision of 93% while the ANFIS training blocks provides an ANFIS accuracy of 91% and ANFIS error of 9%. © 2023 NIPES Pub. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Al-Shehari, T.
AU  - Alsowail, R.A.
TI  - Random resampling algorithms for addressing the imbalanced dataset classes in insider threat detection
PY  - 2023
T2  - International Journal of Information Security
VL  - 22
IS  - 3
SP  - 611
EP  - 629
DO  - 10.1007/s10207-022-00651-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144873120&doi=10.1007%2Fs10207-022-00651-1&partnerID=40&md5=f4282d35e2de88048c37221fd794f46a
AB  - Cybersecurity threats can be perpetrated by insiders or outsiders. The threats that could be carried out by insiders are far more serious due to their privileged access, which they may use to cause financial loss and reputation harm for an organization. Thus, insider threats represent a major cybersecurity challenge for private and government organizations. Researchers and cybersecurity practitioners have proposed different approaches for detecting and mitigating insider threats, but they face many challenges (e.g., dataset availability and the highly imbalanced classes of the available dataset). Because the shortcoming of an insider threat dataset, the benchmarking dataset given by The Computer Emergency Response Team (CERT) was used to validate the majority of the insider threat detection approaches. The CERT dataset of insider threat is extremely imbalanced, and hence, once utilized to validate an insider threat detection model, the detection results may be biased and inaccurate. Such imbalance issue of the CERT dataset is ignored by most existing approaches of insider threat detection. As result, effective model is required to detect insider data leakage incidents from an imbalanced dataset more precisely. In this paper an insider data leakage detection model is proposed to leverage various random sampling techniques and well-known machine learning algorithms to deal with the dataset's extremely imbalanced classes. We evaluate the model on CERT r4.2 insider threat dataset utilizing different sampling techniques, and then compare its performance with the baseline and existing work. The empirical results show that by resolving the imbalanced dataset issue, our model enhances the detection performance of insider data leakage events by surpassing existing approaches. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH, DE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 11
ER  -

TY  - CONF
AU  - Ramamoorthy, J.
AU  - Shashidhar, N.K.
AU  - Zhou, B.
TI  - Anomaly based malware threat detection on Linux Systems
PY  - 2023
SP  - 1744
EP  - 1750
DO  - 10.1109/TrustCom60117.2023.00237
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195464138&doi=10.1109%2FTrustCom60117.2023.00237&partnerID=40&md5=a2894a3b8a4c516a317c8c9bf9c2199b
AB  - There has been a steady increase in malware targeting Linux-based systems. With the proliferation of embedded IoT devices and cloud architectures that use Linux or Unix-based Operating Systems, this trend is expected to grow. Most modern Linux distributions include a configurable and queryable userspace component for security auditing with auditd (audit daemon) subsystem. In a multi-user, enterprise environment, these audit events are typically collected in a centralized repository as a source for threat detection and Incident response. Attack techniques used by malicious programs such as process injection and memory corruption are commonly seen in fileless malware, insider threats, and zero day attacks. Such attacks are difficult to detect through traditional signature-based methods since there are no known, discernible indicators of compromise. This study proposes a novel method of using Linux process overlay (execve) audit logs to identify threats from malicious executable and shellcode, with Machine Learning. Our study proposes a methodology that uses a Sparse Autoencoder Deep Learning model to effectively detect these security threats as anomalies, with an accuracy of over 95 percent. We suggest this approach as a feasible enterprise solution to identify Linux malware and detect security threat anomalies by leveraging native Linux audit logging capabilities. © 2023 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Hatip, A.
AU  - Zayood, K.
AU  - Scharif, R.
TI  - Securing Information Management in Collaborative Environments Using Machine Learning
PY  - 2023
T2  - Journal of Cybersecurity and Information Management
VL  - 11
IS  - 2
SP  - 27
EP  - 35
DO  - 10.54216/JCIM.110203
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189881524&doi=10.54216%2FJCIM.110203&partnerID=40&md5=8d92e731fa48eb24c37200b27e945243
AB  - Recently, there has been a significant increase in the use of collaborative environments for managing and sharing information. However, these environments often present significant security risks due to the potential for unauthorized access, data leakage, and other security breaches. To address these risks, machine learning (ML) techniques have been increasingly used to secure information management in collaborative environments. We propose a novel ML approach to be applied to detect and prevent security threats in collaborative environments. Our approach integrates temporal convolution to detect and prevent security threats by analyzing spatial-temporal patterns in data from various sources, such as network traffic, system logs, and user behavior. Furthermore, we present a case study demonstrating the effectiveness of our model in securing collaborative information management. The case study involves the development of our system for detecting insider threats in a collaborative environment. Extensive experimentation on this case study demonstrates the efficiency and effectiveness of the proposed system for securing information management and promoting further developments. © 2023, American Scientific Publishing Group (ASPG). All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Singh, S.
AU  - Chattopadhyay, P.
TI  - Hierarchical Classification Using Ensemble of Feed-Forward Networks for Insider Threat Detection from Activity Logs
PY  - 2023
SP  - 782
EP  - 787
DO  - 10.1109/INDICON59947.2023.10440886
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187377028&doi=10.1109%2FINDICON59947.2023.10440886&partnerID=40&md5=05f79c9e76fc501e726af28c2cb9d37c
AB  - Insider threat is a significant cybersecurity concern that poses challenges in detection due to its infrequent occurrence and diverse data types. Recent Machine and Deep Learning-based approaches to insider threat detection mostly focus on using sophisticated feature extraction models. However, an ensemble of relatively simpler neural network models is also known to be an effective classifier and there has not been much work on insider threat detection with supervised ensemble models, which we aim to study in this work. The proposed approach follows a two-stage hierarchical process in which the first stage involves training multiple Deep Feed Forward Neural Network models on different subsets of data to identify whether a time-series of user activity is either malicious or non-malicious. The second stage involves identifying the threat scenario if the time series activity is classified as malicious in the first stage. The individual learners in the ensemble are trained with a balanced dataset formed by random undersampling of the majority class instances without replacement to prevent biasedness towards any particular class during the prediction. Further, no two learners are trained using the same dataset which helps in learning accurate decision boundaries between the target classes. Experiments on the CMU CERT insider threat data (version 4.2) verify the effectiveness of our approach in identifying the different insider threat categories. © 2023 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Sridevi, D.
AU  - Kannagi, L.
AU  - Vivekanandan, G.
AU  - Revathi, S.
TI  - Detecting Insider Threats in Cybersecurity Using Machine Learning and Deep Learning Techniques
PY  - 2023
SP  - 871
EP  - 875
DO  - 10.1109/ICCSAI59793.2023.10421133
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186671753&doi=10.1109%2FICCSAI59793.2023.10421133&partnerID=40&md5=7b99f6328dc865f2fa9ea0255f1215d8
AB  - The subject of cybersecurity is evolving at a rapid pace, and one of the challenges that organisations face is keeping up with the ever-evolving nature of the threat posed by their own employees. These risks, which come from contractors or staff inside the organisation, usually get by the normal security measures. This is due to the fact that these individuals are trusted folks. This research presents a comprehensive approach to the identification of insider hazards by making use of both machine learning and deep learning methodologies. We propose a hybrid model that combines deep neural networks, which are able to capture fine-grained behavioural subtleties, with featureengineered patterns that are indicative of anomalous insider behaviours. This model would be used to identify anomalous insider behaviours. Our model had a detection accuracy of 96.3%, which was higher than the existing state-of-the-art approaches, and it surpassed them by using a dataset that was created from user activity records and system logs from multiple different companies. In addition, the deep learning component made it feasible to identify minute patterns of potentially dangerous behaviour that had previously escaped detection. When traditional machine learning techniques are coupled with deep learning methods, as shown by our findings, it may be possible to develop insider threat detection technologies that are more effective, dependable, and versatile within the area of cybersecurity. © 2023 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 12
ER  -

TY  - JOUR
AU  - Kabir, M.H.
AU  - Hasnat, A.
AU  - Mahdi, A.J.
AU  - Hasan, M.N.
AU  - Chowdhury, J.A.
AU  - Fahim, I.M.
TI  - Enhancing Insider Malware Detection Accuracy with Machine Learning Algorithms †
PY  - 2023
T2  - Engineering Proceedings
VL  - 58
IS  - 1
C7  - 104
DO  - 10.3390/ecsa-10-16234
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186449156&doi=10.3390%2Fecsa-10-16234&partnerID=40&md5=0aa4e34275d2286614e49b24d6449898
AB  - One of the biggest cybersecurity challenges in recent years has been the risk that insiders pose. Internet consumers are susceptible to exploitation due to the exponential growth of network usage. Malware attacks are a major concern in the digital world. The potential occurrence of this threat necessitates specialized detection techniques and equipment, including the capacity to facilitate the precise and rapid detection of an insider threat. In this research, we propose a machine learning algorithm using a neural network to enhance malware detection accuracy in response to insider threats. A feature extraction, anomaly detection, and classification workflow are also proposed. We use the CERT4.2 dataset and preprocess the data by encoding text strings and differentiating threat and non-threat records. Our developed machine learning model incorporates numerous dense layers, ReLU activation functions, and dropout layers for regularization. The model attempts to detect and classify internal threats in the dataset with precision. We employed random forest, naive Bayes, KNN, SVM, decision tree, logical regression, and the gradient boosting algorithm to compare our proposed model with other classification techniques. Based on the results of the experiments, the proposed method functions properly and can detect malware more effectively and with 100% accuracy. © 2023 by the authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Ramachandiran, R.
AU  - Amudhini, J.
AU  - Priya, P.
AU  - Harini, C.
AU  - PremKumar, K.
TI  - Data Leakage Detection Using ML
PY  - 2023
DO  - 10.1109/ICSCAN58655.2023.10395027
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185006364&doi=10.1109%2FICSCAN58655.2023.10395027&partnerID=40&md5=e704f7f36db9e3b4fc13f92662fbba83
AB  - Data Leakage is one of the major problems faced by the authorities of the corporate society. Data Leakage could be of different types such as Malicious insiders, Physical exposure, electronic communication, and Accidental leakage. The most common out of all these above -listed types is accidental leakage i.e., data leak due to human error. There have been several incidents regarding data leakage in different companies across the world. And so, our goal in this project is to achieve a solution to prevent data leakage through Machine Learning. However, the detection techs available cannot provide any absolute protection as of now. Thus, it is very essential to find a solution to this risky problem as soon as possible. This research aims to design and implement a data leakage detection system based on machine learning. Furthermore, applying the synthetic minority oversampling technique (SMOTE) is one option to overcome this imbalance problem. Known machine learning methods are regarded as one of the most effective approaches to find instances of data leaking. © 2023 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Kumar, R.
TI  - Thee Machine Learning Analysis of Data Granularity for Insider Threat Detection
PY  - 2023
DO  - 10.1109/GCAT59970.2023.10353269
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182549373&doi=10.1109%2FGCAT59970.2023.10353269&partnerID=40&md5=5e7f01543821a14a4330e830f5c2fb43
AB  - There is a growing and serious risk to the company from insider threats. In most cases, malicious insiders target sensitive company information for theft or manipulation. There are still substantial problems despite the fact that insider threats are harder to identify. The goal of this research is to assess and identify insider threats using a machine learning (ML) technique. The goal of this research is to identify potential insider threats by continuous learning of their behaviors. The initial step is to gather and prepare the insider dataset. The data is first preprocessed to create smaller, more manageable chunks, such as weekly, daily, and hourly behavioural data. The next step is feature extraction, whereby the necessary features are culled from each data instance; this includes but is not limited to HTTP features, E-mail capabilities, file features, and USB characteristics. These are the primary types of characteristics, and insider detection may make use of features from across each of them. Next, one of the most effective ML algorithms, Random Forest (RF) classifier, is given the characteristics. At last, the RF sorts information into "insider" and "normal" categories according to the characteristics. The experimental results demonstrate the efficacy of the proposed ML-based identifying insider threats model at the microlevel. © 2023 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Rauf, U.
AU  - Wei, Z.
AU  - Mohsen, F.
TI  - Employee Watcher: A Machine Learning-based Hybrid Insider Threat Detection Framework
PY  - 2023
SP  - 39
EP  - 45
DO  - 10.1109/CSNet59123.2023.10339777
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182261525&doi=10.1109%2FCSNet59123.2023.10339777&partnerID=40&md5=a1abec89acf23cd51bbfde42e35d405b
AB  - Insider threats refer to harmful actions carried out by authorized users within an organization, posing the most damaging risks. The increasing number of these threats has revealed the inadequacy of traditional methods for detecting and mitigating insider threats. These existing approaches lack the ability to analyze activity-related information in detail, resulting in delayed detection of malicious intent. To address this, our paper presents a hybrid insider threat detection framework. We enhance prediction accuracy by incorporating a layer of statistical criteria using information gain metrics on top of Machine Learning-based classification. We evaluate the performance of our framework using a real-life threat test dataset (CERT r4.2) and compare it to existing methods on the same dataset [7]. Our initial evaluation demonstrates that our proposed framework achieves an accuracy of 98.94% in detecting insider threats, surpassing the performance of existing methods. Additionally, our framework effectively handles potential bias and data imbalance issues that can arise in real-life scenarios. © 2023 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 4
ER  -

TY  - CHAP
AU  - Bhuvaneswari, R.
AU  - Kumar, E.K.
AU  - Padmasini, A.
AU  - Varma, K.V.P.
TI  - Insider threat detection of ransomware using AutoML
PY  - 2023
VL  - 1
SP  - 724
EP  - 733
DO  - 10.1201/9781003393580-107
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180057645&doi=10.1201%2F9781003393580-107&partnerID=40&md5=c72610ab49dca0cd10d87335ce5123d3
AB  - Insider threats are one of the biggest issues that modern-day organizations and many large-scale companies face. The inside threats are caused by the insiders who are authorized individuals, also may have proper access to sensitive and secret information, and may be aware of the weaknesses in the implemented systems and operational procedures. And, it is confirmed that these insider threats have already shown their great damaging power in securing important information and because of this, organizations require more proactive and modern-day solutions to support existing cybersecurity tools in order to detect and prevent them. Conventional interruption recognition frameworks neglect to be powerful in insider threats because of the absence of a wide range of information for insider ways of behaving. All things considered; a more complex and standard technique is expected to have a more profound comprehension of the ways that insiders speak with the information framework. Ransomware hackers appear to be adopting new methods in response to tightening security. Automated machine learning has been utilised in this work for detection of ransomware and we also included the ensembling method for a few algorithms that are suitable for the given dataset. © 2024 selection and editorial matter, Arvind Dagur, Karan Singh, Pawan Singh Mehra & Dhirendra Kumar Shukla; individual chapters, the contributors.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Al-Shehari, T.
AU  - Al-Razgan, M.
AU  - Alfakih, T.
AU  - Alsowail, R.A.
AU  - Saravanan, S.
TI  - Insider Threat Detection Model Using Anomaly-Based Isolation Forest Algorithm
PY  - 2023
T2  - IEEE Access
VL  - 11
SP  - 118170
EP  - 118185
DO  - 10.1109/ACCESS.2023.3326750
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176338318&doi=10.1109%2FACCESS.2023.3326750&partnerID=40&md5=dccbfabcc46cc04f16ad1b55e742686f
AB  - Insider attacks may inflict far greater damage to an organization than outsider threats since insiders are authorized users who are acquainted with the business's system, making detection harder. Many techniques to detecting insider threats have been developed, but they are neither flexible nor resilient owing to different obstacles (e.g., lack of real-world dataset and highly skewed class distribution of the available dataset), making insider threat detection an understudied research field. Previous techniques attempted to solve the dataset's imbalance issue by increasing or lowering the observations of the dataset's classes, however this might lead to underfitting and overfitting problems. We present an insider threat detection model that addresses the class imbalance problem at the algorithm level using anomaly-based techniques, as an enhancement over previous approaches. To limit the effect of skewed class distribution on insider threat detection, the Isolation Forest (IF) technique is used. The model is verified using the benchmarked CERT's insider threat dataset, which is significantly unbalanced, with a small number of malicious cases vs a large number of non-malicious instances. Several contamination ratios of IF's parameters are used to verify the model's performance throughout a range of anomaly scores. The experimental findings reveal that the suggested model handles the dataset class imbalance problem with an accuracy score of 98%. The findings are compared to the baseline technique to demonstrate how the proposed model enhances detection performance and addresses the problem of data imbalance. The findings indicate the usefulness of the suggested approach for identifying insider threats when compared to previous studies. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 17
ER  -

TY  - CONF
TI  - Proceedings - 2023 3rd International Conference on Pervasive Computing and Social Networking, ICPCSN 2023
PY  - 2023
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175254410&partnerID=40&md5=49f3ccdf27bb870ebe2b588f7451501b
AB  - The proceedings contain 293 papers. The topics discussed include: battery energy management systems in active distribution network; FMCG market analysis for wholesalers and retailers using machine learning; detection of insider threats using deep learning; bio-inspired optimization with transfer learning based crowd density detection on sparse environment; an overview on breast cancer detection and classification methods using machine learning techniques; disease prediction using random forest classifier by machine learning application; a study on working and applications of sequential deep learning models; Internet of Things towards the implementation of a smart city; enhancing supply chain traceability with blockchain technology: a study on dairy, agriculture, and seafood supply chains; and customer segmentation and market analysis for portfolio generation.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Sulaiman, M.
AU  - Khan, A.
AU  - Ali, A.N.
AU  - Laouini, G.
AU  - Alshammari, F.S.
TI  - Quantitative Analysis of Worm Transmission and Insider Risks in Air-Gapped Networking Using a Novel Machine Learning Approach
PY  - 2023
T2  - IEEE Access
VL  - 11
SP  - 111034
EP  - 111052
DO  - 10.1109/ACCESS.2023.3322924
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174841561&doi=10.1109%2FACCESS.2023.3322924&partnerID=40&md5=7e97136ad0569f351a82f4391144f3c9
AB  - Researchers and practitioners in the fields of science and engineering encounter significant challenges when it comes to mitigating the proliferation of computer worms, owing to their rapid spread within computer and communication networks. This study delves into a comprehensive analysis of the mathematical model governing the hazard of worm propagation in such networks. Specifically, the mathematical framework employed herein encompasses a system of ordinary differential equations. In numerous instances, mathematical models have been employed to quantitatively investigate the propagation patterns of worms across computer networks. In this scholarly article, we present an enhanced Susceptible-Exposed-Infected-Quarantined-Vaccinated (SEIQV) model, denoted as Susceptible-Exposed-Infected-Quarantined-Patched (SEIQP), which effectively captures the dissemination dynamics of an insider threat within a network featuring air gaps. To facilitate the study, we leverage the power of feedforward neural networks that are trained using the backpropagated Levenberg-Marquardt optimization algorithm. These neural networks serve as surrogate tools, providing solutions to the SEIQP model. To evaluate the efficacy of our approach, we meticulously assess their performance across three distinct scenarios. Additionally, the stability of the mathematical model is examined by manipulating the probability of an insider threat removing a patch from the host, denoted as $\eta $. Our empirical findings conclusively establish the effectiveness of the proposed approach in addressing the intricate challenges associated with insider threats within network environments. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Qiang Wang, Z.
AU  - El Saddik, A.
TI  - DTITD: An Intelligent Insider Threat Detection Framework Based on Digital Twin and Self-Attention Based Deep Learning Models
PY  - 2023
T2  - IEEE Access
VL  - 11
SP  - 114013
EP  - 114030
DO  - 10.1109/ACCESS.2023.3324371
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174819228&doi=10.1109%2FACCESS.2023.3324371&partnerID=40&md5=a3a9c15a5ff07af62fca764a0adbd7f2
AB  - Recent statistics and studies show that the loss generated by insider threats is much higher than that generated by external attacks. More and more organizations are investing in or purchasing insider threat detection systems to prevent insider risks. However, the accurate and timely detection of insider threats faces significant challenges. In this study, we proposed an intelligent insider threat detection framework based on Digital Twins and self-attentions based deep learning models. First, this paper introduces insider threats and the challenges in detecting them. Then this paper presents recent related works on solving insider threat detection problems and their limitations. Next, we propose our solutions to address these challenges: building an innovative intelligent insider threat detection framework based on Digital Twin (DT) and self-attention based deep learning models, performing insight analysis of users' behavior and entities, adopting contextual word embedding techniques using Bidirectional Encoder Representations from Transformers (BERT) model and sentence embedding technique using Generative Pre-trained Transformer 2 (GPT-2) model to perform data augmentation to overcome significant data imbalance, and adopting temporal semantic representation of users' behaviors to build user behavior time sequences. Subsequently, this study built self-attention-based deep learning models to quickly detect insider threats. This study proposes a simplified transformer model named DistilledTrans and applies the original transformer model, DistilledTrans, BERT + final layer, Robustly Optimized BERT Approach (RoBERTa) + final layer, and a hybrid method combining pre-trained (BERT, RoBERTa) with a Convolutional Neural Network (CNN) or Long Short-term Memory (LSTM) network model to detect insider threats. Finally, this paper presents experimental results on a dense dataset CERT r4.2 and augmented sporadic dataset CERT r6.2, evaluates their performance, and performs a comparison analysis with state-of-the-art models. Promising experimental results show that 1) contextual word embedding insert and substitution predicted by the BERT model, and context embedding sentences predicted by the GPT-2 model are effective data augmentation approaches to address high data imbalance; 2) DistilledTrans trained with sporadic dataset CERT r6.2 augmented by the contextual embedding sentence method predicted by GPT-2, outperforms the state-of-the-art models in terms of all evaluation metrics, including accuracy, precision, recall, F1-score, and Area Under the ROC Curve (AUC). Additionally, its structure is much simpler, and thus training time and computing cost are much less than those of recent models; 3) when trained with the dense dataset CERT r4.2, pre-trained models BERT plus a final layer or RoBERTa plus a final layer can achieve significantly higher performance than the current models with a very little sacrifice of precision. However, complex hybrid methods may not be required. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 28
ER  -

TY  - CONF
AU  - Dinardo, K.
AU  - Lemoudden, M.
AU  - Ahmad, J.
TI  - Insider Threat Detection on an Imbalanced Dataset Using Balancing Methods
PY  - 2023
T2  - Lecture Notes in Networks and Systems
VL  - 711 LNNS
SP  - 1216
EP  - 1226
DO  - 10.1007/978-3-031-37717-4_80
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174713019&doi=10.1007%2F978-3-031-37717-4_80&partnerID=40&md5=cc2f43ec15609509813991c15058d65d
AB  - Organizations face a serious security risk from insider threats. In the literature, machine learning approaches have been used as a potential defence against this type of threats. However, if the dataset used is greatly imbalanced, they may be biased or wrong. In this paper, we use machine learning and balancing techniques to create models able to better detect insider threat behaviour. The results show that these techniques improve the detection performance in terms of accuracy by 13%. This suggests that using pre-trained models on artificially balanced datasets could have an important role in a larger detection approach. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Hsu, C.
AU  - Ku, C.-T.
AU  - Wang, Y.
AU  - Hsieh, M.
AU  - Wu, J.-T.
AU  - Hsieh, Y.
AU  - Chang, P.
AU  - Lu, Y.
AU  - Kang, Y.
TI  - A Teacher-Student Knowledge Distillation Framework for Enhanced Detection of Anomalous User Activity
PY  - 2023
SP  - 20
EP  - 21
DO  - 10.1109/IRI58017.2023.00011
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171883689&doi=10.1109%2FIRI58017.2023.00011&partnerID=40&md5=3e381bf22634a19edc47c618afa21355
AB  - As information systems continuously produce high volumes of user event log data, efficient detection of anomalous activities indicative of insider threats becomes crucial. Typical supervised Machine Learning (ML) methods are often labor-intensive and suffer from the constraints of costly labeled data with unknown anomaly dependencies. Here we introduce a knowledge distillation ML framework, using multiple binary classifiers as teacher models and a multi-label model as the student. Leveraging the soft targets of teacher models, we demonstrate that the student model significantly improves performance. © 2023 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Yousef, R.
AU  - Jazzar, M.
AU  - Eleyan, A.
AU  - Bejaoui, T.
TI  - A Machine Learning Framework & Development for Insider Cyber-crime Threats Detection
PY  - 2023
DO  - 10.1109/SmartNets58706.2023.10215718
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170647745&doi=10.1109%2FSmartNets58706.2023.10215718&partnerID=40&md5=c0cf2abf364b046d3d95290050ee1698
AB  - Many organizations face a significant challenge with insider threats. As conventional security measures like intrusion detection systems and firewalls aren't always effective in detecting and preventing such threats. Insider threats often come from trusted individuals who possess knowledge of and access to important organizational assets. This work explores the use of machine learning to classify insider threat behaviors, specifically focusing on three approaches such that supervised, unsupervised, and reinforcement learning. The paper describes the development of an unsupervised machine learning system that analyzes data from multiple technical sources to detect malicious insider activity. The system, which is designed to be simple and easy to assemble, was tested with existing machine learning algorithms and showed moderate success in detecting malicious insider activity during the training phase and negligible success during the testing phase.These results suggest that while machine learning can be a useful tool for detecting insider threats, it should not be solely relied upon for threat detection. To improve the current system's performance, it is necessary to include additional features, such as file names, email subjects and headers, and website types. Furthermore, physical security, cybersecurity, psychological, and organizational factors must be considered when addressing insider threats. Future research should focus on acquiring real datasets, collecting insider threat scenarios and use cases, and testing different machine learning approaches from both technical and non-technical sources. © 2023 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 18
ER  -

TY  - JOUR
AU  - Al-Muntaser, B.
AU  - Mohamed, M.A.
AU  - Tuama, A.Y.
AU  - Rana, I.A.
TI  - Cybersecurity Advances in SCADA Systems Machine Learning-based Insider Threat Detection and Future Directions
PY  - 2023
T2  - International Journal of Advanced Computer Science and Applications
VL  - 14
IS  - 8
SP  - 318
EP  - 328
DO  - 10.14569/IJACSA.2023.0140835
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170640914&doi=10.14569%2FIJACSA.2023.0140835&partnerID=40&md5=ee20dd7f5dff47c5a29e98ef95abaa31
AB  - The management of critical infrastructure heavily relies on Supervisory Control and Data Acquisition [SCADA] systems, but as they become more connected, insider attacks become a greater concern. Insider threat detection systems [IDS] powered by machine learning have emerged as a potential answer to this problem. In order to identify and neutralize insider threats, this review paper examines the most recent developments in machine learning algorithms for insider IDS in SCADA security systems. A thorough analysis of research articles published in 2019 and later, focussed on variety of machine learning methods, have been adopted in this review study to better highlight difficulties and challenges being faced by professionals, and how the study will contribute to overcome them. The results show that, in addition to conventional methods, machine-learning based intrusion detection techniques offer important advantages in identifying complex and covert insider attacks. Finding pertinent insider threat data for model training and guaranteeing data privacy and security are still difficult to address. Ensemble techniques and hybrid strategies show potential for improving detection resiliency. In conclusion, machine learning-based insider IDS has the potential to protect critical infrastructures by strengthening SCADA systems against insider attacks. The similarities and differences between cyber physical systems and SCADA systems, emphasizing security challenges and the potential for mutual improvement were also reviewed in this study. In order to be as effective as possible, future research should concentrate on addressing issues with data collecting and privacy, investigating the latest developments in technology, and creating hybrid models. SCADA systems can accomplish proactive and effective defence against insider attacks by integrating machine learning advancements, maintaining their dependability and security in the face of emerging threats. © (2023), (Science and Information Organization). All Rights Reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Li, Y.
AU  - Su, Y.
TI  - The Insider Threat Detection Method of University Website Clusters Based on Machine Learning
PY  - 2023
SP  - 560
EP  - 565
DO  - 10.1109/ICAIBD57115.2023.10206282
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169595452&doi=10.1109%2FICAIBD57115.2023.10206282&partnerID=40&md5=caabbe211297ee5ed028a15dd58b891b
AB  - In recent years, the informationization construction of universities has developed rapidly. The cluster system has become a standard configuration for most university websites. However, there have been many risks and problems in the use of cluster systems, which have hindered the progress of information security in universities. Especially, the security threats caused by malicious behavior of internal personnel have posed detection difficulties due to the fuzzy boundaries and limited sample data. This paper proposes a machine learning-based log anomaly detection model, which can automatically parse and detect data in the log system for insider threats in the universities' cluster system without the need for annotated data. Considering the differences between users, the model learns the behavior patterns of each user type based on their IP and role distinctions, and then detects abnormal behaviors based on the learned normal behavior patterns. According to experimental evaluation of user data in the cluster system of the Civil Aviation Flight University of China, the results indicate that the insider anomaly detection model proposed in this paper performs well. © 2023 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 14
ER  -

TY  - JOUR
TI  - 2023 IST-Africa Conference, IST-Africa 2023
PY  - 2023
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168567130&partnerID=40&md5=10f2428061960fc695edf382eeff4f03
AB  - The proceedings contain 68 papers. The topics discussed include: smart table: virtual environment for teaching mathematical concepts - continuum; food supply blockchain: a bright future for the food supply chain; reversing cyber loneliness; digital technologies for integrated food loss and waste reduction in agrifood chains in Sub-Saharan Africa: a scoping review; private timestamps and selective verification of notarized data on a blockchain; technology transfer through business-to-business partnerships: lessons from sales partnerships between German manufacturers and African distributors; supporting well-being: a digital intervention model for disclosing sexual harassment in higher education; towards a new insider threat mitigation framework; bibliometric analysis of cloud computing in agriculture using remote sensing data; and a comparison of fully-linear deep learning methods for pipe burst localization in water distribution networks.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
TI  - 2023 2nd International Conference on Electrical, Electronics, Information and Communication Technologies, ICEEICT 2023
PY  - 2023
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166030468&partnerID=40&md5=e0917a04a4fbff582d06206780dfd308
AB  - The proceedings contain 205 papers. The topics discussed include: anxiety, depression and stress prediction among college students using machine learning algorithms; objective full-reference image assessment metrics for estimating the quality of remote sensing images; vertical collision risk of aircraft based on improved event model; prediction and detection of insider threat detection using emails: a comparison; structured text programming to visualize the distribution of packages on a conveyor; tomato plant disease detection using deep learning based techniques: a comparative study; comparative analysis for detecting drowsiness using deep learning approach; feature level fine grained sentiment analysis for classifying online restaurant reviews; and local antimagic chromatic number of certain classes of trees.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Peccatiello, R.B.
AU  - Gondim, J.J.C.
AU  - García, L.P.F.
TI  - Applying One-Class Algorithms for Data Stream-Based Insider Threat Detection
PY  - 2023
T2  - IEEE Access
VL  - 11
SP  - 70560
EP  - 70573
DO  - 10.1109/ACCESS.2023.3293825
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164704569&doi=10.1109%2FACCESS.2023.3293825&partnerID=40&md5=e3cd415e5a9f45c7ecbdcb48ad1fdf53
AB  - An insider threat is anyone who has legitimate access to a particular organization's network and uses that access to harm that organization. Insider threats may act with or without intent, but when they have an intention, they usually also have some specific motivation. This motivation can vary, including but not limited to personal discontent, financial issues, and coercion. It is hard to face insider threats with traditional security solutions because those solutions are limited to the signature detection paradigm. To overcome this restriction, researchers have proposed using Machine Learning which can address Insider Threat issues more comprehensively. Some of them have used batch learning, and others have used stream learning. Batch approaches are simpler to implement, but the problem is how to apply them in the real world. That is because real insider threat scenarios have complex characteristics to address by batch learning. Although more complex, stream approaches are more comprehensive and feasible to implement. Some studies have also used unsupervised and supervised Machine Learning techniques, but obtaining labeled samples makes it hard to implement fully supervised solutions. This study proposes a framework that combines different data science techniques to address insider threat detection. Among them are using semi-supervised and supervised machine learning, data stream analysis, and periodic retraining procedures. The algorithms used in the implementation were Isolation Forest, Elliptic Envelop, and Local Outlier Factor. This study evaluated the results according to the values obtained by the precision, recall, and F1-Score metrics. The best results were obtained by the ISOF algorithm, with 0.78 for the positive class (malign) recall and 0.80 for the negative class (benign) recall. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 12
ER  -

TY  - CONF
AU  - Padiet, P.
AU  - Islam, R.
AU  - Khan, M.A.
TI  - Analysis of Malicious Intruder Threats to Data Integrity
PY  - 2023
T2  - Lecture Notes in Networks and Systems
VL  - 700 LNNS
SP  - 359
EP  - 368
DO  - 10.1007/978-3-031-33743-7_29
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163340228&doi=10.1007%2F978-3-031-33743-7_29&partnerID=40&md5=6abd781e14e90f16caa2e786ae6537e7
AB  - The insider threat has increasingly become the cyber security challenge that threatens organisation, financial enterprises, and governmental agencies. Insider threat is being carryout by former and current employees. Meanwhile, insider threat had authorised access to an organisation asset, thus they have better opportunity to undermine the confidentiality, availability, or data integrity than an external attacker. The detection process consists of different techniques, including detecting suspicious activities in the system. This paper focus on insider threat detection through behavior analysis of user’s activities. A deep machine learning approach has been proposed to detect insiders’ threat with better accuracy with low false positive rate. The publicly available dataset used is the CMU CERT synthetic malicious insider threat dataset r4.2. Our empirical evidence outperforms compared to similar existing models, it proved that our approach (LMT) has high accuracy (99.6%), precision (99.6%) and ROC (99.6%). © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Anju, A.
AU  - Marudhamuthu, M.
AU  - Nithakalyani, M.
AU  - Shalini, K.
AU  - Haritha, R.
TI  - A Review to Analyze Insider Threats Using Machine Learning Techniques
PY  - 2023
T2  - Lecture Notes in Networks and Systems
VL  - 623 LNNS
SP  - 499
EP  - 509
DO  - 10.1007/978-981-19-9638-2_43
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163280121&doi=10.1007%2F978-981-19-9638-2_43&partnerID=40&md5=dbe5c7c65871b5bd9f099dbfdcfcda2e
AB  - The most difficult risks in cyber world are insider threats, because of the modest nature of the insider threat it is quite difficult to identify attackers. Over the last few decades, insider threat detection has risen in popularity. Insider threats are one of the most difficult risks on the internet, and they usually pose serious complications for the organization. Insider attacks are perpetrated by persons who have lawful access to an organization's network, applications, or databases. To analyze the framework execution, many execution methodologies have been identified to work with insider danger situations. Because of the nuanced and adaptive nature of insider threats, heterogeneity, and complexity, it is challenging to identify the behavioral differences between insider users and regular users due to the lack of defined insider risks. On the basis of the audit raw data, network, or ambient data-based the problem of identifying security breaches has been taken into consideration. Then, each piece of work is assessed based on its capacity to defend against insider threats, the manner in which data is gathered from the relevant data sources, and the type of the algorithm used to deal with situations. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Yadav, M.
AU  - Mishra, D.S.
TI  - Identification of network threats using live log stream analysis
PY  - 2023
DO  - 10.1109/PCEMS58491.2023.10136070
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163156495&doi=10.1109%2FPCEMS58491.2023.10136070&partnerID=40&md5=0f0227104e278927e6e7de9aefd5240b
AB  - The field of information security has covered various sectors in order to secure data which is stored online, offline, and during transmission over the network. The standard process of system log analysis is to first parse unstructured logs into structured data, and then apply data mining and machine learning techniques to analyze the data and build a threat detection model. This paper proposes a novel idea for identifying the network threat in an organisation. We take live network device logs in different log formats as input and send them for analysis. Whether a live log contains an anomaly, any vulnerability, or any insider threat will be identified. To find suspicious activity in the network, the logs will be processed, and find any activity at the same time. © 2023 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Jah Rizvi, S.K.
AU  - Javed, K.F.
AU  - Moazam, M.
TI  - CAS - Attention based ISO/IEC 15408-2 Compliant Continuous Audit System for Insider Threat Detection
PY  - 2023
SP  - 153
EP  - 157
DO  - 10.1109/ICAI58407.2023.10136657
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162634563&doi=10.1109%2FICAI58407.2023.10136657&partnerID=40&md5=0200412b987339a1627f17f08b312802
AB  - Enterprises are facing information security threats to intranet-based infrastructure and allied systems from external as well as insider cyber actors. A lot of research has been done to identify the evil insiders and prevent their malicious acts. Moreover, there are many others challenges such as limited availability of real labeled data, variations in organizational nature and emerging zero-day attempts from insiders. Therefore, new approaches are essentially required to combat Information Security (IS) non-complaint behavior and emerging insider cyber threats. To this end, we proposed a novel information security auditing-based system for insider threat detection. Unlike traditional audit approaches, this novel approach is based on continuous auditing system. The approach also fulfills the requirements of with ISO/IEC 15408-2 auditing standard. Moreover, system also proposed deep attention neural network to classify the trusted and untrusted users based on the generated activity logs. We evaluated CAS on the defacto dataset for insider threat detection i.e., CERT. 6.2. Evaluation results show that the proposed model learns from real-world data sets to detect IS non-complaint actions to classify the untrusted insider. The proposed model achieved an accuracy of more than 97% and outpaced traditional machine learning approaches. © 2023 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Mehmood, M.
AU  - Amin, R.
AU  - Muslam, M.M.A.
AU  - Xie, J.
AU  - Aldabbas, H.
TI  - Privilege Escalation Attack Detection and Mitigation in Cloud Using Machine Learning
PY  - 2023
T2  - IEEE Access
VL  - 11
SP  - 46561
EP  - 46576
DO  - 10.1109/ACCESS.2023.3273895
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159793723&doi=10.1109%2FACCESS.2023.3273895&partnerID=40&md5=fd6c892a9a07138705b9d2ee3de2bc1f
AB  - Because of the recent exponential rise in attack frequency and sophistication, the proliferation of smart things has created significant cybersecurity challenges. Even though the tremendous changes cloud computing has brought to the business world, its centralization makes it challenging to use distributed services like security systems. Valuable data breaches might occur due to the high volume of data that moves between businesses and cloud service suppliers, both accidental and malicious. The malicious insider becomes a crucial threat to the organization since they have more access and opportunity to produce significant damage. Unlike outsiders, insiders possess privileged and proper access to information and resources. In this work, a machine learning-based system for insider threat detection and classification is proposed and developed a systematic approach to identify various anomalous occurrences that may point to anomalies and security problems associated with privilege escalation. By combining many models, ensemble learning enhances machine learning outcomes and enables greater prediction performance. Multiple studies have been presented regarding detecting irregularities and vulnerabilities in network systems to find security flaws or threats involving privilege escalation. But these studies lack the proper identification of the attacks. This study proposes and evaluates ensembles of Machine learning (ML) techniques in this context. This paper implements machine learning algorithms for the classification of insider attacks. A customized dataset from multiple files of the CERT dataset is used. Four machine learning algorithms, i.e., Random Forest (RF), Adaboost, XGBoost, and LightGBM, are applied to that dataset and analyzed results. Overall, LightGBM performed best. However, some other algorithms, such as RF or AdaBoost, may perform better on some internal attacks (Behavioral Biometrics attacks) or other internal attacks. Therefore, there is room for incorporating more than one machine learning algorithm to obtain a stronger classification in multiple internal attacks. Among the proposed algorithms, the LightGBM algorithm provides the highest accuracy of 97%; the other accuracy values are RF at 86%, AdaBoost at 88%, and XGBoost at 88.27%. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 43
ER  -

TY  - CONF
AU  - Besnaci, S.
AU  - Hafidi, M.
AU  - Lamia, M.
TI  - Dealing with extremly Unbalanced Data and Detecting Insider Threats with Deep Neural Networks
PY  - 2023
DO  - 10.1109/ICAECCS56710.2023.10105103
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158941555&doi=10.1109%2FICAECCS56710.2023.10105103&partnerID=40&md5=5bc31f87f4d3eeaba2c9d1876e0685d8
AB  - The internal and external security of a company is important. External security can be secured by setting up mechanisms to monitor any external flow, while internal security is the most complex, in this case how do we monitor internal workers who have full privileges to access the resources and data of the organization? All necessary measures must be in place to avoid internal damage, which has increased considerably in last years. Since the number of harmful behaviors is very low compared to normal events, the imbalance in class scores does not allow supervised learning algorithms to provide accurate results as their learning depends on balanced categories. Therefore, it is necessary to use a model capable of distinguishing clearly the harmful category. In previous work, ML techniques were used, although they are less effective if the data used are not balanced. In this document, we propose an S-LSTM model based on the integration of sampling approach, which is the generation of synthetic samples to balance the two classes of learning by SMOTE technique and LSTM algorithm for identify abnormal behavior. To build and evaluate the model, we used the Cert v4.2 dataset, and through the experimental evaluation, which gave a high prediction accuracy of 99%, we show that the proposed model provides a better solution. to detect the insider threat. © 2023 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 6
ER  -

TY  - CONF
AU  - Liu, J.
AU  - Zhang, J.
AU  - Du, C.
AU  - Wang, D.
TI  - MUEBA: A Multi-model System for Insider Threat Detection
PY  - 2023
T2  - Lecture Notes in Computer Science
VL  - 13655 LNCS
SP  - 296
EP  - 310
DO  - 10.1007/978-3-031-20096-0_23
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148699006&doi=10.1007%2F978-3-031-20096-0_23&partnerID=40&md5=040cde95f933cde1b6957a1f8c35ee12
AB  - In the current era of digital communications, cyber security and data protection have always been a top priority. More and more organizations are starting to take insider threat security seriously. Traditional rule-based anomaly detection solutions generate a large number of alerts and are difficult to adapt to particular scenarios. UEBA (User and Entity Behavior Analysis), which correlates entities, events, and users, has become an emerging organizational solution by combining all-around contextual analysis through statistical and machine learning methods. In this paper, we propose MUEBA, a multi-model UEBA system for spatiotemporal analysis, combining user individual historical analysis and group analysis to detect insider threats. The individual historical analysis module uses the attention-based LSTM to improve the model’s sensitivity to abnormal operations and help security analysts improve their efficiency in responding to threat events. In the group analysis module, we have extended the iForest algorithm in attribute selection and iTree construction, which increased the algorithm’s stability. Finally, we comprehensively decide on the above two aspects and propose a full-time user and entity behavior analysis system. Experimental evaluations on the public CERT-4.2 dataset show that our system outperforms either single model in both stability and precision. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Bin Sarhan, B.
AU  - Altwaijry, N.
TI  - Insider Threat Detection Using Machine Learning Approach
PY  - 2023
T2  - Applied Sciences (Switzerland)
VL  - 13
IS  - 1
C7  - 259
DO  - 10.3390/app13010259
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145709034&doi=10.3390%2Fapp13010259&partnerID=40&md5=b57d82c1869b78d5117844455c4e3264
AB  - Insider threats pose a critical challenge for securing computer networks and systems. They are malicious activities by authorised users that can cause extensive damage, such as intellectual property theft, sabotage, sensitive data exposure, and web application attacks. Organisations are tasked with the duty of keeping their layers of network safe and preventing intrusions at any level. Recent advances in modern machine learning algorithms, such as deep learning and ensemble models, facilitate solving many challenging problems by learning latent patterns and modelling data. We used the Deep Feature Synthesis algorithm to derive behavioural features based on historical data. We generated 69,738 features for each user, then used PCA as a dimensionality reduction method and utilised advanced machine learning algorithms, both anomaly detection and classification models, to detect insider threats, achieving an accuracy of 91% for the anomaly detection model. The experimentation utilised a publicly available insider threat dataset called the CERT insider threats dataset. We tested the effect of the SMOTE balancing technique to reduce the effect of the imbalanced dataset, and the results show that it increases recall and accuracy at the expense of precision. The feature extraction process and the SVM model yield outstanding results among all other ML models, achieving an accuracy of 100% for the classification model. © 2022 by the authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 58
ER  -

TY  - JOUR
AU  - S, S.
AU  - D, D.
AU  - Padmavathi, G.
TI  - Malicious insider threat detection using variation of sampling methods for anomaly detection in cloud environment
PY  - 2023
T2  - Computers and Electrical Engineering
VL  - 105
C7  - 108519
DO  - 10.1016/j.compeleceng.2022.108519
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143544061&doi=10.1016%2Fj.compeleceng.2022.108519&partnerID=40&md5=847f136b92189df8351f3a46acfba36e
AB  - Machine learning (ML) techniques have currently been exploited for malicious insider threat (MIT) detection. The data variation between malicious and genuine user influences the ML model to misinterpret a malicious insider. Hence, the class imbalance problem (CIP) remains a challenging one. Regardless of the CIP in MIT detection, past research has a significant shortfall in deploying diverse sampling methods. i.e., undersampling and oversampling approach. This study proposed a novel double-layer architecture for MIT detection. The initial layer involves integration, transformation, and sampling system of data. In the sampling system, an efficient sampling approach is adopted to depreciate CIP among eight sampling techniques, depending on the performance of support vector machine (SVM) classifier. Nearmiss2 (NM-2) excels and is considered an optimal sampling technique. In the second layer, sampled data of NM-2 is employed in an anomalous MIT detection model using various anomaly detection techniques and evaluated with performance metrics. The main focus is to validate the solution for CIP in anomaly detection techniques with previous research. The proposed double-layer architecture with NM-2 and One-class SVM obtained recall and f-score of 100% and 78.72%. In contrast, it exhibits an accuracy of 82.46%, with a reasonable detection rate for MIT detection © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 27
ER  -

TY  - JOUR
AU  - Alabdulkreem, E.
AU  - Alduailij, M.
AU  - Alduailij, M.
AU  - Mansour, R.F.
TI  - Optimal weighted fusion based insider data leakage detection and classification model for Ubiquitous computing systems
PY  - 2022
T2  - Sustainable Energy Technologies and Assessments
VL  - 54
C7  - 102815
DO  - 10.1016/j.seta.2022.102815
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139336809&doi=10.1016%2Fj.seta.2022.102815&partnerID=40&md5=8c57d702f338eb5d2a53d0aa01a90570
AB  - With the rapid growth and evolving advancement in artificial technology, Ubiquitous computing methods plays a vital role in day to day lives. Insider threats were malicious activities which are executed by an official worker within an institution. Insider threats indicate cybersecurity challenges for public and private companies, as an insider attack could cause widespread damages to company properties than exterior attacks. Many prevailing methods in the domain of insider threat concentrated on identifying general insider attack situations. But insider attacks are takes place in several ways, and one of the dangerous attack is a data leakage attack which is accomplished by a malicious insider before one leaves a company. This article develops a Metaheuristic with Weighted Fusion Based Insider Data Leakage Detection and Classification (MWF-IDLDC) Model for Ubiquitous Computing Systems. The presented MWF-IDLDC technique primarily performs pre-processing and feature extraction at the initial stage. In addition, the MWF-IDLDC technique derives a weighted fusion-based feature extraction approach comprising three DL methods namely long short-term memory (LSTM), gated recurrent unit (GRU), and stacked autoencoder (SAE). For optimally tuning the hyperparameters related to the DL models, the ant lion optimizer (ALO) algorithm is utilized in this study. The design of fusion process with ALO hyperparameter optimizer demonstrate the novelty of the work. The experimental validation of the MWF-IDLDC approach can be tested using a series of simulations and the outcomes were scrutinized under distinct aspects. The comparative analysis highlighted the improvements of the MWF-IDLDC method compared to recent approaches with maximum accuracy of 99.40%. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - Aloraini, F.
AU  - Javed, A.
AU  - Rana, O.
AU  - Burnap, P.
TI  - Adversarial machine learning in IoT from an insider point of view
PY  - 2022
T2  - Journal of Information Security and Applications
VL  - 70
C7  - 103341
DO  - 10.1016/j.jisa.2022.103341
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139080324&doi=10.1016%2Fj.jisa.2022.103341&partnerID=40&md5=22990a17313918cea6bec52b71d5dcf3
AB  - With the rapid progress and significant successes in various applications, machine learning has been considered a crucial component in the Internet of Things ecosystem. However, machine learning models have recently been vulnerable to carefully crafted perturbations, so-called adversarial attacks. A capable insider adversary can subvert the machine learning model at either the training or testing phase, causing them to behave differently. The vulnerability of machine learning to adversarial attacks becomes one of the significant risks. Therefore, there is a need to secure machine learning models enabling the safe adoption in malicious insider cases. This paper reviews and organizes the body of knowledge in adversarial attacks and defense presented in IoT literature from an insider adversary point of view. We proposed a taxonomy of adversarial methods against machine learning models that an insider can exploit. Under the taxonomy, we discuss how these methods can be applied in real-life IoT applications. Finally, we explore defensive methods against adversarial attacks. We believe this can draw a comprehensive overview of the scattered research works to raise awareness of the existing insider threats landscape and encourages others to safeguard machine learning models against insider threats in the IoT ecosystem. © 2022 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 34
ER  -

TY  - JOUR
AU  - He, D.
AU  - Lv, X.
AU  - Xu, X.
AU  - Yu, S.
AU  - Li, D.
AU  - Chan, S.
AU  - Guizani, M.
TI  - An Effective Double-Layer Detection System Against Social Engineering Attacks
PY  - 2022
T2  - IEEE Network
VL  - 36
IS  - 6
SP  - 92
EP  - 98
DO  - 10.1109/MNET.105.2100425
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135744580&doi=10.1109%2FMNET.105.2100425&partnerID=40&md5=9a9c14a6da2c76a6b73558f56a7c363c
AB  - In recent years, social engineering attacks that use phishing emails as the medium and target specific groups of people have occurred frequently. Current enterprise systems are vulnerable to social engineering attacks. In addition, existing detection methods are relatively ineffective. Therefore, we propose a double-layer detection framework based on deep learning technology. First, a phishing email detection model based on Long Short-Term Memory (LSTM) and extreme gradient boosting tree (XGBoost) is designed from the perspective of individual security. Then, an insider threat detection model based on Bidirectional LSTM and Attention mechanism is designed from the perspective of group security. Finally, combined with the social engineering network attack simulation theory, a social engineering attack and defense simulation platform is established. In the double-layer frame-work, we use Bi-LSTM to obtain long-range dependent features of email body and user sequence information. Then XGBoost and Attention mechanism are used to further strengthen the network structure and improve the classification accuracy. Compared with traditional methods, our model does not require manual feature extraction, and can accurately identify phishing emails and insider threats. Finally, our proposed social engineering simulation platform verifies the effectiveness of the two-layer model. The experimental results show that our proposed framework has the characteristics of timely detection and after-the-fact investigation, which can effectively detect phishing attacks and insider threats faced by enterprise systems. © 1986-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 8
ER  -

TY  - CONF
TI  - Innovations in Computational and Computer Techniques, ICACCT 2021
PY  - 2022
T2  - AIP Conference Proceedings
VL  - 2555
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141882055&partnerID=40&md5=af0c597a32b3a3908d146c9576041325
AB  - The proceedings contain 85 papers. The topics discussed include: a deep learning based model for detection of android malwares using PCA over physical devices; artificial intelligence-application in the field of Indian banking sector; multi disease prediction based on combined deep reinforcement Boltzmann machines; a machine learning model for detection of man in the middle attack over unsecured devices; a review for insider threats detection using machine learning; time series clustered benchmarking in data envelopment analysis: attainable efficiency enhancement approach for an entity; machine learning approach for heart disease prediction: a survey; employing deep learning for detection of gravitational waves from compact binary coalescences; impact of technical indicators in stock price prediction; analysis of worldwide real-time recovery and death ratio of COVID-19 pandemic; and feature subset selection using filter, heuristic and meta-heuristic approaches using binary encoded diabetes dataset.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Ahmadi-Assalemi, G.
AU  - al-Khateeb, H.
AU  - Epiphaniou, G.
AU  - Aggoun, A.
TI  - Super Learner Ensemble for Anomaly Detection and Cyber-Risk Quantification in Industrial Control Systems
PY  - 2022
T2  - IEEE Internet of Things Journal
VL  - 9
IS  - 15
SP  - 13279
EP  - 13297
DO  - 10.1109/JIOT.2022.3144127
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123353797&doi=10.1109%2FJIOT.2022.3144127&partnerID=40&md5=8106049f8821f1cd90d972f78811ae2a
AB  - Industrial control systems (ICSs) are integral parts of smart cities and critical to modern societies. Despite indisputable opportunities introduced by disruptor technologies, they proliferate the cybersecurity threat landscape, which is increasingly more hostile. The quantum of sensors utilized by ICS aided by artificial intelligence (AI) enables data collection capabilities to facilitate automation, process streamlining, and cost reduction. However, apart from the operational use, the sensors generated data combined with AI can be innovatively utilized to model anomalous behavior as part of layered security to increase resilience to cyberattacks. We introduce a framework to profile anomalous behavior in ICS and derive a cyber-risk score. A novel super learner ensemble for one-class classification is developed, using overlapping rolling windows with stratified, k -fold, n -repeat cross-validation applied to each base learner followed by majority voting to derive the best learner. Our approach is demonstrated on a liquid distribution sensor data set. The experimental results reveal that the proposed technique achieves an overall F1 -score of 99.13%, an anomalous recall score of 99% detecting anomalies lasting only 17 s. The key strength of the framework is the low computational complexity and error rate. The framework is modular, generic, applicable to other ICS, and transferable to other smart city sectors. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 25
ER  -

TY  - JOUR
AU  - Amuda, O.K.
AU  - Akinyemi, B.O.
AU  - Sanni, M.L.
AU  - Aderounmu, G.A.
TI  - A Predictive User Behaviour Analytic Model for Insider Threats in Cyberspace
PY  - 2022
T2  - International Journal of Communication Networks and Information Security
VL  - 14
IS  - 1
SP  - 150
EP  - 159
DO  - 10.17762/ijcnis.v14i1.5208
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129250441&doi=10.17762%2Fijcnis.v14i1.5208&partnerID=40&md5=c6b13a26bb4a32697507087f25a4487b
AB  - Insider threat in cyberspace is a recurring problem since the user activities in a cyber network are often unpredictable. Most existing solutions are not flexible and adaptable to detect sudden change in user's behaviour in streaming data, which led to a high false alarm rates and low detection rates. In this study, a model that is capable of adapting to the changing pattern in structured cyberspace data streams in order to detect malicious insider activities in cyberspace was proposed. The Computer Emergency Response Team (CERT) dataset was used as the data source in this study. Extracted features from the dataset were normalized using Min-Max normalization. Standard scaler techniques and mutual information gain technique were used to determine the best features for classification. A hybrid detection model was formulated using the synergism of Convolutional Neural Network (CNN) and Gated Recurrent Unit (GRU) models. Model simulation was performed using python programming language. Performance evaluation was carried out by assessing and comparing the performance of the proposed model with a selected existing model using accuracy, precision and sensitivity as performance metrics. The result of the simulation showed that the developed model has an increase of 1.48% of detection accuracy, 4.21% of precision and 1.25% sensitivity over the existing model. This indicated that the developed hybrid approach was able to learn from sequences of user actions in a time and frequency domain and improves the detection rate of insider threats in cyberspace. © 2022. All Rights Reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - Yıldırım, M.
AU  - Anarım, E.
TI  - Mitigating insider threat by profiling users based on mouse usage pattern: ensemble learning and frequency domain analysis
PY  - 2022
T2  - International Journal of Information Security
VL  - 21
IS  - 2
SP  - 239
EP  - 251
DO  - 10.1007/s10207-021-00544-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106229324&doi=10.1007%2Fs10207-021-00544-9&partnerID=40&md5=066b524c747014ff54c22b28879d766d
AB  - Exploring novel security layers in academia and industry is always a concern due to the types of malware developing currently. Adding a widely applicable security layer into existing ones in terms of verification can be achieved by profiling users by their behaviors. A great candidate may be mouse dynamics. The nature of behavioral biometry based on mouse dynamics contains less sensitive data and still can perform well enough. We present a verification model based on assigning legality scores to individual mouse actions and aggregate these scores to assign a legality probability to the whole session while investigating frequency domain features of movement sequences. How the combinational schemes can improve the performance of the overall system is also investigated. The publicly known Balabit Dataset which contains 10 users’ training and test sessions is used for evaluation. The classifiers are trained with only training sessions and evaluated on test sessions. After extensive several experiments, equal error rate with a value of 7.46% and area under the receiver operating characteristic curve with a value of 96.47% are achieved. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH, DE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - McCarthy, A.
AU  - Ghadafi, E.
AU  - Andriotis, P.
AU  - Legg, P.
TI  - Functionality-Preserving Adversarial Machine Learning for Robust Classification in Cybersecurity and Intrusion Detection Domains: A Survey
PY  - 2022
T2  - Journal of Cybersecurity and Privacy
VL  - 2
IS  - 1
SP  - 154
EP  - 190
DO  - 10.3390/jcp2010010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131418956&doi=10.3390%2Fjcp2010010&partnerID=40&md5=e75247e3ce0510c4315f74256ba80220
AB  - Machine learning has become widely adopted as a strategy for dealing with a variety of cybersecurity issues, ranging from insider threat detection to intrusion and malware detection. However, by their very nature, machine learning systems can introduce vulnerabilities to a security defence whereby a learnt model is unaware of so-called adversarial examples that may intentionally result in mis-classification and therefore bypass a system. Adversarial machine learning has been a research topic for over a decade and is now an accepted but open problem. Much of the early research on adversarial examples has addressed issues related to computer vision, yet as machine learning continues to be adopted in other domains, then likewise it is important to assess the potential vulnerabilities that may occur. A key part of transferring to new domains relates to functionality-preservation, such that any crafted attack can still execute the original intended functionality when inspected by a human and/or a machine. In this literature survey, our main objective is to address the domain of adversarial machine learning attacks and examine the robustness of machine learning models in the cybersecurity and intrusion detection domains. We identify the key trends in current work observed in the literature, and explore how these relate to the research challenges that remain open for future works. Inclusion criteria were: articles related to functionality-preservation in adversarial machine learning for cybersecurity or intrusion detection with insight into robust classification. Generally, we excluded works that are not yet peer-reviewed; however, we included some significant papers that make a clear contribution to the domain. There is a risk of subjective bias in the selection of non-peer reviewed articles; however, this was mitigated by co-author review. We selected the following databases with a sizeable computer science element to search and retrieve literature: IEEE Xplore, ACM Digital Library, ScienceDirect, Scopus, SpringerLink, and Google Scholar. The literature search was conducted up to January 2022. We have striven to ensure a comprehensive coverage of the domain to the best of our knowledge. We have performed systematic searches of the literature, noting our search terms and results, and following up on all materials that appear relevant and fit within the topic domains of this review. This research was funded by the Partnership PhD scheme at the University of the West of England in collaboration with Techmodal Ltd. © 2022 by the authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 61
ER  -

TY  - CONF
AU  - Asher Lee, H.
AU  - Prathapani, N.
AU  - Paturi, R.
AU  - Parmaksiz, S.
AU  - Di Troia, F.
TI  - NLP-based User Authentication through Mouse Dynamics
PY  - 2022
T2  - International Conference on Information Systems Security and Privacy
SP  - 696
EP  - 702
DO  - 10.5220/0011005900003120
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176306554&doi=10.5220%2F0011005900003120&partnerID=40&md5=729c41adfca7843fde088ba69c10c5f4
AB  - Insider threat attacks are increasing in most organizations yearly. It is also tough to prevent this type of attack because the threat is within the boundary, making them more dangerous than external threat actors. There can be a situation where a strong authentication layer is implemented for the external users, but due to cost or maintenance effort reasons, the authentication layer for insiders might not have proper security controls. One of the types of insider threat attacks is to exploit established sessions by legitimate users. There are certain applications and operating systems that provide an in-built security mechanism to detect idle sessions and automatically expire the sessions if no action is performed by the user. However, this type of protection is still vulnerable since it cannot really detect if the user who is taking action is the legitimate user or not. In this paper, we propose to use an advanced machine learning model based on Natural Language Processing (NLP) algorithms to authenticate users based on their mouse dynamics in web browser contexts. The model can provide a protective layer that continuously monitors against insider threat attacks. By this method, we can prevent malicious users from accessing unauthorized assets and provide enhanced security to legitimate users. © 2022 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Xin, W.
AU  - Shen, Q.
AU  - Feng, K.
AU  - Xia, Y.
AU  - Wu, Z.
AU  - Lin, Z.
TI  - Personalized User Profiles-based Insider Threat Detection for Distributed File System
PY  - 2022
SP  - 1441
EP  - 1446
DO  - 10.1109/TrustCom56396.2022.00204
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151636426&doi=10.1109%2FTrustCom56396.2022.00204&partnerID=40&md5=793c256590b85417828071644b15a314
AB  - In recent years, data security incidents caused by insider threats in distributed file systems have attracted the attention of academia and industry. The most common way to detect insider threats is based on user profiles. Through analysis, we realize that based on existing user profiles are not efficient enough, and there are many false positives when a stable user profile has not yet been formed. In this work, we propose personalized user profiles and design an insider threat detection framework, which can intelligently detect insider threats for securing distributed file systems in real-time. To generate personalized user profiles, we come up with a time window-based clustering algorithm and a weighted kernel density estimation algorithm. Compared with non-personalized user profiles, both the Recall and Precision of insider threat detection based on personalized user profiles have been improved, resulting in their harmonic mean F1 increased to 96.52%. Meanwhile, to reduce the false positives of insider threat detection, we put forward operation recommendations based on user similarity to predict new operations that users will produce in the future, which can reduce the false positive rate (FPR). The FPR is reduced to 1.54% and the false positive identification rate (FPIR) is as high as 92.62%. Furthermore, to mitigate the risks caused by inaccurate authorization for users, we present user tags based on operation content and permission. The experimental results show that our proposed framework can detect insider threats more effectively and precisely, with lower FPR and high FPIR. © 2022 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Nagabhushana Babu, B.
AU  - Gunasekaran, M.
TI  - An Analysis of Insider Attack Detection Using Machine Learning Algorithms
PY  - 2022
DO  - 10.1109/ICMNWC56175.2022.10032009
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148282667&doi=10.1109%2FICMNWC56175.2022.10032009&partnerID=40&md5=10732ae796ca4c5a8baafb12168359bb
AB  - Among the greatest obstacles in cybersecurity is insider threat, which is a well-known massive issue. This anomaly shows that the vulnerability calls for specialized detection techniques, and resources that can help with the accurate and quick detection of an insider who is harmful. Numerous studies on identifying insider threats and related topics were also conducted to tackle this problem are proposed. Various researches sought to improve the conceptual perception of insider risks. Furthermore, there are numerous drawbacks, including a dearth of actual cases, unfairness in drawing decisions, a lack of self-optimization in learning, which would be a huge concern and is still vague, and the absence of an investigation that focuses on the conceptual, technological, and numerical facets concerning insider threats and identifying insider threats from a wide range of perspectives. The intention of the paper is to afford a thorough exploration of the categories, levels, and methodologies of modern insiders based on machine learning techniques. Further, the approach and evaluation metrics for predictive models based on machine learning are discussed. The paper concludes by outlining the difficulties encountered and offering some suggestions for efficient threat identification using machine learning. © 2022 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Bharathi, S.T.
AU  - Chokkalingam, C.
TI  - Non-Trusted user Classification-Comparative Analysis of Machine and Deep Learning Approaches
PY  - 2022
SP  - 316
EP  - 324
DO  - 10.1109/ICAISS55157.2022.10010811
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147549942&doi=10.1109%2FICAISS55157.2022.10010811&partnerID=40&md5=4a9c9a7827189542d5d7b16e11a1bab5
AB  - A cloud environment in any context is subject to threats due to various non-trusted users. Non-trusted users might be the new users or existing trusted users who turn into non-trusted users. Classification of these users is needed in all scenarios. It has also been observed that the history of user behavior plays a key role in identifying non-trusted users. Such data would be high in volume and machine learning models are found to better suit them in classifying the non-trusted users. Instead of using the real-time data more similar data from the insider threat dataset is employed in the work. Since the features in the insider threat dataset cannot be directly used in the machine learning models, new features were created from them and a new dataset is created. Four different machine learning classifiers, Logistic Regression, Decision Tree, Random Forest Classifier, and K-Nearest Neighbor are used for classification. In addition to this, a deep neural network model is also created. The results are compared and it is found that the Deep Neural network model performs well than the other models with an accuracy of 88% and an AUC value of 0.856. the sigmoid activation function is used in the output layer of the deep artificial neural networks and hence it produces probability values that reflect the trust value of the users. © 2022 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Shi, Y.
AU  - Sagduyu, Y.E.
TI  - How to Launch Jamming Attacks on Federated Learning in NextG Wireless Networks
PY  - 2022
SP  - 945
EP  - 950
DO  - 10.1109/GCWkshps56602.2022.10008669
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146906588&doi=10.1109%2FGCWkshps56602.2022.10008669&partnerID=40&md5=ba7c6f0f62a68c35d573753ef4f5dd78
AB  - We study how to launch jamming attacks on federated learning when performed over wireless channels in NextG systems. Federated learning has emerged as a decentralized learning framework, where clients can collectively train a global model at the server without sharing their training datasets. To support NextG wireless network applications such as spectrum sensing and user equipment identification, federated learning can be used to train machine learning models to classify wireless signals that are collected by clients (spectrum sensors) at different locations while keeping training datasets of clients confidential. Federated learning is known to be susceptible to insider threats by malicious clients. In this paper, we consider external threats in terms of the over-the-air jamming attacks on federated learning in a wireless network. We study three scenarios that an adversary can jam the local model updates transmitted from clients to the server (uplink attack), or jam the global model updates transmitted from the server to clients (downlink attack), or jam both. We impose an attack budget on the number of clients that can be attacked per federated learning round. These clients are selected based on their local model accuracies that are expected in the absence of an attack or ranked by observing the spectrum. This selection may be fixed or change over time. We show that this jamming attack leads to a major loss of performance for federated learning compared to benchmark attacks. These results raise new security concerns for federated learning when executed in NextG wireless networks subject to jamming attacks. © 2022 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - Patil, R.C.
AU  - Kumar, A.
AU  - Narmadha, T.
AU  - Suganthi, M.
AU  - Siva Rama Rao, A.V.S.S.
AU  - Rajesh, A.
TI  - Data Leakage Detection in Cloud Computing Environment Using Classification Based on Deep Learning Architectures
PY  - 2022
T2  - International Journal of Intelligent Systems and Applications in Engineering
VL  - 10
IS  - 2s
SP  - 281
EP  - 285
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145471574&partnerID=40&md5=76bcbc6c54ebf99cbed3a040cb17ffd9
AB  - Insider threats are hostile actions that a legitimate employee of a company could commit. For both commercial and governmental enterprises, insider threats pose a significant cybersecurity risk since they have a considerably greater potential to harm an organization's assets than external attacks. The majority of currently utilised insider threat methodologies concentrated on identifying common insider attack scenarios. This research propose novel technique in data leakage detection in cloud computing based on data classification using deep learning architectures. Here the input data has been collected as network data and processed for noise removal, smoothening. The classification has been done based on Generative Regression kernel SVM. The experimental findings have been calculated in terms of RMSE, SNR, F-1 score, recall, accuracy, and precision. The proposed model offers practical approaches to deal with potential bias and class imbalance issues in order to design a system that effectively detects insider data leaking. Proposed technique attained accuracy of 97%, precision of 92%, recall of 67%, F-1 score of 66%, RMSE 62% and SNR of 61%. © 2022, Ismail Saritas. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 6
ER  -

TY  - CONF
AU  - Hong, W.
AU  - Yin, J.
AU  - You, M.
AU  - Wang, H.
AU  - Cao, J.
AU  - Li, J.
AU  - Liu, M.
TI  - Graph Intelligence Enhanced Bi-Channel Insider Threat Detection
PY  - 2022
T2  - Lecture Notes in Computer Science
VL  - 13787 LNCS
SP  - 86
EP  - 102
DO  - 10.1007/978-3-031-23020-2_5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145019650&doi=10.1007%2F978-3-031-23020-2_5&partnerID=40&md5=97e3e1a69a3a2d369c5bc0e8b34a1084
AB  - For an organization, insider intrusion generally poses far more detrimental threats than outsider intrusion. Traditionally, insider threat is detected by analyzing logged user behaviours and then establishing a binary classifier to distinguish malicious ones. However, most approaches consider user behaviour in an isolated manner, inevitably missing the background information from organizational connections such as a shared supervisor or e-mail interactions. Consequently, the performance of those existing works still has the potential to be enhanced. In this paper, we propose a bi-channel insider threat detection (B-CITD) framework enhanced by graph intelligence to improve the overall performance of existing methods. Firstly, We extract behavioural features from a series of log files as the inner-user channel features. Secondly, we construct an organizational connection graph and extract topological features through a graph neural networks (GNN) model as the inter-user channel features. In the end, the features from inner-user and inter-user channels are combined together to perform an insider threat detection task through a binary classification model. Experimental results on an open-sourced CERT 4.2 dataset show that B-CITD can enhance the performance of insider threat detection by a large margin, compared with using features only from inner-user or inter-user channels. We published our code on GitHub: https://github.com/Wayne-on-the-road/B-CITD. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 20
ER  -

TY  - JOUR
AU  - Sowmya, B.J.
AU  - Hanumantharaju, R.
AU  - Kumar, D.P.
AU  - Srinivasa, K.G.
TI  - Identification of authorship and prevention of fraudulent transactions/cybercrime using efficient high performance machine learning techniques
PY  - 2022
T2  - International Journal of Business Intelligence and Data Mining
VL  - 22
IS  - 1-2
SP  - 144
EP  - 169
DO  - 10.1504/ijbidm.2023.127312
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144381181&doi=10.1504%2Fijbidm.2023.127312&partnerID=40&md5=b2d31ba38ded22075f596617b07e837f
AB  - Cyber safety is the best skill required among a group of employees in organisations. Many offenders hide behind anonymous masking, including dishonest purchases, brazen plagiarism of the work, breaching corporate safety and stealing private data. To understand and analyse the actual phenomenon encountered with data, requirements of scientific methods, machine learning techniques, processes are to be used. This paper aims to tackle these problems by providing a protection layer for users, where data is being gathered from cyber security sources, analytical complement with latest data-driven patterns provides effective security solutions. We then discuss machine learning, deep learning powered models for the detection of insider threats and identifying authorship identification of anonymised articles. The individual modules are trained on authorship attribution, mouse monitoring, keyboard monitoring and command tracing and reached promising results with good accuracies in the range of 65%-85% on average. © 2023 Inderscience Enterprises Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 7
ER  -

TY  - CONF
AU  - Pham, N.
AU  - Guo, J.
AU  - Wang, Z.
TI  - Abnormality Detection in Network Traffic by Classification and Graph Data Analysis
PY  - 2022
SP  - 41
EP  - 47
DO  - 10.1109/IEMCON56893.2022.9946563
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143635037&doi=10.1109%2FIEMCON56893.2022.9946563&partnerID=40&md5=b655bc221a9300203bc622bf18b6f5ea
AB  - The invention of the Internet, along with the technology industry innovation, accommodates human society in the new age conveniently and effortlessly. Cyber-attacks, however, have increased drastically in the forms of ransomware, crypto- jacking, or insider threat. Many efforts have provided ways against network attacks as they put the digital world on the cliff edge. In this paper, we identify the abnormalities in the network traffic using a machine learning classification model and visualize the results via the graph network. We balanced the data, applied random forest to the training data, and used testing data to assess prediction accuracy. One novelty of our research is to utilize graph networks to visualize the ground truth and predicted network traffic. Both numerical performance and graph visualization support the competitive performance of our learning method. © 2022 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Arul, E.
AU  - Punidha, A.
TI  - Malicious Firmware Attack Detection in ICT tools Connected on Cloud Services using Deep Random Forest (MAC-DRF)
PY  - 2022
VL  - 8
SP  - 557
EP  - 562
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143302396&partnerID=40&md5=c057ea945c764fa04183550be975e167
AB  - Ever more advanced virus protection alternatives are relying on ML ways to protect malicious software users. Deep neural networks have generated outstanding results in over the last few last several years, instantly learning depictions of the functionality of complex problems, including such pictures, voice as well as message. Cloud malware insider threats are amongst the most important assaults on web systems, even though they can be carried out by any suspicious user. This approach is used by the attackers to insert malicious code or software into an end-user program operating on either SaaS, PaaS, or cloud services framework. It is indeed essential to build and collate a broad lot of practical functionality through hackers, database developers and developers. To illuminate this firmware assault on cloud providers with a profoundly logistic inference, Deep Random Forest was used (MAC-DRF).A single output device can be named harmful or benign by training a MAC-DRF with several input clusters of benign and malicious API calls. The proposed MAC-DRF was equipped to discover a poor trend in the virtual desktop firmware from Deep RF's hidden cloud. The results revealed that 98.47% of beneficial real numbers, and 0.02% of spyware attacks are feeble. © Grenze Scientific Society, 2022.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Gayathri, R.G.
AU  - Sajjanhar, A.
AU  - Xiang, Y.
TI  - Adversarial Training for Robust Insider Threat Detection
PY  - 2022
DO  - 10.1109/IJCNN55064.2022.9892059
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140798784&doi=10.1109%2FIJCNN55064.2022.9892059&partnerID=40&md5=6fa72707c3e4df35b3d3906044994b74
AB  - Insider threat analysis techniques based on machine learning provide convenient and effective automated detection of internally generated cyberattacks. When data are manipulated by adding slight perturbations, the threat intelligence models result in misclassifications of highly skewed class distribution with rare occurrences of events in insider threats. This paper proposes a generative model WGAN-GP conditioned by the class labels, referred to as CWGAN-GP, for insider threat analysis to create synthetic data samples for the rare malicious activities and shows that it generalizes well across different learning algorithms. Further, the robustness of the supervised algorithms to unknown inputs have not been investigated in any other works. This study explores how the synthetically created adversarial samples can increase the robustness of supervised models using adversarial training. We use a target classifier as threat model to generate one-step and iterative adversarial samples and perform a non-targeted test-time attack on the classifiers. We evaluate the robustness of various learning models against synthetic data from other data generation methods and demonstrate that the adversarial training using data generated from CWGAN-GP is less susceptible to adversarial attacks on insider threat classifiers using multiple versions of benchmark CMU CERT data set. © 2022 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 11
ER  -

TY  - JOUR
AU  - Hafizur Rahman, M.M.
AU  - Naeem, M.A.A.
AU  - Abubakar, A.
TI  - Threats From Unintentional Insiders: An Assessment of an Organization's Readiness Using Machine Learning
PY  - 2022
T2  - IEEE Access
VL  - 10
SP  - 110294
EP  - 110308
DO  - 10.1109/ACCESS.2022.3214819
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140720505&doi=10.1109%2FACCESS.2022.3214819&partnerID=40&md5=d4649e271f811214f8388951f5edba41
AB  - Today's organisations are facing a number of challenges, one of the most significant of which is ensuring the safety of their digital data. This is as a result of the fact that they are frequently faced with internal and external threats that can put the data they have been entrusted with in jeopardy of being compromised. As a result of this, this study investigates the dimension of threats associated to unintentional internal user of an organisation and utilises NARX to model and test a detection scheme associated to the menace. In addition, this study aims to provide a better understanding of the current state of the threat landscape. The data adopted for this research is primarily a 'user activity logs' dataset from CERT (release version r4.2). From the data, the study conceptualized 'Access', 'Motivation', and 'Action' to be the key dimensions influencing 'insider', whereas 'Intent', '+Action', 'Method', and 'knowledge' are the key dimension influencing 'threats'. Experimental analyses conducted by NARX within several numbers of partitions of the data point to a good detection capacity, with the greatest value of R2 coming in at 0.97. This indicates that NARX was able to detect the crucial dimension that was formulated for by the research to be the detections parameter of an inadvertent insider threat when operating under the best partition. In light of these findings, organisations can use the proposed approach to assess their preparedness for Insider attacks. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Tran, N.
AU  - Sabir, B.
AU  - Ali Babar, M.A.
AU  - Cui, N.
AU  - Abolhasan, M.
AU  - Lipman, J.
TI  - ProML: A Decentralised Platform for Provenance Management of Machine Learning Software Systems
PY  - 2022
T2  - Lecture Notes in Computer Science
VL  - 13444 LNCS
SP  - 49
EP  - 65
DO  - 10.1007/978-3-031-16697-6_4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139044950&doi=10.1007%2F978-3-031-16697-6_4&partnerID=40&md5=c9f3eaec392573fbad245a6e333f3458
AB  - Large-scale Machine Learning (ML) based Software Systems are increasingly developed by distributed teams situated in different trust domains. Insider threats can launch attacks from any domain to compromise ML assets (models and datasets). Therefore, practitioners require information about how and by whom ML assets were developed to assess their quality attributes such as security, safety, and fairness. Unfortunately, it is challenging for ML teams to access and reconstruct such historical information of ML assets (ML provenance) because it is generally fragmented across distributed ML teams and threatened by the same adversaries that attack ML assets. This paper proposes ProML, a decentralised platform that leverages blockchain and smart contracts to empower distributed ML teams to jointly manage a single source of truth about circulated ML assets’ provenance without relying on a third party, which is vulnerable to insider threats and presents a single point of failure. We propose a novel architectural approach called Artefact-as-a-State-Machine to leverage blockchain transactions and smart contracts for managing ML provenance information and introduce a user-driven provenance capturing mechanism to integrate existing scripts and tools to ProML without compromising participants’ control over their assets and toolchains. We evaluate the performance and overheads of ProML by benchmarking a proof-of-concept system on a global blockchain. Furthermore, we assessed ProML’s security against a threat model of a distributed ML workflow. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Arnold, D.
AU  - Ford, J.
AU  - Saniie, J.
TI  - Machine Learning Models for Cyberattack Detection in Industrial Control Systems
PY  - 2022
T2  - IEEE International Conference on Electro Information Technology
VL  - 2022-May
SP  - 166
EP  - 170
DO  - 10.1109/eIT53891.2022.9813829
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134302269&doi=10.1109%2FeIT53891.2022.9813829&partnerID=40&md5=5a4ccd757cf88c5ab8b55821f668a16f
AB  - Industrial Control Systems (ICS) provide a network environment for operator command and control of cyber-physical systems and devices. As such, these systems are common throughout power plants, pipelines, manufactories, and other critical infrastructure. Due to the importance of critical infrastructure in everyday life, hackers of all stripes are taking an increased interest in compromising ICS for personal gain or nefarious purposes. Recent high-profile attacks also highlight the need to monitor system process and sensor data in detecting compromised user accounts or insider threats. Central to ICS data collection and monitoring, Data Historians hold the key to identifying malicious behavior and cyber breaches. Machine Learning techniques may be applied to detect data that is indicative of part failures or cyberattacks, allowing operators to take preventative measures prior to system failure. In this paper, several machine models for cyberattack detection within Industrial Control Systems will be introduced. These models will reside within the Data Historian and are implemented through the Apache Spark MLlib Libraries. The machine learning model were applied to an ICS Dataset to determine the system's accuracy at detecting cyberattacks. Naïve Bayes, Logistic Regression, Decision Tree Classifier, and Random Forest Classifier Machine Learning models were tested with the Tree Classifiers producing the most promising results. © 2022 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 5
ER  -

TY  - CONF
AU  - Zheng, C.
AU  - Hu, W.
AU  - Li, T.
AU  - Liu, X.
AU  - Zhang, J.
AU  - Wang, L.
TI  - An Insider Threat Detection Method Based on Heterogeneous Graph Embedding
PY  - 2022
SP  - 11
EP  - 16
DO  - 10.1109/BigDataSecurityHPSCIDS54978.2022.00013
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134186444&doi=10.1109%2FBigDataSecurityHPSCIDS54978.2022.00013&partnerID=40&md5=14a61a9450df7c40df4112effdebb5f6
AB  - Insider threats have high risk and concealment characteristics, which makes traditional anomaly detection methods less effective in insider threat detection. Existing detection methods ignore the logical relationship between user behaviors and the consistency of behavior sequences among homogeneous users, resulting in poor model effects. We propose an insider threat detection method based on internal user heterogeneous graph embedding. Firstly, according to the characteristics of CERT data, comprehensively consider the relationship between users, the time sequence, and logical relationship, and construct a heterogeneous graph. In the second step, according to the characteristics of heterogeneous graphs, the embedding learning of graph nodes is carried out according to random walk and Word2vec. Finally, we propose an Insider Threat Detection Design (ITDD) model which can map and the user behavior sequence information into a high-dimensional feature space. In the CERT r5.2 dataset, compared with a variety of traditional machine learning methods, the effect of our method is significantly better than the final result. © 2022 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Alshehri, A.
TI  - Relational Deep Learning Detection with Multi-Sequence Representation for Insider Threats
PY  - 2022
T2  - International Journal of Advanced Computer Science and Applications
VL  - 13
IS  - 5
SP  - 758
EP  - 765
DO  - 10.14569/IJACSA.2022.0130587
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131413492&doi=10.14569%2FIJACSA.2022.0130587&partnerID=40&md5=8f6193391d7fc3711de9099ae634f3f4
AB  - Insider threats are typically more challenging to be detected since security protocols struggle to recognize the anomaly behavior of privileged users in the network. Intuitively, an insider threat detection model depends on analyzing the audit data, representing trusted users’ activity streams, on recognizing malicious behaviors. However, the audit data is high dimensional data in that it presents n dependent streams of activities where it establishes a complex feature extraction. In this context, the dependent streams represent user activities where each activity is represented by an ordered set of real variables that pertain to a specific occurrence, such as log-in records. As a result, multiple actions can be represented simultaneously, with one or more values being recorded at each timestamp. Moreover, the relations between dependent streams are typically neglected while detecting the anomaly behavior. Ideally, relation learning is commonly considered to recognize occurrence patterns in streaming data. Thus, the latent relations are thought to have insight for the accurate detection of anomaly behavior concerning insider threats. This study introduces a novel model to detect insider threats by representing audit data as multivariate time series to explicitly learn the existing inter-relations between activity streams using a Recurrent Neural Network (RNN). The model considers learning the latent relationships to effectively extract features for modeling the behavior profile where anomaly behavior can be detected accurately. The evaluation, using the CERT dataset has shown that the proposed model outperforms the comparator approaches to insider threats detection with AUC of 0:99. © 2022. International Journal of Advanced Computer Science and Applications. All Rights Reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Lee, J.
AU  - Alghamdi, A.
AU  - Zaidi, A.K.
TI  - Creating a Digital Twin of an Insider Threat Detection Enterprise Using Model-Based Systems Engineering
PY  - 2022
DO  - 10.1109/SysCon53536.2022.9773890
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130829478&doi=10.1109%2FSysCon53536.2022.9773890&partnerID=40&md5=12c2f0dd3548ed0d6e7fe53d98020732
AB  - Inference Enterprise Modeling (IEM) is a methodology developed to address test and evaluation limitations that insider threat detection enterprises face due to a lack of ground truth and/or missing data. IEM uses a collection of statistical, data processing, analysis, and machine learning techniques to estimate and forecast the performance of these enterprises. As part of developing the IEM method, models satisfying various detection system evaluation requirements were created. In this work, we extend IEM as a digital twin generation technique by representing modeled processes as executable UML Activity Diagrams and tracing solution processes to problem requirements using ontologies. Using the proposed framework, we can rapidly prototype a digital twin of a detection system that can also be imported and executed in systems engineering simulation software tools such as Cameo Enterprise Architecture Simulation Toolkit. Cyber security and threat detection is a continuous process that requires regular maintenance and testing throughout its lifecycle, but there often exists access issues for sensitive and private data and proprietary detection model details to perform adequate test and evaluation activities in the live production environment. To solve this issue, organizations can use a digital twin technique to create a real-time virtual counterpart of the physical system. We describe a method for creating digital twins of live and/or hypothetical insider threat detection enterprises for the purpose of performing test and evaluation activities on continuous monitoring systems that are sensitive to disruptions. In this work, we use UML Activity Diagrams to leverage the integrated simulation capabilities of Model-Based Systems Engineering (MBSE). © 2022 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 10
ER  -

TY  - CONF
TI  - 16th Annual IEEE International Systems Conference, SysCon 2022
PY  - 2022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130818401&partnerID=40&md5=91a544e254b8ac12aa1ced09ffeeb56e
AB  - The proceedings contain 104 papers. The topics discussed include: an autonomous bird monitoring and food intake recording feeder system towards effective rehabilitation; a deep CNN system for classification of emotions using EEG signals; identifying ai opportunities in donor kidney acceptance: incremental hierarchical systems engineering approach; context-aware recommendation systems using consensus-clustering; a system based on deep-learning for dynamic routing problems; evaluation of the data distribution service for a lossy autonomous hybrid system; cyber analytics for intrusion detection on the navy smart grid using supervised learning; model-based systems engineering papers analysis based on word cloud visualization; creating a digital twin of an insider threat detection enterprise using model-based systems engineering; and leveraging ambient sensing for the estimation of curiosity-driven human crowd.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Lavanya, P.
AU  - Shankar Sriram, V.S.
TI  - Detection of Insider Threats Using Deep Learning: A Review
PY  - 2022
T2  - Smart Innovation, Systems and Technologies
VL  - 281
SP  - 41
EP  - 57
DO  - 10.1007/978-981-16-9447-9_4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130347921&doi=10.1007%2F978-981-16-9447-9_4&partnerID=40&md5=afc57867aeed4f9afe403b9d48a3228b
AB  - Massive number of cyberattacks exist on the Internet, among which insider threat is one of the most challenging malicious threats in cyberspace. The identification of insiders (attackers) is a very hard-hitting job within an organization and discriminating benign employees and insiders is crucial. Hence, the automation of insider threat detection using machine learning and deep learning techniques improves the detection performance and helps in analyzing the characteristics of an insider. Several learning models have been developed, of which deep learning techniques are promising as it offers high-quality results and it does not require feature engineering. Assorted deep learning techniques have been employed to discriminate insiders from benign employees, and this review article articulates the deep learning techniques presented so far in the literature for effective insider threat detection. The performance of the deep learning techniques and their discrimination ability, commonalities, and differences among the cybersecurity researchers based on the metrics are summarized in a motive to provide a clear insight to the budding cybersecurity researchers. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 7
ER  -

TY  - JOUR
AU  - Das, A.
AU  - Pramod, n.
TI  - Design and Development of an Efficient Network Intrusion Detection System using Ensemble Machine Learning Techniques for Wifi Environments
PY  - 2022
T2  - International Journal of Advanced Computer Science and Applications
VL  - 13
IS  - 4
SP  - 856
EP  - 866
DO  - 10.14569/IJACSA.2022.0130499
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130091498&doi=10.14569%2FIJACSA.2022.0130499&partnerID=40&md5=0dec408252c0393c7b5bfc73de6f27e6
AB  - Intrusion Detection Systems(IDS) are vital for computer networks as they protect against attacks that lead to privacy breaches and data leaks. Over the years, researchers have formulated IDS using machine learning (ML) and/or deep learning(DL) to detect network anomalies and identify attacks. Network Intrusion Detection Systems (NIDS) within corporate networks is a form of security that detects and generates an alarm for any cyberattacks. In both academia and industry, the concept of deploying a NIDS has been studied and adopted. The majority of NIDS research, on the other hand, has focused on detecting threats that emerge from outside of a wired connection. In addition, the NIDSs recognize Wi-Fi and wired networks alike. The Wi-Fi network's accessible connectivity distinguishes this from the wired network. A wired connection is highly resistant to many insider threats that could occur on a Wi-Fi router. A conventional view to developing NIDSs may miss malicious activities. This paper aims to design a multi-level NIDS for WiFi predominant networks to identify both organizational WiFi networks malicious activity and standard network malicious activity. Wi-Fi devices are common on campuses and businesses, and they are incorporated into the fixed wired network at the gateway. Wi-Fi networks are the primary target for this implementation; however, they are also designed to function in wired environments. For the Multi-Level NIDS, the proposed model used an ensemble learning method that pools the strengths of multiple weak learners into a single strong learner. © 2022. All Rights Reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 6
ER  -

TY  - CONF
AU  - Padmavathi, G.
AU  - D, D.
AU  - S, S.
TI  - A Framework to Detect the Malicious Insider Threat in Cloud Environment using Supervised Learning Methods
PY  - 2022
SP  - 354
EP  - 358
DO  - 10.23919/INDIACom54597.2022.9763205
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130032025&doi=10.23919%2FINDIACom54597.2022.9763205&partnerID=40&md5=1d22b595bbaa09265d03b66668ad3373
AB  - A malicious insider threat is more vulnerable to an organization. It is necessary to detect the malicious insider because of its huge impact to an organization. The occurrence of a malicious insider threat is less but quite destructive. So, the major focus of this paper is to detect the malicious insider threat in an organization. The traditional insider threat detection algorithm is not suitable for real time insider threat detection. A supervised learning-based anomaly detection technique is used to classify, predict and detect the malicious and non-malicious activity based on highest level of anomaly score. In this paper, a framework is proposed to detect the malicious insider threat using supervised learning-based anomaly detection. It is used to detect the malicious insider threat activity using One-Class Support Vector Machine (OCSVM). The experimental results shows that the proposed framework using OCSVM performs well and detects the malicious insider who obtain huge anomaly score than a normal user. © 2022 Bharati Vidyapeeth, New Delhi.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 10
ER  -

TY  - CONF
AU  - Vinay, M.S.
AU  - Yuan, S.
AU  - Wu, X.
TI  - Contrastive Learning for Insider Threat Detection
PY  - 2022
T2  - Lecture Notes in Computer Science
VL  - 13245 LNCS
SP  - 395
EP  - 403
DO  - 10.1007/978-3-031-00123-9_32
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129871763&doi=10.1007%2F978-3-031-00123-9_32&partnerID=40&md5=de073cea3ce0b03211473c8cac209fe3
AB  - Insider threat detection techniques typically employ supervised learning models for detecting malicious insiders by using insider activity audit data. In many situations, the number of detected malicious insiders is extremely limited. To address this issue, we present a contrastive learning-based insider threat detection framework, CLDet, and empirically evaluate its efficacy in detecting malicious sessions that contain malicious activities from insiders. We evaluate our framework along with state-of-the-art baselines on two unbalanced benchmark datasets. Our framework exhibits relatively superior performance on these unbalanced datasets in effectively detecting malicious sessions. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 6
ER  -

TY  - CONF
AU  - Mamidanna, S.K.
AU  - Reddy, C.R.K.
AU  - Gujju, A.
TI  - Detecting an Insider Threat and Analysis of XGBoost using Hyperparameter tuning
PY  - 2022
DO  - 10.1109/ACCAI53970.2022.9752509
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128807371&doi=10.1109%2FACCAI53970.2022.9752509&partnerID=40&md5=3c541d7e4fb9806c342625012e265261
AB  - Nowadays, organizations of all forms and sizes are facing many challenges with regards to protecting their data, systems and devices, and one of the alarming concernsis the Insider threat. Insiders try to misuse their privileges to compromise the privacy, integrity and accessibility of the data or the device. An Insider attack leads to immense loss to the company in terms of integrity, trust and revenue. There are many Machine Learning approaches to detect malicious insiders that provide solutions to these attacks. At the same time, they demonstrated short-comings with regards to performance and Accuracy. Therefore, in this paper, a novel machine learning model is proposed using XGBoost algorithm to address these problems. XGBoost is a decision-Tree based ensemble machine learning algorithm that uses a gradient boosting framework that improves speed and performance. Hyper-parameter optimization using Grid Search was applied to enhance the performance of the model using the CERT 4.2 dataset to detect the insider. The model has generated the desired results with a high accuracy rate of 98.6%. A webform was also created using Flask Micro Web Framework that takes user attributes as an input and detects insider activity using the XGBoost model. © 2022 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 11
ER  -

TY  - JOUR
AU  - Haq, M.A.
AU  - Khan, M.A.R.
AU  - Alshehri, M.
TI  - Insider Threat Detection Based on NLP Word Embedding and Machine Learning
PY  - 2022
T2  - Intelligent Automation and Soft Computing
VL  - 33
IS  - 1
SP  - 619
EP  - 635
DO  - 10.32604/iasc.2022.021430
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122303547&doi=10.32604%2Fiasc.2022.021430&partnerID=40&md5=2de9ccd3e52190f91ff9925c9feaf3c3
AB  - The growth of edge computing, the Internet of Things (IoT), and cloud computing have been accompanied by new security issues evolving in the information security infrastructure. Recent studies suggest that the cost of insider attacks is higher than the external threats, making it an essential aspect of information security for organizations. Efficient insider threat detection requires state-of-the-art Artificial Intelligence models and utility. Although significant have been made to detect insider threats for more than a decade, there are many limitations, including a lack of real data, low accuracy, and a relatively low false alarm, which are major concerns needing further investigation. In this paper, an attempt to fulfill these gaps by detecting insider threats with the novelties of the present investigation first developed two deep learning hybrid LSTM models integrated with Goo-gle's Word2vec LSTM (Long Short-Term Memory) GLoVe (Global Vectors for Word Representation) LSTM. Secondly, the performance of two hybrid DL models was compared with the state-of-the-art ML models such as XGBoost, Ada-Boost, RF (Random Forest), KNN (K-Nearest Neighbor) and LR (Logistics Regression). Thirdly, the present investigation bridges the gaps of using a real dataset, high accuracy, and significantly lower false alarm rate. It was found that ML-based models outperformed the DL-based ones. The results were evaluated based on earlier studies and deemed efficient at detecting insider threats using the real dataset. © 2022, Tech Science Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 42
ER  -

TY  - JOUR
AU  - Al-Mhiqani, M.N.
AU  - Ahmad, R.
AU  - Zainal Abidin, Z.Z.
AU  - Abdulkareem, K.H.
AU  - Mohammed, M.A.
AU  - Gupta, D.
AU  - K, K.
TI  - A new intelligent multilayer framework for insider threat detection
PY  - 2022
T2  - Computers and Electrical Engineering
VL  - 97
C7  - 107597
DO  - 10.1016/j.compeleceng.2021.107597
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119610462&doi=10.1016%2Fj.compeleceng.2021.107597&partnerID=40&md5=59a1ceb34d39a6fe8caef61028f613f3
AB  - In several earlier studies, machine learning (ML) has been widely used for building insider threat detection systems. However, the selection of the most appropriate ML classification model for insider threats detection remains a challenge. Despite the prominence of ML in the domain of insider threat detection, none of the previous works have utilized ML techniques for building a hybrid solution that can take advantage of the misuse and anomaly insider threat detection. In this study, a new multilayer framework has been proposed for insider threat detection. The first layer of the framework is used for selecting the best insider threat detection classification model among many based on the multi-criteria decision making techniques. The selection procedure has been developed based on the integration of the entropy-VIKOR methods. For the second layer, a hybrid insider threat detection method has been proposed, where the Misuse Insider Threat Detection (MITD) model has been created using the random forest algorithm. Subsequently, using the K-Nearest Neighbors algorithm, an anomaly insider threat detection algorithm has been developed. The proposed multilayer framework for insider threat detection has been evaluated by using the CERT r4.2 dataset. Results of the experiment demonstrate that the validity of the results produced by the selection framework is proven by the validation procedure obtained from previous research. The proposed hybrid detection method is observed to exhibit an overall accuracy of 99% and a false positive rate of 0.29% for known insider threats, whereas it exhibits 97% accuracy and 2.88% false-positive rate for unknown insider threats. © 2021
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 72
ER  -

TY  - JOUR
AU  - Khalfaoui, S.
AU  - Leneutre, J.
AU  - Villard, A.
AU  - Gazeau, I.
AU  - Ma, J.
AU  - Urien, P.
TI  - Security analysis of machine learning-based puf enrollment protocols: A review
PY  - 2021
T2  - Sensors
VL  - 21
IS  - 24
C7  - 8415
DO  - 10.3390/s21248415
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121148979&doi=10.3390%2Fs21248415&partnerID=40&md5=97e01c341e86641ffbd8dab11a6a757d
AB  - The demand for Internet of Things services is increasing exponentially, and consequently a large number of devices are being deployed. To efficiently authenticate these objects, the use of physical unclonable functions (PUFs) has been introduced as a promising solution for the resource-constrained nature of these devices. The use of machine learning PUF models has been recently proposed to authenticate the IoT objects while reducing the storage space requirement for each device. Nonetheless, the use of a mathematically clonable PUFs requires careful design of the enrollment process. Furthermore, the secrecy of the machine learning models used for PUFs and the scenario of leakage of sensitive information to an adversary due to an insider threat within the organization have not been discussed. In this paper, we review the state-of-the-art model-based PUF enrollment protocols. We identity two architectures of enrollment protocols based on the participating entities and the building blocks that are relevant to the security of the authentication procedure. In addition, we discuss their respective weaknesses with respect to insider and outsider threats. Our work serves as a comprehensive overview of the ML PUF-based methods and provides design guidelines for future enrollment protocol designers. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.
M3  - Review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - Al Hammadi, A.Y.
AU  - Yeun, C.Y.
AU  - Damiani, E.
AU  - Yoo, P.D.
AU  - Hu, J.
AU  - Yeun, H.K.
AU  - Yim, M.-S.
TI  - Explainable artificial intelligence to evaluate industrial internal security using EEG signals in IoT framework
PY  - 2021
T2  - Ad Hoc Networks
VL  - 123
C7  - 102641
DO  - 10.1016/j.adhoc.2021.102641
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112393109&doi=10.1016%2Fj.adhoc.2021.102641&partnerID=40&md5=697f47315817841217f59fbcf69abd5e
AB  - Industrial insider threat detection has consistently been a popular field of research. To help detect potential insider threats, the emotional states of humans are identified through a wide range of physiological signals including the galvanic skin response, electrocardiogram, and electroencephalogram (EEG). This paper presents an insider risk assessment system as a fitness for duty security evaluation using EEG brainwave signals with explainable deep learning and machine learning algorithms to classify abnormal EEG signals indicating a potential insider threat and evaluating fitness for duty. The system is designed to be cost-effective by using an Emotiv Insight EEG device with five electrodes. In this study, the data from 17 people in different emotional states were collected. The different levels of emotions were mapped and classified into four risk levels, namely low, normal, medium, and high. The data were collected while the subjects were presented with different images from the scientific international affective picture system. The collected EEG signals were preprocessed to eliminate noise from physical movements and blinking. The data were then used to train self-feature learning of two- and one-dimensional convolutional neural networks, Adaptive Boosting, random forest, and K-nearest neighbors models; the proposed method yielded classification accuracies of 96, 75, 97, 94 and 81%, respectively. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 44
ER  -

TY  - JOUR
AU  - Janjua, F.
AU  - Masood, A.
AU  - Abbas, H.
AU  - Rashid, I.
AU  - Khan, M.M.Z.M.
TI  - Textual analysis of traitor-based dataset through semi supervised machine learning
PY  - 2021
T2  - Future Generation Computer Systems
VL  - 125
SP  - 652
EP  - 660
DO  - 10.1016/j.future.2021.06.036
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111874321&doi=10.1016%2Fj.future.2021.06.036&partnerID=40&md5=0f38c6aa17e930183918a7327fc568fb
AB  - Insider threats are one of the most challenging and growing security threats which the government agencies, organizations, and institutions face. In such scenarios, malicious (red) activities are performed by the authorized individuals within the company. Because of which, an insider threat has become a taxing and difficult task to identify among other attacks. Along with other monitoring parameters; email logs play a vital role in many research areas such as stalking Insider Threat involving Collaborating Traitors, Textual Analysis, and Social Media exploration. This paper presents a semi-supervised machine learning framework which embraces the pre-processing and classification techniques together for unlabeled dataset i.e. emails. Enron Corporation dataset has been used for experiments and TWOS for evaluation of the proposed framework. Initially, dataset is transformed into vector form using Term Frequency–Inverse Document Frequency (TF–IDF). Thereafter, K-Means is used to classify emails based on message content. Finally, Machine Learning algorithm Decision Tree (DT) is applied to classify the malicious activities. The proposed framework has also been tested with other algorithms such as Logistic Regression (LR), Naive Bayes (NB), KNN, Support Vector Machine (SVM), Random Forest (RF) and Neural Network (NN). However, Decision Tree (DT) combined with pre-processing steps has given the desired results with 99.96% Accuracy and 0.994 AUC for identification of malicious content. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 20
ER  -

TY  - JOUR
AU  - Wei, Y.
AU  - Chow, K.-P.
AU  - Yiu, S.-M.
TI  - Insider threat prediction based on unsupervised anomaly detection scheme for proactive forensic investigation
PY  - 2021
T2  - Forensic Science International: Digital Investigation
VL  - 38
C7  - 301126
DO  - 10.1016/j.fsidi.2021.301126
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119601253&doi=10.1016%2Fj.fsidi.2021.301126&partnerID=40&md5=6bb60f70f029009605f2686b4e2773df
AB  - The complexity, concealment and infrequency of malicious internal actions make it difficult to detect insider threats. In the process of traditional reactive forensic investigation, analysis and interpretation of the digital evidence are performed after a crime has been committed. Even if insiders can be detected, they have already caused huge damage. In this paper, we propose a novel general unsupervised anomaly detection scheme based on cascaded autoencoders (CAEs) and joint optimization network. Our core idea is to utilize CAEs to do data purification among unlabeled digital evidence, then jointly optimize the dimension reduction and density estimation network to avoid sub-optimal problems. Based on this scheme, we design an end-to-end insider threat prediction framework for proactive forensic investigation, through which we can make real time response to prevent the harmful influences of insider threats in advance. We extract the tractable and scalable feature representation automatically through the data driven Bidirectional Long Short-Term Memory (BiLSTM) feature extractor, waiving the time-consuming and customarily expert dependable feature engineering work. Additionally, a hypergraph correction module is applied to solve the commonly existed relatively high false positive rate problem in insider threat detection. We evaluate our scheme and framework on public benchmark datasets. The empirical experiments demonstrate that our models outperform state-of-the-art unsupervised methods. © 2021 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 23
ER  -

TY  - CONF
AU  - Velmurugadass, P.
AU  - Dhanasekaran, S.
TI  - Enhancing Security Service of Data Protection Level using Machine Learning
PY  - 2021
DO  - 10.1109/GCAT52182.2021.9587730
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119494773&doi=10.1109%2FGCAT52182.2021.9587730&partnerID=40&md5=3acca55d5d3c69df4f29d7157f155df5
AB  - Insider threats become more dangerous and introduce high risk in the organization. In general, insider attackers seek to theft or alter the organization data with intentions. As insider threats are more difficult to detect, still major issues are there. In this research, the machine learning (ML) approach is proposed to analyze and detect insider threats. This project focuses on detecting insiders by learning the behaviour of insider threats continuously. At first, the insider dataset is collected and pre-processed. The preprocessing step breaks the data into a granular level (i.e.) weekly, daily and hourly behaviour data. Then, this data is processed with feature extraction in which the required features including HTTP features, E-mail features, file features, and USB features are extracted from each data instance. These are the main feature categories and each category consists of several features that are useful in insider detection. Then, the features are fed into the Random Forest (RF) classifier, one of the best ML algorithms. Finally, the RF classifies data into insiders and normally based on the features. The experimental analysis shows that the proposed ML-based insider threat detection model in granular level works is more accurate. © 2021 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Al-Shehari, T.
AU  - Alsowail, R.A.
TI  - An insider data leakage detection using one‐hot encoding, synthetic minority oversampling and machine learning techniques
PY  - 2021
T2  - Entropy
VL  - 23
IS  - 10
C7  - 1258
DO  - 10.3390/e23101258
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116039986&doi=10.3390%2Fe23101258&partnerID=40&md5=7a92c5a9fe01922116b313b36174a004
AB  - Insider threats are malicious acts that can be carried out by an authorized employee within an organization. Insider threats represent a major cybersecurity challenge for private and public organizations, as an insider attack can cause extensive damage to organization assets much more than external attacks. Most existing approaches in the field of insider threat focused on detecting general insider attack scenarios. However, insider attacks can be carried out in different ways, and the most dangerous one is a data leakage attack that can be executed by a malicious insider before his/her leaving an organization. This paper proposes a machine learning‐based model for detecting such serious insider threat incidents. The proposed model addresses the possible bias of detection results that can occur due to an inappropriate encoding process by employing the feature scaling and one‐hot encoding techniques. Furthermore, the imbalance issue of the utilized dataset is also addressed utilizing the synthetic minority oversampling technique (SMOTE). Well known machine learning algorithms are employed to detect the most accurate classifier that can detect data leakage events executed by malicious insiders during the sensitive period before they leave an organization. We provide a proof of concept for our model by applying it on CMU‐CERT Insider Threat Dataset and comparing its performance with the ground truth. The experimental results show that our model detects insider data leakage events with an AUC‐ROC value of 0.99, outperforming the existing approaches that are validated on the same dataset. The proposed model provides effective methods to address possible bias and class imbalance issues for the aim of devising an effective insider data leakage detection system. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 135
ER  -

TY  - CONF
AU  - Pantelidis, E.
AU  - Bendiab, G.
AU  - Shiaeles, S.
AU  - Kolokotronis, N.
TI  - Insider threat detection using deep autoencoder and variational autoencoder neural networks
PY  - 2021
SP  - 129
EP  - 134
DO  - 10.1109/CSR51186.2021.9527925
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115733259&doi=10.1109%2FCSR51186.2021.9527925&partnerID=40&md5=dbbd4843490336400659446eefe758de
AB  - Internal attacks are one of the biggest cybersecurity issues to companies and businesses. Despite the implemented perimeter security systems, the risk of adversely affecting the security and privacy of the organization's information remains very high. Actually, the detection of such a threat is known to be a very complicated problem, presenting many challenges to the research community. In this paper, we investigate the effectiveness and usefulness of using Autoencoder and Variational Autoencoder deep learning algorithms to automatically defend against insider threats, without human intervention. The performance evaluation of the proposed models is done on the public CERT dataset (CERT r4.2) that contains both benign and malicious activities generated from 1000 simulated users. The comparison results with other models show that the Variational Autoencoder neural network provides the best overall performance with a higher detection accuracy and a reasonable false positive rate. © 2021 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 28
ER  -

TY  - JOUR
TI  - 2021 International Conference on Cyber Situational Awareness, Data Analytics and Assessment, CyberSA 2021
PY  - 2021
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114250280&partnerID=40&md5=20c38c631409003f8644ed61e02c610f
AB  - The proceedings contain 34 papers. The topics discussed include: navigation anomaly detection: an added value for maritime cyber situational awareness; file slack handling tool; feature vulnerability and robustness assessment against adversarial machine learning attacks; intelligent intrusion detection system for smart grid applications; secure (S)hell: introducing an SSH deception proxy framework; energy efficiency in low power and lossy networks; the cybersecurity (CSEC) questionnaire: individual differences in unintentional insider threat behaviors; evaluating threat modeling tools: Microsoft TMT versus OWASP threat dragon; and revolution and stability in the study of the human factor in the security of information systems field. a systematic literature review over 30 years of publication.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Wall, A.
AU  - Agrafiotis, I.
TI  - A bayesian approach to insider threat detection
PY  - 2021
T2  - Journal of Wireless Mobile Networks, Ubiquitous Computing, and Dependable Applications
VL  - 12
IS  - 2
SP  - 48
EP  - 84
DO  - 10.22667/JOWUA.2021.06.30.048
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117952855&doi=10.22667%2FJOWUA.2021.06.30.048&partnerID=40&md5=967c9d54f6e4d9e7f46b3f103d9a394a
AB  - Insider attacks are an ever-increasing threat for organizations, with dire consequences. Rogue employees who possess legitimate access to systems, and knowledge of security policies and monitoring practices of organizations, can evade detection. Organizations remain ill-equipped in detecting, deterring and mitigating sophisticated insider attacks, as traditional security controls and detection systems are tailored to external threats. Literature on insider threat detection provides the theoretical foundation to understand the motives, behavior and patterns of insider attacks. The majority of proposed models for insider threat anomaly detection, mainly focus on processing network data. In this paper, we propose and evaluate a Bayesian Network architecture that can consider behavioral aspects in tandem with network data. Our system utilizes machine learning to understand the structure of the data, inputs specially crafted features based on theoretical foundations of insider threat and enables analysts to consider behavioral features, if such data is available. We applied our system on CMU’s synthetic dataset and our results provide justified and informed decisions on selecting parameters for Bayesian Networks and suggest that such an approach is highly effective. All attacks in the dataset were identified, with a very low number of false positives. © 2021, Innovative Information Science and Technology Research Group. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 9
ER  -

TY  - JOUR
AU  - Le, D.C.
TI  - Anomaly Detection for Insider Threats Using Unsupervised Ensembles
PY  - 2021
T2  - IEEE Transactions on Network and Service Management
VL  - 18
IS  - 2
C7  - 9399116
SP  - 1152
EP  - 1164
DO  - 10.1109/TNSM.2021.3071928
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104195907&doi=10.1109%2FTNSM.2021.3071928&partnerID=40&md5=1bd72dacd76c4b49e949d65bcbfd389e
AB  - Insider threat represents a major cybersecurity challenge to companies, organizations, and government agencies. Insider threat detection involves many challenges, including unbalanced data, limited ground truth, and possible user behavior changes. This research presents an unsupervised learning based anomaly detection approach for insider threat detection. We employ four unsupervised learning methods with different working principles, and explore various representations of data with temporal information. Furthermore, different computational intelligence schemes are explored to combine these models to create anomaly detection ensembles for improving the detection performance. Evaluation results show that the approach allows learning from unlabelled data under challenging conditions for insider threat detection. Insider threats are detected with high detection and low false positive rates. For example, 60% of malicious insiders are detected under 0.1% investigation budget, and all malicious insiders are detected at less than 5% investigation budget. Furthermore, we explore the ability of the proposed approach to generalize for detecting new anomalous behaviors in different datasets, i.e., robustness. Finally, results demonstrate that a voting-based ensemble of anomaly detection can be used to improve detection performance as well as the robustness. Comparisons with the state-of-the-art confirm the effectiveness of the proposed approach. © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 96
ER  -

TY  - JOUR
AU  - Yuan, S.
AU  - Wu, X.
TI  - Deep learning for insider threat detection: Review, challenges and opportunities
PY  - 2021
T2  - Computers and Security
VL  - 104
C7  - 102221
DO  - 10.1016/j.cose.2021.102221
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101500375&doi=10.1016%2Fj.cose.2021.102221&partnerID=40&md5=5c42e72aeb4d694a0b7bb8c0506ca9b5
AB  - Insider threats, as one type of the most challenging threats in cyberspace, usually cause significant loss to organizations. While the problem of insider threat detection has been studied for a long time in both security and data mining communities, the traditional machine learning based detection approaches, which heavily rely on feature engineering, are hard to accurately capture the behavior difference between insiders and normal users due to various challenges related to the characteristics of underlying data, such as high-dimensionality, complexity, heterogeneity, sparsity, lack of labeled insider threats, and the subtle and adaptive nature of insider threats. Advanced deep learning techniques provide a new paradigm to learn end-to-end models from complex data. In this brief survey, we first introduce commonly-used datasets for insider threat detection and review the recent literature about deep learning for such research. The existing studies show that compared with traditional machine learning algorithms, deep learning models can improve the performance of insider threat detection. However, applying deep learning to further advance the insider threat detection task still faces several limitations, such as lack of labeled data, adaptive attacks. We discuss such challenges and suggest future research directions that have the potential to address challenges and further boost the performance of deep learning for insider threat detection. © 2021 Elsevier Ltd
M3  - Review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 196
ER  -

TY  - CONF
AU  - Sundaram, A.
AU  - Abdel-Khalik, H.S.
TI  - DEVELOPING COVERT COGNIZANCE (C2) FOR INDUSTRIAL CONTROL SYSTEMS
PY  - 2021
SP  - 859
EP  - 866
DO  - 10.13182/M&C21-33753
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133841989&doi=10.13182%2FM%26C21-33753&partnerID=40&md5=ca16377b1d1b61699770ecd33bcfb045
AB  - Recent developments in industrial control systems (ICS) using a cyber-physical framework have rendered them susceptible to cyberattacks. Traditional measures such as Information Technology (IT) defenses and passive Operational Technology (OT) techniques have become increasingly ineffective in the face of state-sponsored, resourceful, and knowledgeable attackers, and do not provide a solution against insider threats. Specifically, active OT techniques are required to digitally “watermark” these processes and prevent falsification, but these often come at a cost of optimality as they can affect system behavior. A new approach to securing such systems via active defense is introduced in this manuscript by using the idea of covert cognizance, or C2. The C2 paradigm is then successfully implemented in a representative nuclear reactor ICS with a linear controller to detect sensor-falsification attacks in a deterministic manner. The system is augmented by ways of an injector that perturbs the system output such that it contains a signature. The signature is designed to be pattern-less so as to avoid detection by machine-learning techniques and remain covert. Additionally, statistical analyses have been performed to demonstrate the indistinguishability of the augmented process from the original process, thereby highlighting the covert nature of the defense. Lastly, several extensions of the generalized mathematical framework are discussed for more practical scenarios. © © 2021 AMERICAN NUCLEAR SOCIETY, INCORPORATED, LA GRANGE PARK, ILLINOIS 60526.All rights reserved.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Suresh, P.V.
AU  - Madhavu, M.L.
TI  - INSIDER ATTACK: INTERNAL CYBER ATTACK DETECTION USING MACHINE LEARNING
PY  - 2021
DO  - 10.1109/ICCCNT51525.2021.9579549
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126192552&doi=10.1109%2FICCCNT51525.2021.9579549&partnerID=40&md5=d4fa20d7aeca7420e5aa561212416a4a
AB  - A Cyber Attack is a sudden attempt launched by cybercriminals against multiple computers or networks. According to evolution of cyber space, insider attack is the most serious attack faced by end users, all over the world. Cyber Security reports shows that both US federal Agency as well as different organizations faces insider threat. Machine learning (ML) provide an important technology to secure data from insider threats. Random Forest is the best algorithm that focus on user's action, services and ability for insider attack detection based on data granularity. Substantial raise in the count of decision tree, increases the time consumption and complexity of Random Forest. A novel algorithm Known as Random Forest With Randomized Weighted Fuzzy Feature Set (RF-RWFF) is developed. Fuzzy Membership Function is used for feature aggregation and Randomized Weighted Majority Algorithm (RWMA) is used in the prediction part of Random Forest (RF) algorithm to perform voting. RWMA transform conventional Random Forest, to a perceptron like algorithm and increases the miliage. The experimental results obtained illustrate that the proposed model exhibits an overall improvement in accuracy and recall rate with very much decrease in time complexity compared to conventional Random Forest algorithm. This algorithm can be used in organization and government sector to detect insider fastly and accurately. © 2021 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 8
ER  -

TY  - CONF
AU  - Khalfaoui, S.
AU  - Leneutre, J.
AU  - Villard, A.
AU  - Gazeau, I.
AU  - Ma, J.
AU  - Danger, J.-L.
AU  - Urien, P.
TI  - Water- PUF: An Insider Threat Resistant PUF Enrollment Protocol Based on Machine Learning Watermarking
PY  - 2021
DO  - 10.1109/NCA53618.2021.9685239
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125894040&doi=10.1109%2FNCA53618.2021.9685239&partnerID=40&md5=b07eaa32f1cd2e8c737611a351b9cf91
AB  - The demand for Internet of Things services is increasing exponentially, and consequently a big number of devices are being deployed. To efficiently authenticate these services, the use of Physical Unclonable Functions (PUF) has been introduced as a promising solution that is suitable for the resource-constraint nature of these devices. A growing number of PUF architectures has been demonstrated mathematically clonable through Machine Learning (ML) modeling techniques. The use of ML PUF models has been recently proposed to authenticate the IoT objects. This procedure facilitates the scalability of the authentication process by reducing the storage space required for each device. Nonetheless, the leakage scenario of the PUF model to an adversary due to an insider threat within the organization is not supported by the existing solutions. Hence, the security of these PUF model-based enrollment proposals can be compromised. In this paper, we propose an enrollment solution that exploits a ML PUF model in the authentication process, called Water-PUF. Our enrollment scheme is based on a specifically designed black-box watermarking technique for PUF models with a binary output response. This procedure prevents an adversary from relying on the watermarked model in question or another derivative model to bypass the authentication. Therefore, any leakage of the watermarked PUF model that is used for the enrollment does not affect the correctness of the protocol. The Water- PUF design is validated by a number of simulations against numerous watermark suppression attacks to assess the robustness of our proposal. © 2021 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 5
ER  -

TY  - CONF
AU  - Datta, J.
AU  - Dasgupta, R.
AU  - Dasgupta, S.
AU  - Reddy, K.R.
TI  - Real-Time Threat Detection in UEBA using Unsupervised Learning Algorithms
PY  - 2021
DO  - 10.1109/IEMENTech53263.2021.9614848
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123420275&doi=10.1109%2FIEMENTech53263.2021.9614848&partnerID=40&md5=7dfa31cd938fcb904ff36678940d2e10
AB  - In this modern world of digital communications and transactions, cybersecurity and the protection of user data have been of utmost importance. User and Entity behavior analytics is a powerful tool to prevent various threats. Through this paper, we bring to you a proposed machine learning UEBA model which protects user data and prevents insider threats more efficiently. We have tried to compare four different unsupervised algorithms which we believe to be far superior to the normally supervised machine learning algorithms. Our main aim is to provide a more efficient UEBA model through the combination of the above-mentioned algorithms. On comparing with the normally used supervised algorithms, we have observed that our proposed model works much more efficiently and is less time-consuming. © 2021 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 9
ER  -

TY  - CONF
AU  - Huang, W.
AU  - Zhu, H.
AU  - Li, C.
AU  - Lv, Q.
AU  - Wang, Y.
AU  - Yang, H.
TI  - ITDBERT: Temporal-semantic Representation for Insider Threat Detection
PY  - 2021
T2  - Proceedings - International Symposium on Computers and Communications
VL  - 2021-September
DO  - 10.1109/ISCC53001.2021.9631538
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123204426&doi=10.1109%2FISCC53001.2021.9631538&partnerID=40&md5=da071d0eb94df8c849a7f2f093e782e8
AB  - The objective and universal nature of user behavior data make it the primary data for insider threat detection. Existing solutions treat user behavior as atomic symbols and do not consider behavior semantic information. Meanwhile, fine-grained temporal information is ignored despite its relevance to describe user behavior. Such approaches inevitably lead to unsatisfactory performance and generalization. In this paper, we propose ITDBERT which embeds temporal information into behavior and catches the fused semantic representation via pre-trained language models. ITDBERT also leverages attention-based Bi-LSTM to provide behavior-level detection results. To verify the effectiveness of our proposed method, we conduct comparison experiments on Cert datasets. Our proposed model achieves an F1-score of 0.9243 in day-level insider threat detection, which outperforms baselines. © 2021 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 30
ER  -

TY  - JOUR
AU  - Nasir, R.
AU  - Afzal, M.
AU  - Latif, R.
AU  - Iqbal, W.
TI  - Behavioral Based Insider Threat Detection Using Deep Learning
PY  - 2021
T2  - IEEE Access
VL  - 9
SP  - 143266
EP  - 143274
DO  - 10.1109/ACCESS.2021.3118297
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118997499&doi=10.1109%2FACCESS.2021.3118297&partnerID=40&md5=5fc496b7cf652bfb9dc3aee8b68298b6
AB  - The most detrimental cyber attacks are usually not originated by malicious outsiders or malware but from trusted insiders. The main advantage insider attackers have over external elements is their ability to bypass security checks and remain undiscovered, this may cause serious damage to the organizational assets. This paper focuses on insider threat detection through behavioral analysis of users. User behavior is categorized as normal or malicious based on user activity. A series of events and activities are analyzed for feature selection to efficiently detect adversarial behavior. Selected feature vectors are used for model training during the implementation phase. A deep learning based approach is proposed that detects insiders with greater accuracy and low false positive rate. A rich event/user role based feature set containing Logon/Logoff events, User_role, Functional_unit etc are used for detection. The dataset used is the CMU CERT synthetic insider threat dataset r4.2. Performance of our proposed algorithm has been compared to other well-known techniques i.e. long short term Memory-convolutional neural network, random forest, long short term memory-recurrent neural network, one class support vector machine, Markov chain model, multi state long short term memory convolutional neural network, gated recurrent unit skipgram. The comparison proved that our novel approach produces relatively good accuracy(90.60%), precision(97%) and F1 Score (94%). © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 83
ER  -

TY  - CONF
AU  - Bartoszewski, F.W.
AU  - Just, M.
AU  - Lones, M.A.
AU  - Mandrychenko, O.
TI  - Anomaly Detection for Insider Threats: An Objective Comparison of Machine Learning Models and Ensembles
PY  - 2021
T2  - IFIP Advances in Information and Communication Technology
VL  - 625
SP  - 367
EP  - 381
DO  - 10.1007/978-3-030-78120-0_24
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111403610&doi=10.1007%2F978-3-030-78120-0_24&partnerID=40&md5=f15792851ac6252bb903d9ab293eec2b
AB  - Insider threat detection is challenging due to the wide variety of possible attacks and the limited availability of real threat data for testing. Most previous anomaly detection studies have relied on synthetic threat data, such as the CERT insider threat dataset. However, several previous studies have used models that arguably introduce bias, such as the selective use of metrics, and reusing the same dataset with the prior knowledge of the answer labels. In this paper, we create and test a host of models following some guidelines of good conduct to produce what we believe to be a more objective comparison of these models. Our results indicate that majority voting ensembles are a simple and cost-effective way of boosting the quality of results from individual machine learning models, both on the CERT data and on a version augmented with additional attacks. We include a comparison of models with their hyperparameters optimized for different target metrics. © 2021, IFIP International Federation for Information Processing.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - JOUR
TI  - 36th IFIP International Conference on ICT Systems Security and Privacy Protection, SEC 2021
PY  - 2021
T2  - IFIP Advances in Information and Communication Technology
VL  - 625
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111378870&partnerID=40&md5=01086bb842e71faf3f2fdc46f107ce78
AB  - The proceedings contain 28 papers. The special focus in this conference is on ICT Systems Security and Privacy Protection. The topics include: TAR: Generalized Forensic Framework to Detect Deepfakes Using Weakly Supervised Learning; anomaly Detection for Insider Threats: An Objective Comparison of Machine Learning Models and Ensembles; revitalizing Self-Organizing Map: Anomaly Detection Using Forecasting Error Patterns; what Is Lurking in Your Backups?; how Do Users Chain Email Accounts Together?; tensions that Hinder the Implementation of Digital Security Governance; SIUV: A Smart Car Identity Management and Usage Control System Based on Verifiable Credentials; a Performance Assessment of Free-to-Use Vulnerability Scanners - Revisited; QuickBCC: Quick and Scalable Binary Vulnerable Code Clone Detection; Automatic Inference of Taint Sources to Discover Vulnerabilities in SOHO Router Firmware; ESQABE: Predicting Encrypted Search Queries; reconnection-Based Covert Channels in Wireless Networks; Minecraft Altered Skin Channel (MASC); preface; XML Signature Wrapping Still Considered Harmful: A Case Study on the Personal Health Record in Germany; Lattice-Based Weak Curve Fault Attack on ECDSA; hyperSec: Visual Analytics for Blockchain Security Monitoring; 100 Popular Open-Source Infosec Tools; RootAsRole: Towards a Secure Alternative to sudo/su Commands for Home Users and SME Administrators; Accept All: The Landscape of Cookie Banners in Greece and the UK; The AppChk Crowd-Sourcing Platform: Which Third Parties are iOS Apps Talking To?; compiling Personal Data and Subject Categories from App Data Models; privacy Concerns Go Hand in Hand with Lack of Knowledge: The Case of the German Corona-Warn-App; perceived Privacy Problems Within Digital Contact Tracing: A Study Among Swedish Citizens.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Al-Mhiqani, M.N.
AU  - Ahmad, R.
AU  - Zainal Abidin, Z.Z.
AU  - Isnin, S.N.
TI  - An Integrated Imbalanced Learning and Deep Neural Network Model for Insider Threat Detection
PY  - 2021
T2  - International Journal of Advanced Computer Science and Applications
VL  - 12
IS  - 1
SP  - 573
EP  - 577
DO  - 10.14569/IJACSA.2021.0120166
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100426593&doi=10.14569%2FIJACSA.2021.0120166&partnerID=40&md5=64c9da2ffdf960a2a890889124018d95
AB  - The insider threat is a vital security problem concern in both the private and public sectors. A lot of approaches available for detecting and mitigating insider threats. However, the implementation of an effective system for insider threats detection is still a challenging task. In previous work, the Machine Learning (ML) technique was proposed in the insider threats detection domain since it has a promising solution for a better detection mechanism. Nonetheless, the (ML) techniques could be biased and less accurate when the dataset used is hugely imbalanced. Therefore, in this article, an integrated insider threat detection is named (AD-DNN), which is an integration of adaptive synthetic technique (ADASYN) sampling approach and deep neural network technique (DNN). In the proposed model (AD-DNN), the adaptive synthetic (ADASYN) is used to solve the imbalanced data issue and the deep neural network (DNN) for insider threat detection. The proposed model uses the CERT dataset for the evaluation process. The experimental results show that the proposed integrated model improves the overall detection performance of insider threats. A significant impact on the accuracy performance brings a better solution in the proposed model compared with the current insider threats detection system. © 2021. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 53
ER  -

TY  - CHAP
AU  - Dhavale, S.V.
TI  - Motivational quotes-based intelligent insider threat prediction model
PY  - 2020
SP  - 164
EP  - 176
DO  - 10.4018/978-1-7998-4900-1.ch010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137313209&doi=10.4018%2F978-1-7998-4900-1.ch010&partnerID=40&md5=3a5ac3e26e964dd0c597a70fcdbeb421
AB  - Insiders are considered as the weakest link. The digital records of a person's Facebook likes against motivational quotes can be used for automatic and accurate prediction of sensitive attributes related to their personality traits depression, and their views against company/government policies, etc. Such analysis will help organization to take proactive measures against vulnerable insiders. Insiders managing their impressions differently than their basic personality traits can also be identified. Deep learning models can be utilized to learn and map the association among extracted features and insider behavioral patterns. Further, reinforcement techniques can be used to select appropriate motivational quotes in order to collect additional data required for further analysis. At the same time, the same exposed motivational messages on insider's social platform can aid to improve their psychological health over a time. However, due to implications involved in data collections related to personalization and data collection privacy, the authors have quoted their work in terms of this concept chapter only. © 2021, IGI Global.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Raut, M.
AU  - Dhavale, S.V.
AU  - Singh, A.
AU  - Mehra, A.
TI  - Insider threat detection using deep learning: A review
PY  - 2020
C7  - 9315932
SP  - 856
EP  - 863
DO  - 10.1109/ICISS49785.2020.9315932
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100739541&doi=10.1109%2FICISS49785.2020.9315932&partnerID=40&md5=c3be6fcb08e86076694ae8cc167524f5
AB  - A plethora of research is available for detecting and mitigating threats that occur across the organization's boundaries. However, Insider Threat Detection has only recently entered the limelight. It turns out to be a daunting task, given that insiders can evade firewalls, Intrusion Detection Systems, and other security mechanisms aimed at protecting the information infrastructure from outside attacks. In addition to this, some insiders having administrative rights to access privileged information and perform operations on it might turn rogue. Their malicious actions could go undetected as their digital footprint might get buried in massive dumps of log data. This survey aims to provide a comprehensive explanation of the problem statement at hand, Insider Threat Detection using Deep Learning. It has been initiated by introducing Insider Threat Detection and related terminology. Deep Learning has been chosen as the preferred approach for solving this problem statement as it has been proven to be better than the conventional Machine Learning algorithms while dealing with complex data originating from varied sources. Here, Deep Learning and Log based Anomaly Detection have been explained. Some datasets available specifically for the research domain of Insider Threat Detection have been brought under one roof. Then, by having a closer look at the CERT Insider Threat Dataset, a brief comparative analysis of the existing Deep Learning solutions for Insider Threat Detection based on this dataset is provided. Also, this work overviews the challenges faced and how they open doors for further research. In order to cater to the readers looking for an industry-oriented approach, this survey explains how a Deep Learning model can be integrated with the Elasticsearch-Logstash-Kibana (ELK) Stack. © 2020 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 23
ER  -

TY  - CONF
AU  - Diop, A.
AU  - Emad, N.
AU  - Winter, T.
TI  - A Parallel and Scalable Framework for Insider Threat Detection
PY  - 2020
C7  - 9406705
SP  - 101
EP  - 110
DO  - 10.1109/HiPC50609.2020.00024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105476737&doi=10.1109%2FHiPC50609.2020.00024&partnerID=40&md5=7ef32acba4120b2122d1ec2870012c60
AB  - In this article, we propose an innovative method for the detection of insider threats. This method is based on a unite and conquer approach used to combine ensemble learning techniques, which have the particularity of being intrinsically parallel. Furthermore, it showcases multi-level parallelism properties, offers fault tolerance, and is suitable for heterogeneous architectures. To highlight our approach's efficacy, we present a use case of insider threat detection on a parallel platform. This experiment's results showed the benefits of this method relative to its improvement of classification AUC-score and its scalability. © 2020 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 6
ER  -

TY  - CONF
AU  - Diop, A.
AU  - Emad, N.
AU  - Winter, T.
TI  - A Unite and Conquer Based Ensemble learning Method for User Behavior Modeling
PY  - 2020
C7  - 9391528
DO  - 10.1109/IPCCC50635.2020.9391528
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104493313&doi=10.1109%2FIPCCC50635.2020.9391528&partnerID=40&md5=9615d13a84c0c404737ef65c0aab804a
AB  - IT companies use tools to analyze user and entity behavior to protect their information assets from insider threats. Although supervised machine learning methods seem to be the ideal solution for solving this problem, situations in which new employee activity data is labeled and balanced, are not so common. Besides, the data can have different origins, structures, and can be substantial. Therefore, it's difficult for a specific detection model to deal with and identify insiders in all cases effectively. To provide a solution to this problem, we are faced with methodological, algorithmic, and technological challenges. In this article, we try to meet these challenges by proposing a new approach based on ensemble learning methods to improve their performances from the point of view of accuracy and computation efficiency. With the detection of behavioral anomalies as a case study, we show the interest of this approach for its improvement of the prediction results and its efficacy on a high-performance computing system. © 2020 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 5
ER  -

TY  - CONF
AU  - Al Hammadi, A.Y.
AU  - Yeun, C.Y.
AU  - Damiani, E.
TI  - Novel EEG risk framework to identify insider threats in national critical infrastructure using deep learning techniques
PY  - 2020
C7  - 9284522
SP  - 469
EP  - 471
DO  - 10.1109/SCC49832.2020.00071
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099261196&doi=10.1109%2FSCC49832.2020.00071&partnerID=40&md5=e37bbc40781621c6b9667607d5be9351
AB  - The Cybersecurity of organization is becoming quite alarming especially in National Critical Infrastructure (NCI) as to protect their sensitive information and other valuable assets. A lot of focus has been done in managing outside attacks of data in organizations. Including Cyber-Physical System (CPS), which is a complex mixture of physical and computer components typically monitored or controlled by computer-based algorithms. However, there has been need to safeguard insider's behavior of breaching the expected code of conduct in maintaining the critical organizations' data and assets. The technology is highly reliable as it cannot be easily fabricated. The analysis of the brainwave signal will be performed using an advanced deep learning algorithm called Long Short Term Memory Recurrent Neural Network (LSTM-RNN) classifier which will remember a previous mental states of each insider and compare it with new present brain state to classify the risk level associated. The brain wave is also analysed with Adaptive Machine learning Algorithm which combines several weak learners which is decision trees, to form a single strong learner. In this study, our targets is to increase the security of NCI by providing a significant proof of concept system to detect insider threats through fitness evaluation using EEG signals that gets analyzed using deep learning algorithm which will classify different mental states into four categories risk matrix. © 2020 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 5
ER  -

TY  - CONF
AU  - Yuan, F.
AU  - Shang, Y.
AU  - Liu, Y.
AU  - Cao, Y.
AU  - Tan, J.
TI  - Data Augmentation for Insider Threat Detection with GAN
PY  - 2020
VL  - 2020-November
C7  - 9288292
SP  - 632
EP  - 638
DO  - 10.1109/ICTAI50040.2020.00102
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098773813&doi=10.1109%2FICTAI50040.2020.00102&partnerID=40&md5=7b8af4ba44f587bb17985bfa49509efc
AB  - In insider threat detection domain, the datasets are highly imbalanced, where the number of user's normal behavior is higher than that of insider's anomalous behavior. A direct approach to handle the class imbalance problem is using data augmentation on the minority class. Existing data augmentation methods mainly produce synthetic samples according with the linear operation based on samples of the minority class. Hence, these methods just focus on local information which leads to the unitarily of the synthetic samples, resulting in overfitting. To enrich the diversity of the synthetic samples, we propose a deep adversarial insider threat detection (DAITD) framework using the Generative Adversarial Networks (GAN) to approximate the true anomalous behavior distribution. Specifically, we first obtain anomalous user behavior representations from the anomalous behavior data (minority class), and then use the generator of the GAN to model the actual anomalous behavior distribution, use the discriminator of the GAN to distinguish whether the synthetic sample from the generator is real or not. In this way, our method is able to generate high quality synthetic samples that are close to the anomalous user behavior. Experimental results show that the DAITD framework outperforms other comparative inside threat detection algorithms. © 2020 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 28
ER  -

TY  - JOUR
AU  - Kim, J.H.
AU  - Kim, C.M.
AU  - Yim, M.-S.
TI  - An investigation of insider threat mitigation based on eeg signal classification
PY  - 2020
T2  - Sensors
VL  - 20
IS  - 21
C7  - 6365
SP  - 1
EP  - 17
DO  - 10.3390/s20216365
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096030415&doi=10.3390%2Fs20216365&partnerID=40&md5=be94019d3682c5ac5c8d3fa2f0e98f8a
AB  - This study proposes a scheme to identify insider threats in nuclear facilities through the detection of malicious intentions of potential insiders using subject-wise classification. Based on electroencephalography (EEG) signals, a classification model was developed to identify whether a subject has a malicious intention under scenarios of being forced to become an insider threat. The model also distinguishes insider threat scenarios from everyday conflict scenarios. To support model development, 21-channel EEG signals were measured on 25 healthy subjects, and sets of features were extracted from the time, time–frequency, frequency and nonlinear domains. To select the best use of the available features, automatic selection was performed by random-forest-based algorithms. The k-nearest neighbor, support vector machine with radial kernel, naïve Bayes, and multilayer perceptron algorithms were applied for the classification. By using EEG signals obtained while contemplating becoming an insider threat, the subject-wise model identified malicious intentions with 78.57% accuracy. The model also distinguished insider threat scenarios from everyday conflict scenarios with 93.47% accuracy. These findings could be utilized to support the development of insider threat mitigation systems along with existing trustworthiness assessments in the nuclear industry. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 15
ER  -

TY  - CONF
AU  - Orizio, R.
AU  - Vuppala, S.
AU  - Basagiannis, S.
AU  - Prován, G.
TI  - Towards an Explainable Approach for Insider Threat Detection: Constraint Network Learning
PY  - 2020
C7  - 9264049
SP  - 42
EP  - 49
DO  - 10.1109/IDSTA50958.2020.9264049
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098638991&doi=10.1109%2FIDSTA50958.2020.9264049&partnerID=40&md5=75755394fbc2baf4ca3c43e3120bfe96
AB  - Insider threats are considered a major threat to information and communication technology (ICT) systems creating an important source of vulnerabilities from a security perspective. The technical knowledge that insiders have about the ICT systems, such as its IT infrastructure, the high load of data generated by other employees of the company which hides insiders' activities, their access rights as well as the confidentiality of the data of which they have access to, creates the perfect scenario for a powerful yet undetected attack. State of the art techniques and security operations center tools struggle to come up with effective solutions to recognise these threats. Therefore, in this paper, we propose a novel artificial intelligence based constraint learning technique to help their detection. The approach creates an optimized constraint network representing the nominal behaviour of an employee and detects threatening events when their associated costs are above a certain threshold. The threshold is learnt alongside with the constraint network model. The proposed approach is based on detection models able to provide human interpretable feedback regarding the detection performed. These information are crucial in helping system operators to understand why the detection has occurred and to help them acting promptly on the threat. The explanation comes directly from the structure of the detection model and relies on the identification of which constraints are being violated. The approach is tested on the CERT insider threat dataset v4.2 and the results obtained look promising, achieving at least the same accuracy as other state of the art techniques as well as providing the details regarding the broken constraints of the threat. A comparison with state of the art techniques applied on this dataset is also provided, showing the strength of our results. © 2020 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 9
ER  -

TY  - JOUR
AU  - Faiz, M.F.
AU  - Arshad, J.
AU  - Alazab, M.
AU  - Shalaginov, A.
TI  - Predicting likelihood of legitimate data loss in email DLP
PY  - 2020
T2  - Future Generation Computer Systems
VL  - 110
SP  - 744
EP  - 757
DO  - 10.1016/j.future.2019.11.004
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075425403&doi=10.1016%2Fj.future.2019.11.004&partnerID=40&md5=95200fdd4cda50b78432767d8c11b304
AB  - The volume and variety of data collected for modern organisations has increased significantly over the last decade necessitating the detection and prevention of disclosure of sensitive data. Data loss prevention is an embedded process used to protect against disclosure of sensitive data to external uncontrolled environments. A typical Data Loss Prevention (DLP) system uses custom policies to identify and prevent accidental and malicious data leakage producing large number of security alerts including significant volume of false positives. Consequently, identifying legitimate data loss can be very challenging as each incident comprises of different characteristics often requiring extensive intervention by a domain expert to review alerts individually. This limits the ability to detect data loss alerts in real-time making organisations vulnerable to financial and reputational damages. The aim of this research is to strengthen data loss detection capabilities of a DLP system by implementing a machine learning model to predict the likelihood of legitimate data loss. We conducted extensive experimentation using Decision Tree and Random Forest algorithms with historical email incident data collected by a globally established telecommunication enterprise. The final model produced with Random Forest algorithm was identified as the most effective as it was successfully able to predict approximately 95% data loss incidents accurately with an average true positive value of 90%. Furthermore, the proposed solution successfully enables identification of legitimate data loss in email DLP whilst facilitating prioritisation of real data loss through human-understandable explanation of the decision thereby improving the efficiency of the process. © 2019 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 17
ER  -

TY  - JOUR
AU  - Nicolaou, A.
AU  - Shiaeles, S.
AU  - Savage, N.
TI  - Mitigating insider threats using bio-inspired models
PY  - 2020
T2  - Applied Sciences (Switzerland)
VL  - 10
IS  - 15
C7  - 5046
DO  - 10.3390/app10155046
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088646483&doi=10.3390%2Fapp10155046&partnerID=40&md5=9bc1304835ee0ffd7478bf4db78a4bcf
AB  - Insider threats have become a considerable information security issue that governments and organizations must face. The implementation of security policies and procedures may not be enough to protect organizational assets. Even with the evolution of information and network security technology, the threat from insiders is increasing. Many researchers are approaching this issue with various methods in order to develop a model that will help organizations to reduce their exposure to the threat and prevent damage to their assets. In this paper, we approach the insider threat problem and attempt to mitigate it by developing a machine learning model based on Bio-inspired computing. The model was developed by using an existing unsupervised learning algorithm for anomaly detection and we fitted the model to a synthetic dataset to detect outliers. We explore swarm intelligence algorithms and their performance on feature selection optimization for improving the performance of the machine learning model. The results show that swarm intelligence algorithms perform well on feature selection optimization and the generated, near-optimal, subset of features has a similar performance to the original one. © 2020 by the authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 18
ER  -

TY  - CONF
TI  - Proceedings of the 11th International Conference on Advances in Information Technology, IAIT 2020
PY  - 2020
T2  - ACM International Conference Proceeding Series
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123043303&partnerID=40&md5=b443ca9c57808415a9531eb95478ecf1
AB  - The proceedings contain 47 papers. The topics discussed include: stock price analysis with natural language processing and machine learning; data mining methods for optimizing feature extraction and model selection; gamifying MOOC's a step in the right direction? a systematic literature review; exploration of hardware architectures for string matching algorithms in network intrusion detection systems; robust LCSS beamformer against DOA mismatch; user behavior analytics for anomaly detection using LSTM autoencoder - insider threat detection; automated scheduling of undergraduate student advising reservation using extended flower pollination algorithm; enhancement of fault tolerance in Kafka pipeline architecture; a system to estimate the amount and calories of food that elderly people in the hospital consume; and correlation-based incremental learning network with sliding window for perfume classification.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Sharma, B.
AU  - Pokharel, P.
AU  - Joshi, B.
TI  - User Behavior Analytics for Anomaly Detection Using LSTM Autoencoder-Insider Threat Detection
PY  - 2020
T2  - ACM International Conference Proceeding Series
DO  - 10.1145/3406601.3406610
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117543134&doi=10.1145%2F3406601.3406610&partnerID=40&md5=94c98a1fb803a966d28026eba6f11c0f
AB  - Identifying anomalies from log data for insider threat detection is practically a very challenging task for security analysts. User behavior modeling is very important for the identification of these anomalies. This paper presents unsupervised user behavior modeling for anomaly detection. The proposed approach uses LSTM based Autoencoder to model user behavior based on session activities and thus identify the anomalous data points. The proposed method follows a two-step process. First, it calculates the reconstruction error using the autoencoder on the non-anomalous dataset, and then it is used to define the threshold to separate the outliers from the normal data points. The identified outliers are then classified as anomalies. The CERT insider threat dataset has been used for the research work. For each user, the feature vectors are prepared by extracting key information from corresponding raw events and aggregating the data points based on users' actions within respective users' sessions. LSTM Autoencoder has been implemented for behavior learning and anomaly detection. For any unseen behavior or anomaly pattern, the model produces high reconstruction error which is an indication of an anomaly. The experimental results show that in the best case, the model produced an Accuracy of 90.17%, True Positives 91.03%, and False Positives 9.84%. Thus, the results suggest that the proposed approach can be effectively used in automatic anomaly detection. © 2020 ACM.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 84
ER  -

TY  - JOUR
AU  - Gayathri, R.G.
AU  - Sajjanhar, A.
AU  - Xiang, Y.
TI  - Image-based feature representation for insider threat classification
PY  - 2020
T2  - Applied Sciences (Switzerland)
VL  - 10
IS  - 14
C7  - 4945
DO  - 10.3390/app10144945
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088628096&doi=10.3390%2Fapp10144945&partnerID=40&md5=e36f28ab7774125c32dfde1c8892f53b
AB  - Cybersecurity attacks can arise from internal and external sources. The attacks perpetrated by internal sources are also referred to as insider threats. These are a cause of serious concern to organizations because of the significant damage that can be inflicted by malicious insiders. In this paper, we propose an approach for insider threat classification which is motivated by the effectiveness of pre-trained deep convolutional neural networks (DCNNs) for image classification. In the proposed approach, we extract features from usage patterns of insiders and represent these features as images. Hence, images are used to represent the resource access patterns of the employees within an organization. After construction of images, we use pre-trained DCNNs for anomaly detection, with the aim to identify malicious insiders. Random under sampling is used for reducing the class imbalance issue. The proposed approach is evaluated using the MobileNetV2, VGG19, and ResNet50 pre-trained models, and a benchmark dataset. Experimental results show that the proposed method is effective and outperforms other state-of-the-art methods. © 2020 by the authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 41
ER  -

TY  - CONF
AU  - Gegan, R.
AU  - Perry, B.
AU  - Ghosal, D.
AU  - Bishop, M.
TI  - Insider Attack Detection for Science DMZs Using System Performance Data
PY  - 2020
C7  - 9162260
DO  - 10.1109/CNS48642.2020.9162260
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090131567&doi=10.1109%2FCNS48642.2020.9162260&partnerID=40&md5=d07ccf87074fca17b1f30c05eb366e39
AB  - The science DMZ is a specialized network model developed to guarantee secure and efficient transfer of data for large-scale distributed research. To enable a high level of performance, the Science DMZ includes dedicated data transfer nodes (DTNs). Protecting these DTNs is crucial to maintaining the overall security of the network and the data, and insider attacks are a major threat. Although some limited network intrusion detection systems (NIDS) are deployed to monitor DTNs, this alone is not sufficient to detect insider threats. Monitoring for abnormal system behavior, such as unusual sequences of system calls, is one way to detect insider threats. However, the relatively predictable behavior of the DTN suggests that we can also detect unusual activity through monitoring system performance, such as CPU and disk usage, along with network activity. In this paper, we introduce a potential insider attack scenario, and show how readily available system performance metrics can be employed to detect data tampering within DTNs, using DBSCAN clustering to actively monitor for unexpected behavior. © 2020 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Sundaram, A.
AU  - Abdel-Khalik, H.S.
AU  - Ashy, O.
TI  - A data analytical approach for assessing the efficacy of Operational Technology active defenses against insider threats
PY  - 2020
T2  - Progress in Nuclear Energy
VL  - 124
C7  - 103339
DO  - 10.1016/j.pnucene.2020.103339
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082777020&doi=10.1016%2Fj.pnucene.2020.103339&partnerID=40&md5=0a1da381df86cb8bda0c32abf6b72bfc
AB  - In recent years, the need for Operational Technology (OT) defenses has been recognized, serving as an additional line of defense when Information Technology (IT) defenses are bypassed. This is no longer considered an uncommon possibility when dealing with advanced persistent threat (APT) actors expected to be state-sponsored and receiving insider assistance. In these extreme adversarial situations, OT defenses aim to provide another layer of defense for the system, introduced directly at the physical process level, as described by the sensors data, the system model, and control actions. Just like IT defenses, two schools of thought, i.e., passive and active defenses, have emerged to address this challenge. In active defenses, representing the focus of this paper, known signatures, synthesized based on the system's unique characteristics, are inserted into the system. In contradistinction, passive methods rely solely on observing system behavior in search of patterns of normal behavior with deviations thereof representing abnormal behavior. In their most sophisticated implementations, both passive and active defenses rely on the use of data analytics to identify the patterns and synthesize the observed and/or inserted signatures. Past research has shown that passive defenses may be bypassed by APT actors relying on data analytics and their intimate knowledge of the system to evade detection by respecting the patterns identified by the defenders. Thus, this manuscript explores the use of active defenses under the assumption that the attacker has privileged access to the system, including access to the system's model and sensors data. Specifically, this manuscript assesses the ability of active defenses to remain invisible to the attackers, and discusses the associated challenges that must be addressed to ensure their resiliency against APT actors. © 2020 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 9
ER  -

TY  - CONF
AU  - Duessel, P.
AU  - Luo, S.
AU  - Flegel, U.
AU  - Dietrich, S.
AU  - Meier, M.
TI  - Tracing privilege misuse through behavioral anomaly detection in geometric spaces
PY  - 2020
C7  - 9133707
SP  - 22
EP  - 31
DO  - 10.1109/SADFE51007.2020.00012
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092162696&doi=10.1109%2FSADFE51007.2020.00012&partnerID=40&md5=d503c202109ec1acb1980684642bd103
AB  - Privilege misuse is a common technique used by insiders to ex-filtrate proprietary information or sabotage organizations. Although operating systems provide means to log security-related activities indicators of compromise are often difficult to detect due to the often proprietary nature of logging mechanisms in place - rendering the analysis of log files a daunting task. In this contribution we present a format-agnostic approach to detect privilege misuse based on rule-free user activity models learned over security audit logs typically provided by servers. We investigate language model based feature types (i.e. token grams, temporal token grams and attributed token grams) using One-Class Support Vector Machines (OC-SVM). We conduct experiments on synthetic as well as real-world data collected on Microsoft Windows 2008 servers to investigate the effect of feature types and similarity measures and demonstrate usability of this approach for privilege misuse detection as part of an insider threat detection program. © 2020 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Sheykhkanloo, N.M.
AU  - Hall, A.
TI  - Insider threat detection using supervised machine learning algorithms on an extremely imbalanced dataset
PY  - 2020
T2  - International Journal of Cyber Warfare and Terrorism
VL  - 10
IS  - 2
SP  - 1
EP  - 26
DO  - 10.4018/IJCWT.2020040101
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094196104&doi=10.4018%2FIJCWT.2020040101&partnerID=40&md5=6038d3f57e655c9824c13e4bccebab55
AB  - An insider threat can take on many forms and fall under different categories. This includes malicious insider, careless/unaware/uneducated/naïve employee, and the third-party contractor. Machine learning techniques have been studied in published literature as a promising solution for such threats. However, they can be biased and/or inaccurate when the associated dataset is hugely imbalanced. Therefore, this article addresses the insider threat detection on an extremely imbalanced dataset which includes employing a popular balancing technique known as spread subsample. The results show that although balancing the dataset using this technique did not improve performance metrics, it did improve the time taken to build the model and the time taken to test the model. Additionally, the authors realised that running the chosen classifiers with parameters other than the default ones has an impact on both balanced and imbalanced scenarios, but the impact is significantly stronger when using the imbalanced dataset. © 2020, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 33
ER  -

TY  - CONF
AU  - Ho, T.-Y.
AU  - Chen, W.-A.
AU  - Sun, M.-K.
AU  - Huang, C.-Y.
TI  - Visualizing the Malicious of Your Network Traffic by Explained Deep Learning
PY  - 2020
C7  - 9065247
SP  - 687
EP  - 692
DO  - 10.1109/ICAIIC48513.2020.9065247
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084071022&doi=10.1109%2FICAIIC48513.2020.9065247&partnerID=40&md5=b3256b7b05269ced2ada2604740a529c
AB  - In recent years, insider threats within computers have been overgrowing because a high quantity of malware and its variants have been spread massively by spam mail, malvertising attack, and users' carelessness. Moreover, some of the dormant malware would not be inspected by ant-virus software, and the risk exists continually until finally becoming a disastrous economic loss. Several studies developed signature-based methods to detect insider threats, but we are more interested in how to simplify the network behavior from sophisticated traffic flow. Without inspecting network payload and packet with time-consuming, we focus on the traffic behavior that we only consider the features of source IP, destination IP, timestamp of connection, and quantity of connection. To conquer the black box of complicated network traffic, this work applies the deep learning paradigm and proposes the variant version of VGG16 to examine the features within traffic flow. Finally, this paper proposes a method to support more explanation on traffic behavior with learning model. © 2020 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Loheswaran, K.
AU  - Murali, D.
AU  - Kalaiabirami, D.
TI  - RNN with adaptive split algorithm for the analysis of security on cloud computing
PY  - 2020
T2  - International Journal of Advanced Science and Technology
VL  - 29
IS  - 3
SP  - 3191
EP  - 3204
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081190470&partnerID=40&md5=4665054ffb27181a885944f67ed19ee3
AB  - One of the most recent trends in IT division is cloud computing (CC). It is an appropriated processing condition which has committed registering assets gotten to whenever from anyplace. In the present time, user keeps a high measure of information on cloud and even share a great deal of information, and thus, it is important to utilize safety efforts so that there is no risk to any of the client's information. To furnish an abnormal state of security with the fast headway of Internet, numerous devices and systems are being utilized. In this study, a Hybrid Adaptive algorithm is developed for the security on Cc. The proposed adaptive machine learning algorithm is the combination of Recurrent Neural Network (RNN) with adaptive split algorithm (ASA). RNN is one of the Artificial Intelligence (AI) techniques, which is utilized to classification purpose. The proposed hybrid adaptive algorithm is utilized to classify the data before the encryption process. Based on the process, the accuracy of the data is achieved and it requires less memory space only. After the data storage allocation, the design of end to end security framework is carried out. The main objective is to secure the data and eliminate the insider threats. The objective of the paper is to increase security by using adaptive split algorithm (ASA) for the transfer of data on cloud servers. The proposed hybrid adaptive method is implemented in JAVA platform and compared with the traditional methods, such as Artificial Neural Network (ANN), Support Vector Machines (SVM),respectively. Moreover, the statistical measures are evaluated Accuracy, Recall, Precision, F-measure, for the proposed and existing methods. © 2019 SERSC.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 3
ER  -

TY  - CHAP
AU  - Burns, D.
TI  - APPLICATIONS OF ARTIFICIAL INTELLIGENCE IN CYBERSECURITY
PY  - 2020
SP  - 21
EP  - 48
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138361319&partnerID=40&md5=f92df8d615708e15a3b8cd86c0a3d70a
AB  - Can artificial intelligence (AI) predict human behavior like insider threats? A detailed case study for predicting attrition using human resources data will shed light on how to recast these types of questions in a statistical context. National security implications are explored while common applications of AI in cybersecurity are surveyed. The prevelance and success of adversarial attacks on AI systems indicates there is a clear need to perform quantitative risk and threat assessments for companies and agencies beginning to implement AI and machine learning tools, but have not necessarily considered security implications. A standard framework is developed for securing data analytics projects. Strong motivation is given for the need to defend against adversarial attacks related to national security. © 2021 by Nova Science Publishers, Inc. All rights reserved.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Janjua, F.
AU  - Masood, A.
AU  - Abbas, H.
AU  - Rashid, I.
TI  - Handling insider threat through supervised machine learning techniques
PY  - 2020
T2  - Procedia Computer Science
VL  - 177
SP  - 64
EP  - 71
DO  - 10.1016/j.procs.2020.10.012
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099882239&doi=10.1016%2Fj.procs.2020.10.012&partnerID=40&md5=718a09054e6ea6c79640c3cfd46af416
AB  - Information technology systems face increasing cyber security threats, mostly from insiders. Network security mechanism for insiders are not as strict as for rest. Also insider can easily bypass security or have legitimate access to confidential documents, therefore to detect and prevent insider threat is a growing challenge. The aim of this paper is to implement predictive models that are using linguistic analysis to determine an employee's risk level computer-mediated communication, particularly emails. The emails log part of the TWOS dataset has been analyzed using supervised machine learning techniques. The data set comprise behavior traces of 24 users observed over 5 days spam. Limited data issue have been addressed by avoiding complex models with many parameters. We have limited their normalization and ability to overfit by using existing pivotal models. The outcomes are collated and contrasted for the following algorithms: Adaboost, Naive Bayes (NB), Logistic Regression (LR), KNN, Linear Regression (LR) and Support Vector Machine (SVM). Among all these algorithms, Adaboost has outperformed with 98.3% Accuracy and 0.983 AUC for identification of malicious emails. © 2020 The Authors. Published by Elsevier B.V.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 34
ER  -

TY  - JOUR
TI  - 11th Conference on Decision and Game Theory for Security, GameSec 2020
PY  - 2020
T2  - Lecture Notes in Computer Science
VL  - 12513 LNCS
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098286932&partnerID=40&md5=9136c07fca6224f9aa7162b6f5f1ff5f
AB  - The proceedings contain 29 papers. The special focus in this conference is on Decision and Game Theory for Security. The topics include: Farsighted Risk Mitigation of Lateral Movement Using Dynamic Cognitive Honeypots; exploiting Bounded Rationality in Risk-Based Cyber Camouflage Games; a Realistic Approach for Network Traffic Obfuscation Using Adversarial Machine Learning; security Games with Insider Threats; hardware Security and Trust: A New Battlefield of Information; a Review of Multi Agent Perimeter Defense Games; attacking Machine Learning Models for Social Good; a Data-Driven Distributionally Robust Game Using Wasserstein Distance; using One-Sided Partially Observable Stochastic Games for Solving Zero-Sum Security Games with Sequential Attacks; MASAGE: Model-Agnostic Sequential and Adaptive Game Estimation; on the Characterization of Saddle Point Equilibrium for Security Games with Additive Utility; combating Online Counterfeits: A Game-Theoretic Analysis of Cyber Supply Chain Ecosystem; a Game Theoretic Framework for Software Diversity for Network Security; normalizing Flow Policies for Multi-agent Systems; blocking Adversarial Influence in Social Networks; popular Imperceptibility Measures in Visual Adversarial Attacks are Far from Human Perception; lie Another Day: Demonstrating Bias in a Multi-round Cyber Deception Game of Questionable Veracity; adversarial Deep Reinforcement Learning Based Adaptive Moving Target Defense; learning and Planning in the Feature Deception Problem; moving Target Defense for Robust Monitoring of Electric Grid Transformers in Adversarial Environments; secure Discrete-Time Linear-Quadratic Mean-Field Games; harnessing the Power of Deception in Attack Graph-Based Security Games; partially Observable Stochastic Games for Cyber Deception Against Network Epidemic; decoy Allocation Games on Graphs with Temporal Logic Objectives.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Al Hammadi, A.Y.
AU  - Lee, D.
AU  - Yeun, C.Y.
AU  - Damiani, E.
AU  - Kim, S.-K.
AU  - Yoo, P.D.
AU  - Choi, H.-J.
TI  - Novel EEG Sensor-Based Risk Framework for the Detection of Insider Threats in Safety Critical Industrial Infrastructure
PY  - 2020
T2  - IEEE Access
VL  - 8
C7  - 9258932
SP  - 206222
EP  - 206234
DO  - 10.1109/ACCESS.2020.3037979
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097216922&doi=10.1109%2FACCESS.2020.3037979&partnerID=40&md5=bc4482b79dc22fda78f7d444aa7b6ed9
AB  - The loss or compromise of any safety critical industrial infrastructure can seriously impact the confidentiality, integrity, or delivery of essential services. Research has shown that such threats often come from malicious insiders. To identify these insiders, survey-and electrocardiogram-based approaches have been proposed; however, these approaches cannot effectively detect or predict any malicious insiders. Recently, electroencephalograms (EEGs) have been suggested as a potential alternative to detect these potential threats. Threat detection using EEG would be highly reliable as it overcomes the limitations of the previous methods. This study proposes a proof of concept for a system wherein a model trained using a deep learning algorithm is employed to evaluate EEG signals to detect insider threats. The algorithm can classify different mental states based on four category risk matrices. In particular, it analyses brainwave signals using long short-Term memory (LSTM) designed to remember the previous mental states of each insider and compare them with the current brain state for associated risk-level classification. To evaluate the performance of the proposed system, we performed a comparative analysis using logistic regression (LR)-a predictive analysis technique used to describe the relationship between one dependent binary variable and one or more independent variables-on the same dataset. The experimental results obtained suggest that LSTM can achieve a classification accuracy of more than 80% compared to LR, which yields a classification accuracy of approximately 51%. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 20
ER  -

TY  - JOUR
TI  - 13th International Conference on Social Computing, Behavioral-Cultural Modeling and Prediction and Behavior Representation in Modeling and Simulation, SBP-BRiMS 2020
PY  - 2020
T2  - Lecture Notes in Computer Science
VL  - 12268 LNCS
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094126641&partnerID=40&md5=f5d00b79832e7512a960a219a9f11c86
AB  - The proceedings contain 33 papers. The special focus in this conference is on Social Computing, Behavioral-Cultural Modeling and Prediction and Behavior Representation in Modeling and Simulation. The topics include: Deploying System Dynamics Models for Disease Surveillance in the Philippines; MDR Cluster-Debias: A Nonlinear Word Embedding Debiasing Pipeline; modeling Interventions for Insider Threat; validating Social Media Monitoring: Statistical Pitfalls and Opportunities from Public Opinion; lying About Lying on Social Media: A Case Study of the 2019 Canadian Elections; breadth Verses Depth: The Impact of Tree Structure on Cultural Influence; preface; beyond Words: Comparing Structure, Emoji Use, and Consistency Across Social Media Posts; optimizing Attention-Aware Opinion Seeding Strategies; polarizing Tweets on Climate Change; characterizing Sociolinguistic Variation in the Competing Vaccination Communities; on Countering Disinformation with Caution: Effective Inoculation Strategies and Others that Backfire into Community Hyper-Polarization; homicidal Event Forecasting and Interpretable Analysis Using Hierarchical Attention Model; development of a Hybrid Machine Learning Agent Based Model for Optimization and Interpretability; canadian Federal Election and Hashtags that Do Not Belong; group Formation Theory at Multiple Scales; towards Agent Validation of a Military Cyber Team Performance Simulation; developing Graph Theoretic Techniques to Identify Amplification and Coordination Activities of Influential Sets of Users; bot Impacts on Public Sentiment and Community Structures: Comparative Analysis of Three Elections in the Asia-Pacific; detecting Online Hate Speech: Approaches Using Weak Supervision and Network Embedding Models; critical Spatial Clusters for Vaccine Preventable Diseases; multi-cause Discrimination Analysis Using Potential Outcomes; twitter Is the Megaphone of Cross-platform Messaging on the White Helmets.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Wei, Y.
AU  - Chow, K.-P.
AU  - Yiu, S.-M.
TI  - Insider threat detection using multi-autoencoder filtering and unsupervised learning
PY  - 2020
T2  - IFIP Advances in Information and Communication Technology
VL  - 589 IFIP
SP  - 273
EP  - 290
DO  - 10.1007/978-3-030-56223-6_15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091271356&doi=10.1007%2F978-3-030-56223-6_15&partnerID=40&md5=f6deefc70c8c4918935362329e287b75
AB  - Insider threat detection and investigation are major challenges in digital forensics. Unlike external attackers, insiders have privileges to access resources in their organizations and violations of normal behavior are difficult to detect. This chapter describes an unsupervised deep learning framework for detecting insider threats by analyzing system log files. A typical deep neural network can capture normal behavior patterns, but not insider threat behavior patterns because of the presence of small, if any, amounts of insider threat data. For example, the autoencoder unsupervised deep learning model, which is widely used for anomaly detection, requires a dataset containing labeled normal data for training purposes and does not work well when the training dataset contains anomalies. In contrast, the framework proposed in this chapter leverages unsupervised multi-autoencoder filtering to remove anomalies from a training dataset and uses the resulting trained Gaussian mixture model to estimate the distributions of encoded and recognized normal data; data with lower probabilities is identified as insider threat data by the trained model. Experiments demonstrate that the multi-autoencoder-filtered unsupervised learning framework has superior detection performance compared with state-of-the-art baseline models. © IFIP International Federation for Information Processing 2020.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 8
ER  -

TY  - CONF
AU  - Sanders, M.W.
AU  - Yue, C.
TI  - Mining least privilege attribute based access control policies
PY  - 2019
T2  - ACM International Conference Proceeding Series
SP  - 404
EP  - 416
DO  - 10.1145/3359789.3359805
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077815423&doi=10.1145%2F3359789.3359805&partnerID=40&md5=483da404d6fb00ff4fbf7db8ad299b5f
AB  - Creating effective access control policies is a significant challenge to many organizations. Over-privilege increases security risk from compromised credentials, insider threats, and accidental misuse. Under-privilege prevents users from performing their duties. Policies must balance between these competing goals of minimizing under-privilege vs. over-privilege. The Attribute Based Access Control (ABAC) model has been gaining popularity in recent years because of its advantages in granularity, flexibility, and usability. ABAC allows administrators to create policies based on attributes of users, operations, resources, and the environment. However, in practice, it is often very difficult to create effective ABAC policies in terms of minimizing under-privilege and over-privilege especially for large and complex systems because their ABAC privilege spaces are typically gigantic. In this paper, we take a rule mining approach to mine systems’ audit logs for automatically generating ABAC policies which minimize both under-privilege and over-privilege. We propose a rule mining algorithm for creating ABAC policies with rules, a policy scoring algorithm for evaluating ABAC policies from the least privilege perspective, and performance optimization methods for dealing with the challenges of large ABAC privilege spaces. Using a large dataset of 4.7 million Amazon Web Service (AWS) audit log events, we demonstrate that our automated approach can effectively generate least privilege ABAC policies, and can generate policies with less over-privilege and under-privilege than a Role Based Access Control (RBAC) approach. Overall, we hope our work can help promote a wider and faster deployment of the ABAC model, and can help unleash the advantages of ABAC to better protect large and complex computing systems. © 2019 Association for Computing Machinery.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 40
ER  -

TY  - CONF
AU  - Hines, C.
AU  - Youssef, A.
TI  - Class Balancing for Fraud Detection in Point of Sale Systems
PY  - 2019
C7  - 9006040
SP  - 4730
EP  - 4739
DO  - 10.1109/BigData47090.2019.9006040
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081321234&doi=10.1109%2FBigData47090.2019.9006040&partnerID=40&md5=06e9a0d38f5cf0df8586b79c9bbbbf47
AB  - Restaurant servers are an example of an insider threat to the security of restaurant financial data. This paper applies machine learning to detect the digital representation of malevolent behavior of restaurant employees. The results of this research could be used to notify restaurant owners in real time when fraud is being committed. This paper applies machine learning (ML) techniques including neural networks, support vector machines, Random Forest, and Adaboost, to detecting insider fraud in restaurant point-of-sales data. By applying undersampling and oversampling class balancing techniques we show that ML techniques can improve fraud detection performance. In particular, detection with a Random Forest model using cross validation can be increased 55% by oversampling the minority class to the same size as the majority class. And results with a Neural Net model trained to detect fraud on the first year the restaurant opened, and tested on data from the following year can be improved by 50% by decreasing the majority class to be the same size as the minority class. © 2019 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Soh, C.
AU  - Yu, S.
AU  - Narayanan, A.
AU  - Duraisamy, S.
AU  - Chen, L.
TI  - Employee profiling via aspect-based sentiment and network for insider threats detection
PY  - 2019
T2  - Expert Systems with Applications
VL  - 135
SP  - 351
EP  - 361
DO  - 10.1016/j.eswa.2019.05.043
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067510467&doi=10.1016%2Fj.eswa.2019.05.043&partnerID=40&md5=7cd94515d6ba1cb57ccd020da797b0cf
AB  - Historically, the harm caused by insiders has proven to be one of the greatest concerns for any organization. As such, it has received considerable attention from both the industrial and research communities. Existing works mainly focused on modeling the employees’ normal biometric behavior (e.g., human to device interaction pattern) to detect anomalous behavior which corresponds to the insider activity. However, it is unattainable to stop the insider at the final moment when the malicious act is being carried out. In this paper, we propose a novel framework which performs employee profiling based on aspect-based sentiments and social network information and examine its applicability for early detection of potential insider threats. On the contrary to the traditional sentiment analysis, aspect-based sentiment analysis provides more fine-grained information on the employee. Our framework employs a combination of deep learning techniques such as Gated Recurrent Unit (GRU) and skipgram to build temporal sentiment profiles for the employees. It then performs anomaly detection on the profiles and ranks the employees based on their respective anomaly score. Due to the absence of relevant benchmark dataset, we augmented the publicly available real-world Enron email corpus with an insider threat scenario to evaluate our framework. The evaluation results demonstrate that the augmentation is indeed reflected in the augmented employee's anomaly ranking (i.e., from normal to abnormal) and her close associates are indeed placed closely to her when the profiles are visualized in the 2D space. The profiles obtained from our framework can also be used to complement any existing expert and intelligent systems with additional capabilities in handling textual information such as, integration with profiles obtained from biometric behavior to form a more comprehensive threat detection system. © 2019 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 53
ER  -

TY  - CONF
AU  - Liu, F.
AU  - Jiang, X.
AU  - Wen, Y.
AU  - Xing, X.
AU  - Zhang, D.
AU  - Meng, D.
TI  - Log2vec: A heterogeneous graph embedding based approach for detecting cyber threats within enterprise
PY  - 2019
T2  - Proceedings of the ACM Conference on Computer and Communications Security
SP  - 1777
EP  - 1794
DO  - 10.1145/3319535.3363224
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075931180&doi=10.1145%2F3319535.3363224&partnerID=40&md5=57d05e9c2f6c5e9e94ebfd16af6fcfbb
AB  - Conventional attacks of insider employees and emerging APT are both major threats for the organizational information system. Existing detections mainly concentrate on users' behavior and usually analyze logs recording their operations in an information system. In general, most of these methods consider sequential relationship among log entries and model users' sequential behavior. However, they ignore other relationships, inevitably leading to an unsatisfactory performance on various attack scenarios. We propose log2vec, a heterogeneous graph embedding based modularized method. First, it involves a heuristic approach that converts log entries into a heterogeneous graph in the light of diverse relationships among them. Next, it utilizes an improved graph embedding appropriate to the above heterogeneous graph, which can automatically represent each log entry into a low-dimension vector. The third component of log2vec is a practical detection algorithm capable of separating malicious and benign log entries into different clusters and identifying malicious ones. We implement a prototype of log2vec. Our evaluation demonstrates that log2vec remarkably outperforms state-of-the-art approaches, such as deep learning and hidden markov model (HMM). Besides, log2vec shows its capability to detect malicious events in various attack scenarios. © 2019 Association for Computing Machinery.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 265
ER  -

TY  - CONF
AU  - Jiang, J.
AU  - Chen, J.
AU  - Gu, T.
AU  - Choo, K.-K.R.
AU  - Liu, C.
AU  - Yu, M.
AU  - Huang, W.
AU  - Mohapatra, P.
TI  - Anomaly Detection with Graph Convolutional Networks for Insider Threat and Fraud Detection
PY  - 2019
T2  - Proceedings - IEEE Military Communications Conference MILCOM
VL  - 2019-November
C7  - 9020760
DO  - 10.1109/MILCOM47813.2019.9020760
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082397793&doi=10.1109%2FMILCOM47813.2019.9020760&partnerID=40&md5=163e4cf220e0a05315d80f35e85bd231
AB  - Anomaly detection generally involves the extraction of features from entities' or users' properties, and the design of anomaly detection models using machine learning or deep learning algorithms. However, only considering entities' property information could lead to high false positives. We posit the importance of also considering connections or relationships between entities in the detecting of anomalous behaviors and associated threat groups. Therefore, in this paper, we design a GCN (graph convolutional networks) based anomaly detection model to detect anomalous behaviors of users and malicious threat groups. The GCN model could characterize entities' properties and structural information between them into graphs. This allows the GCN based anomaly detection model to detect both anomalous behaviors of individuals and associated anomalous groups. We then evaluate the proposed model using a real-world insider threat data set. The results show that the proposed model outperforms several state-of-art baseline methods (i.e., random forest, logistic regression, SVM, and CNN). Moreover, the proposed model can also be applied to other anomaly detection applications. © 2019 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 130
ER  -

TY  - CONF
AU  - Jiang, J.
AU  - Chen, J.
AU  - Gu, T.
AU  - Choo, K.-K.R.
AU  - Liu, C.
AU  - Yu, M.
AU  - Huang, W.
AU  - Mohapatra, P.
TI  - Warder: Online Insider Threat Detection System Using Multi-Feature Modeling and Graph-Based Correlation
PY  - 2019
T2  - Proceedings - IEEE Military Communications Conference MILCOM
VL  - 2019-November
C7  - 9020931
DO  - 10.1109/MILCOM47813.2019.9020931
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082382259&doi=10.1109%2FMILCOM47813.2019.9020931&partnerID=40&md5=b3b5f459b26a29d262749c3c5c25f8db
AB  - Existing insider threat detection models and frameworks generally focus on characterizing and detecting malicious insiders, for example by fusing behavioral analysis, machine learning, psychological characters, management measures, etc. However, it remains challenging to design a practical insider threat detection scheme that can be efficiently implemented and deployed in a real-world system. For example, existing approaches focus on extracting features from user behavioral activities but they lack in-depth correlation and decision making for suspected alerts; thus, resulting in high false positives and low detection accuracy. In this work, we propose a novel online insider threat detection system, Warder, which leverages diverse feature dimensions (using neural language processing) and fuses content and behavior features to create a user's daily profile to facilitate threat detection. Besides, hypergraph-based threat scenario feature tree is designed to correlate suspicious users' activities with threat scenarios to further screen the users. In practice, Warder can also be constantly updated using newly discovered features and threat scenarios. We evaluate the performance of Warder using the public CMU CERT dataset, as well as that of approaches from the Oxford group and CMU group. Findings from the evaluation demonstrate that Warder outperforms the other two competing approaches. © 2019 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 12
ER  -

TY  - JOUR
AU  - Kim, J.
AU  - Park, M.
AU  - Kim, H.
AU  - Cho, S.
AU  - Kang, P.
TI  - Insider threat detection based on user behavior modeling and anomaly detection algorithms
PY  - 2019
T2  - Applied Sciences (Switzerland)
VL  - 9
IS  - 19
C7  - 4018
DO  - 10.3390/app9194018
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073279165&doi=10.3390%2Fapp9194018&partnerID=40&md5=aa731cdbc912451f8e06880b341cef7c
AB  - Insider threats are malicious activities by authorized users, such as theft of intellectual property or security information, fraud, and sabotage. Although the number of insider threats is much lower than external network attacks, insider threats can cause extensive damage. As insiders are very familiar with an organization's system, it is very difficult to detect their malicious behavior. Traditional insider-threat detection methods focus on rule-based approaches built by domain experts, but they are neither flexible nor robust. In this paper, we propose insider-threat detection methods based on user behavior modeling and anomaly detection algorithms. Based on user log data, we constructed three types of datasets: user's daily activity summary, e-mail contents topic distribution, and user's weekly e-mail communication history. Then, we applied four anomaly detection algorithms and their combinations to detect malicious activities. Experimental results indicate that the proposed framework can work well for imbalanced datasets in which there are only a few insider threats and where no domain experts' knowledge is provided. © 2019 by the authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 94
ER  -

TY  - CONF
AU  - Aldairi, M.
AU  - Karimi, L.
AU  - Joshi, J.
TI  - A trust aware unsupervised learning approach for insider threat detection
PY  - 2019
C7  - 8843465
SP  - 89
EP  - 98
DO  - 10.1109/IRI.2019.00027
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073221671&doi=10.1109%2FIRI.2019.00027&partnerID=40&md5=e61f12d7cb56ef80617fd196b429f0d1
AB  - With the rapidly increasing connectivity in cyberspace, Insider Threat is becoming a huge concern. Insider threat detection from system logs poses a tremendous challenge for human analysts. Analyzing log files of an organization is a key component of an insider threat detection and mitigation program. Emerging machine learning approaches show tremendous potential for performing complex and challenging data analysis tasks that would benefit the next generation of insider threat detection systems. However, with huge sets of heterogeneous data to analyze, applying machine learning techniques effectively and efficiently to such a complex problem is not straightforward. In this paper, we extract a concise set of features from the system logs while trying to prevent loss of meaningful information and providing accurate and actionable intelligence. We investigate two unsupervised anomaly detection algorithms for insider threat detection and draw a comparison between different structures of the system logs including daily dataset and periodically aggregated one. We use the generated anomaly score from the previous cycle as the trust score of each user fed to the next period's model and show its importance and impact in detecting insiders. Furthermore, we consider the psychometric score of users in our model and check its effectiveness in predicting insiders. As far as we know, our model is the first one to take the psychometric score of users into consideration for insider threat detection. Finally, we evaluate our proposed approach on CERT insider threat dataset (v4.2) and show how it outperforms previous approaches. © 2019 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 27
ER  -

TY  - CONF
AU  - Zhang, J.
AU  - Chen, Y.
AU  - Yang, K.
AU  - Zhao, J.
AU  - Yan, X.
TI  - Insider threat detection based on adaptive optimization DBN by grid search
PY  - 2019
C7  - 8823459
SP  - 173
EP  - 175
DO  - 10.1109/ISI.2019.8823459
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072986120&doi=10.1109%2FISI.2019.8823459&partnerID=40&md5=ca3f3c4a9a369dc66cf3b5796f60e359
AB  - Aiming at the problem that one-dimensional parameter optimization in insider threat detection using deep learning will lead to unsatisfactory overall performance of the model, an insider threat detection method based on adaptive optimization DBN by grid search is designed. This method adaptively optimizes the learning rate and the network structure which form the two-dimensional grid, and adaptively selects a set of optimization parameters for threat detection, which optimizes the overall performance of the deep learning model. The experimental results show that the method has good adaptability. The learning rate of the deep belief net is optimized to 0.6, the network structure is optimized to 6 layers, and the threat detection rate is increased to 98.794%. The training efficiency and the threat detection rate of the deep belief net are improved. © 2019 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Sun, D.
AU  - Wu, Z.
AU  - Wang, Y.
AU  - Lv, Q.
AU  - Hu, B.
TI  - Cyber Profiles Based Risk Prediction of Application Systems for Effective Access Control
PY  - 2019
T2  - Proceedings - International Symposium on Computers and Communications
VL  - 2019-June
C7  - 8969646
DO  - 10.1109/ISCC47284.2019.8969646
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078875921&doi=10.1109%2FISCC47284.2019.8969646&partnerID=40&md5=e516954d7cdc7517e2d82ed66c5cee30
AB  - Application systems maintain critical sensitive information of an enterprise and especially huge number of data with specific ownership. Unauthorized modification or deletion of data caused by cyber attacks may bring tremendous loses for enterprises. To reduce the damage of cyber attacks, existing techniques have been proposed to predict the potential risk of external attacks at the level of an enterprise, a user, or a machine. However, risk prediction has not been conducted at the level of application systems, which may suffer from external attacks or insider threats. This paper proposes a model based on machine learning to predict whether the application systems of an enterprise have the risk of unauthorized access by using a cyber profile. In particular, the cyber profile is composed of features extracted from the information of the three domains in cyberspace: Information Infrastructure domain, Data domain, and Application domain. The core idea of the model selects the most significant features that have a large impact on the occurrence of unauthorized access to application systems. At last, by using a limited number of selected features, high forecast accuracy is achieved. These results verify the effectiveness of the prediction model, which can potentially be exploited to guide the adjustment of access control policies for effective access control. © 2019 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Le, D.C.
AU  - Nur Zincir-Heywood, A.
TI  - Machine learning based insider threat modelling and detection
PY  - 2019
C7  - 8717892
SP  - 1
EP  - 6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066993633&partnerID=40&md5=8ac35c825584c2f070060775cac11d13
AB  - Recently, malicious insider attacks represent one of the most damaging threats to companies and government agencies. This paper proposes a new framework in constructing a user-centered machine learning based insider threat detection system on multiple data granularity levels. System evaluations and analysis are performed not only on individual data instances but also on normal and malicious insiders, where insider scenario specific results and delay in detection are reported and discussed. Our results show that the machine learning based detection system can learn from limited ground truth and detect new malicious insiders with a high accuracy. © 2019 IFIP.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 55
ER  -

TY  - CONF
AU  - Alzhrani, K.
AU  - Alrasheedi, F.S.
AU  - Kateb, F.A.
AU  - Boult, T.E.
TI  - CNN with Paragraph to Multi-Sequence Learning for Sensitive Text Detection
PY  - 2019
C7  - 8769490
DO  - 10.1109/CAIS.2019.8769490
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073915305&doi=10.1109%2FCAIS.2019.8769490&partnerID=40&md5=092e88d87a07d2da23a573e096f41428
AB  - The problem of sensitive information leaks became apparent in the recent infamous security breaches such as WikiLeaks, DNC emails, and Panama Papers. Detecting sensitive texts on the fly enhances the capabilities of security solutions' to monitor and protect critical information flow within the network. Automated text security classification is relatively a new research area, where sensitive texts are marked with labels as Secret, Confidential, and Unclassified with no human interaction. This paper examines the performance of deep learning networks in detecting the sensitivity levels of a given text. In deep text classification networks, regardless of text samples length, each paragraph/sentence is represented by a single sequence. We propose techniques to expand training set size, minimize the number of padding character in sequences, and lower inputs' dimensionality through learning from long paragraphs' segments as independent instances. Also, we introduce a wide variation of Convolution Neural Networks (CNN) network evaluated on four large sets of U. S. embassy's diplomatic cables. We are not aware of any paper that applied deep networks to sensitive text classification. Thus, we further evaluate our multi-sequencing technique and CNN network on well-researched non-sensitive text corpora. Our approach outperformed the state-of-the-art models on non-sensitive text datasets and competed with other traditional classifiers on the sensitive text datasets. © 2019 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Oh, J.
AU  - Kim, T.H.
AU  - Lee, K.H.
TI  - Advanced insider threat detection model to apply periodic work atmosphere
PY  - 2019
T2  - KSII Transactions on Internet and Information Systems
VL  - 13
IS  - 3
SP  - 1722
EP  - 1737
DO  - 10.3837/tiis.2019.03.035
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065568630&doi=10.3837%2Ftiis.2019.03.035&partnerID=40&md5=4f58e1e93c7c4c63a8b5f44289ec8663
AB  - We developed an insider threat detection model to be used by organizations that repeat tasks at regular intervals. The model identifies the best combination of different feature selection algorithms, unsupervised learning algorithms, and standard scores. We derive a model specifically optimized for the organization by evaluating each combination in terms of accuracy, AUC (Area Under the Curve), and TPR (True Positive Rate). In order to validate this model, a four-year log was applied to the system handling sensitive information from public institutions. In the research target system, the user log was analyzed monthly based on the fact that the business process is processed at a cycle of one year, and the roles are determined for each person in charge. In order to classify the behavior of a user as abnormal, the standard scores of each organization were calculated and classified as abnormal when they exceeded certain thresholds. Using this method, we proposed an optimized model for the organization and verified it. © 2019 KSII.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 7
ER  -

TY  - CONF
TI  - ACM International Conference Proceeding Series
PY  - 2019
T2  - ACM International Conference Proceeding Series
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061292423&partnerID=40&md5=ce99c4ff5c7cbbfc8b93d1c5684a943c
AB  - The proceedings contain 57 papers. The topics discussed include: insider threat detection with long short-term memory; a survey of anonymity of cryptocurrencies; decision model for the security and utility risk evaluation (SURE) framework; information associations for multi-domain applications; receipt-free, universally and individually verifiable poll attendance; overcoming the bottlenecks in next-generation heterogeneous vehicular networks - is SDN the optimal solution?; an adaptive and autonomous LoRa gateway for throughput optimization; multi-agent-based system to model and simulate the emergency response in metropolis; impact of network fairness on the performance of parallel systems; and using visualization to illustrate machine learning models for genomic data.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Saaudi, A.
AU  - Tong, Y.
AU  - Farkas, C.
TI  - Probabilistic Graphical Model on Detecting Insiders: Modeling with SGD-HMM
PY  - 2019
T2  - International Conference on Information Systems Security and Privacy
SP  - 461
EP  - 470
DO  - 10.5220/0007404004610470
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176289605&doi=10.5220%2F0007404004610470&partnerID=40&md5=4b590caa00e027a4c451b3f1c1ddb592
AB  - This paper presents a novel approach to detect malicious behaviors in computer systems. We propose the use of varying granularity levels to represent users' log data: Session-based, Day-based, and Week-based. A user's normal behavior is modeled using a Hidden Markov Model. The model is used to detect any deviation from the normal behavior. We also propose a Sliding Window Technique to identify malicious activity effectively by considering the near history of user activity. We evaluated our results using Receiver Operating Characteristic curves (or ROC curves). Our evaluation shows that the results are superior to existing research by improving the detection ability and reducing the false positive rate. Combining sliding window technique with session-based system gives a fast detection performance. © 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Liu, L.
AU  - Chen, C.
AU  - Zhang, J.
AU  - De Vel, O.
AU  - Xiang, Y.
TI  - Unsupervised Insider Detection Through Neural Feature Learning and Model Optimisation
PY  - 2019
T2  - Lecture Notes in Computer Science
VL  - 11928 LNCS
SP  - 18
EP  - 36
DO  - 10.1007/978-3-030-36938-5_2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076997367&doi=10.1007%2F978-3-030-36938-5_2&partnerID=40&md5=c75f05b1c3d8e2dd5166d30950db56c2
AB  - The insider threat is a significant security concern for both organizations and government sectors. Traditional machine learning-based insider threat detection approaches usually rely on domain focused feature engineering, which is expensive and impractical. In this paper, we propose an autoencoder-based approach aiming to automatically learn the discriminative features of the insider behaviours, thus alleviating security experts from tedious inspection tasks. Specifically, a Word2vec model is trained with a corpus transformed from various security logs to generate event representations. Instead of manually selecting Word2vec model parameters, we develop an autoencoder-based “parameter tuner” for the model to produce an optimal feature set. Then, the detection is undertaken by examining the reconstruction error of an autoencoder for each transformed event using the Carnegie Mellon University (CMU) CERT Programs insider threat database. Experimental results demonstrate that our proposed approach could achieve an extremely low false-positive rate (FPR) with all malicious events identified. © 2019, Springer Nature Switzerland AG.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 16
ER  -

TY  - CONF
AU  - Yuan, F.
AU  - Shang, Y.
AU  - Liu, Y.
AU  - Cao, Y.
AU  - Tan, J.
TI  - Attention-Based LSTM for Insider Threat Detection
PY  - 2019
T2  - Communications in Computer and Information Science
VL  - 1116 CCIS
SP  - 192
EP  - 201
DO  - 10.1007/978-981-15-0871-4_15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076792633&doi=10.1007%2F978-981-15-0871-4_15&partnerID=40&md5=cc3df0fa33a0503cf43047080684696a
AB  - Insider threat is an important cyber security issue for businesses and organizations. Existing insider threat detection methods can be roughly divided into two categories, statistical features based detection methods and action sequence based detection methods. The first kind of method aggregates all actions that a user has performed over one day and uses these aggregated features to find insider threat. This kind of coarse-grained analytics of user behavior may miss anomalous behavior happening within that day. The second kind of method overcomes the coarser-grained problem and uses fine-grained detection to identify insider threat through user actions. However, the second kind of method considers all user operations to be equally important, without highlighting malicious user actions. To solve this problem, we present an attention-based Long Short-Term Memory (LSTM) model to detect insider threat. In our model, we apply the LSTM to capture the sequential information of user action sequence and employ an attention layer that can learn which user actions contribute more to insider threat detection. Extensive studies are conducted on the public dataset of insider threat. Our results demonstrate that the proposed model outperforms other deep learning models and can successfully identify insider threat. © 2019, Springer Nature Singapore Pte Ltd.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 17
ER  -

TY  - JOUR
TI  - 10th International Conference on Applications and Techniques in Information Security, ATIS 2019
PY  - 2019
T2  - Communications in Computer and Information Science
VL  - 1116 CCIS
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076772010&partnerID=40&md5=4cdaeaafdc0d58cd82e67cf3b7efbf5d
AB  - The proceedings contain 24 papers. The special focus in this conference is on Applications and Techniques in Information Security. The topics include: Chaotic Map Based Key Generation and Realistic Power Allocation Technique for Secure MU-MIMO Wireless System; a Survey of Machine Learning Techniques Used to Combat Against the Advanced Persistent Threat; Subtree Hypergraph-Based Attack Detection Model for Signature Matching over SCADA HMI; Computational CBGSA – SVM Model for Network Based Intrusion Detection System; Attention-Based LSTM for Insider Threat Detection; Cog-SDN: Mitigation Mechanism for Distributed Denial of Service Attacks in Software Defined Networks; password Strength Estimators Trained on the Leaked Password Lists; cellular Automata Based Key Stream Generator – A Reconfigurable Hardware Approach; Hardware Trojan on SIMON Architecture for Key Retrieval; an Image Mathcrypt - A Flawless Security via Flawed Image; privacy-Preserving Authentication Scheme Using Reduced-Advanced Encryption Standard for Vehicular Ad Hoc Network; On the Security of the Double-Block-Length Hash Function NCASH; tele-Transmission of Secured Prefrontal Cortex Information Records for Remote Health Care; Encryption by Heart (EbH) for Secured Data Transmission and CNN Based EKG Signal Classification of Arrhythmia with Normal Data; ripping the Fabric: Attacks and Mitigations on Hyperledger Fabric; Secure ATM Device Design by Control Command Verification; construction of Two Dimensional Cubic-Tent-Sine Map for Secure Image Transmission; confused Memory Read Attracts Synthetic Diffusion on the Fly – A Lightweight Image Encryption for IoT Platform; Insider Attacks on Zigbee Based IoT Networks by Exploiting AT Commands; a Survey on Various Integrity Verification Schemes on the Data Outsourced to Cloud Storage.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Saaudi, A.
AU  - Tong, Y.
AU  - Farkas, C.
TI  - Probabilistic graphical model on detecting insiders: Modeling with SGD-HMM
PY  - 2019
SP  - 461
EP  - 470
DO  - 10.5220/0007404004610470
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064627285&doi=10.5220%2F0007404004610470&partnerID=40&md5=19df1a24ac71cb578b1f365b01ff554a
AB  - This paper presents a novel approach to detect malicious behaviors in computer systems. We propose the use of varying granularity levels to represent users' log data: Session-based, Day-based, andWeek-based. A user's normal behavior is modeled using a Hidden Markov Model. The model is used to detect any deviation from the normal behavior. We also propose a Sliding Window Technique to identify malicious activity effectively by considering the near history of user activity. We evaluated our results using Receiver Operating Characteristic curves (or ROC curves). Our evaluation shows that the results are superior to existing research by improving the detection ability and reducing the false positive rate. Combining sliding window technique with sessionbased system gives a fast detection performance. © 2019 by SCITEPRESS - Science and Technology Publications, Lda.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Saaudi, A.
AU  - Al-Ibadi, Z.
AU  - Tong, Y.
AU  - Farkas, C.
TI  - Insider threats detection using CNN-LSTM model
PY  - 2018
C7  - 8947634
SP  - 94
EP  - 99
DO  - 10.1109/CSCI46756.2018.00025
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078572054&doi=10.1109%2FCSCI46756.2018.00025&partnerID=40&md5=44de917121b43fa525b71f6a515d8cfb
AB  - Malicious insider activities threaten various govern-ment agencies and private organizations. This paper presents a novel approach to detect malicious behaviors. We propose the use of a granularity level to represent users' log data: textual session-based data samples. The user's behaviors are modeled using character embeddings and a deep learning model that consists of CNN and LSTM. Character embeddings are used to represent the input samples. Then, a convolution layer is used to capture local tri-gram features from the input samples, followed by an LSTM layer to consider the order of these given features (tri-grams). We conduct experiments using several variations of model architectures with no handcrafted features. The proposed model is evaluated with a subset of CERT Insider Threat dataset, r4.2. The result shows that performance improved with high precision and recall values. © 2018 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 18
ER  -

TY  - JOUR
AU  - Buede, D.M.
AU  - Axelrad, E.T.
AU  - Brown, D.P.
AU  - Hudson, D.W.
AU  - Laskey, K.B.
AU  - Sticha, P.J.
AU  - Thomas, J.L.
TI  - Inference enterprise models: An approach to organizational performance improvement
PY  - 2018
T2  - Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery
VL  - 8
IS  - 6
C7  - e1277
DO  - 10.1002/widm.1277
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051049363&doi=10.1002%2Fwidm.1277&partnerID=40&md5=d0fbda4ae9689ee6c72fc1b69ba6b290
AB  - We demonstrate that our success in solving a set of increasingly complex challenge problems is associated with an inference enterprise (IE) using inference enterprise models (IEMs). As part of a sponsored research competition, we created a multimodeling inference enterprise modeling (MIEM) process to achieve winning scores on a spectrum of challenge problems related to insider threat detection. We present in general terms the motivation for and description of our MIEM solution. We then present the results of applying MIEM across a range of challenge problems, with a detailed illustration for one challenge problem. Finally, we discuss the science and promise of IEM and MIEM, including the applicability of MIEM to a spectrum of inference domains. This article is categorized under: Technologies > Machine Learning Algorithmic Development > Model Combining Technologies > Prediction. © 2018 The Authors. WIREs Data Mining and Knowledge Discovery published by Wiley Periodicals, Inc.
M3  - Review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 10
ER  -

TY  - CONF
AU  - Zhang, D.
AU  - Zheng, Y.
AU  - Wen, Y.
AU  - Xu, Y.
AU  - Wang, J.
AU  - Yu, Y.
AU  - Meng, D.
TI  - Role-based log analysis applying deep learning for insider threat detection
PY  - 2018
T2  - Proceedings of the ACM Conference on Computer and Communications Security
SP  - 18
EP  - 20
DO  - 10.1145/3267494.3267495
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056823366&doi=10.1145%2F3267494.3267495&partnerID=40&md5=3e49261958568491d850e9864d85253b
AB  - Insider threats have shown their great destructive power in information security and financial stability and have received widespread attention from governments and organizations. Traditional intrusion detection systems fail to be effective in insider attacks due to the lack of extensive knowledge for insider behavior patterns. Instead, a more sophisticated method is required to have a deeper understanding for activities that insiders communicate with the information system. In this paper, we design a classifier, a neural network model utilizing Long Short Term Memory (LSTM) to model user log as a natural language sequence and achieve role-based classification. LSTM Model can learn behavior patterns of different users by automatically extracting feature and detect anomalies when log patterns deviate from the trained model. To illustrate the effective of classification model, we design two experiments based on cmu dataset. Experimental evaluations have shown that our model can successfully distinguish different behavior pattern and detect malicious behavior. © 2018 Association for Computing Machinery.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 30
ER  -

TY  - CONF
AU  - Dutta, P.K.
AU  - Ryan, G.
AU  - Zieba, A.
AU  - Stolfo, S.J.
TI  - Simulated user bots: Real time testing of insider threat detection systems
PY  - 2018
C7  - 8424654
SP  - 228
EP  - 236
DO  - 10.1109/SPW.2018.00038
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052199415&doi=10.1109%2FSPW.2018.00038&partnerID=40&md5=93ddfb4b9753bbb2b14049d0008a9014
AB  - The insider threat is one of the most serious security problems faced by modern organizations. High profile cases demonstrate the serious consequences of successful attacks. The problem has been studied for many years, leading to a number of technologies and products that have been deployed widely in government and commercial enterprises. A fundamental question is: how well do these systems work? How may they be tested? How expensive are widely deployed monitoring infrastructures in terms of computational cost? Measurement of real systems, which are dynamic in nature, encounter unknown configuration bugs and have sensitivities to the vagaries of human nature and adversarial behavior, requires a formal means to continuously test and evaluate deployed detection systems. We present a framework to deploy in situ simulated user bots (SUBs) that can emulate the actions of real users. By creating a user account and by running a host in the enterprise network, a SUB can be introduced into an enterprise system that runs at a realistic pace and does not interfere with normal operations. Infusing malicious behavior into the SUB should be detected by the insider threat monitoring infrastructure. The SUB framework can be controlled to explore the limits of deployed systems and to test the effectiveness of insider evasion tactics, especially low and slow behaviors. We demonstrate our framework in a synthetic ecosystem as well as in a live enterprise deployment. We created a synthetic environment of users based on data collected in a West Point cadet study. Various machine learning based intrusion detection algorithms are used to validate the ability of the SUB framework to generate both normal and malicious users. In a live University network, we launched a number of attacks on its intrusion detection system and showcased the ability to devise malicious users. In addition, we further deployed low and slow attacks that perform malicious actions over an extended period of time and demonstrate how even a large enterprise is ill equipped to combat such attacks. © 2018 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 9
ER  -

TY  - JOUR
AU  - Tabash, K.A.
AU  - Happa, J.
TI  - Insider-threat detection using Gaussian Mixture Models and Sensitivity Profiles
PY  - 2018
T2  - Computers and Security
VL  - 77
SP  - 838
EP  - 859
DO  - 10.1016/j.cose.2018.03.006
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046159155&doi=10.1016%2Fj.cose.2018.03.006&partnerID=40&md5=ac199cb185249c957fb3b50867771d58
AB  - The insider threat is one of the most challenging problems to detect due to its complex nature and significant impact on organisations. Insiders pose a great threat on organisations due to their knowledge on the organisation and its security protocols, their authorised access to the organisation's resources, and the difficulty of discerning the behaviour of an insider threat from a normal employee's behavior (Gheyas and Abdallah, 2016). As a result, the insider-threat field faces the challenge of developing detection solutions that are able to detect threats without generating a great number of false positives, and are able to take into consideration the non-technical aspect of the problem. This paper introduces a novel automated anomaly detection method that uses Gaussian Mixture Models for modelling the normal behaviour of employees to detect anomalous behaviour that may be malicious. The paper also introduces a novel approach to insider-threat detection that capitalises on the knowledge of security experts during analysis using visual analytics and sensitivity profiles which is a novel approach to re-contextualise detection output by considering outside, qualitative, non-technical factors that analysts may be privy to, but not the detection method. A feasibility study with experts in threat detection was conducted to evaluate the detection performance of the proposed solution and its usability. The results demonstrate the success of designing a solution that builds on the knowledge of security experts during analysis and reduces the number of false positives generated by automated anomaly detection. The work presented in the paper also demonstrates the potential of introducing more methods for capitialising on the knowledge of security experts to improve the false negative rate, and the potential of designing sensitivity profiles. © 2018
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 39
ER  -

TY  - CONF
AU  - Lu, Y.
AU  - Huang, X.
AU  - Ma, Y.
AU  - Ma, M.
TI  - A weighted context graph model for fast data leak detection
PY  - 2018
T2  - Conference Record - International Conference on Communications
VL  - 2018-May
C7  - 8422280
DO  - 10.1109/ICC.2018.8422280
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050628176&doi=10.1109%2FICC.2018.8422280&partnerID=40&md5=b14984c363b3b46951503418162f275f
AB  - Data leakage prevention (DLP) uses a series of techniques to detect and prevent the sensitive data leakage caused by insider threat. Current detection methods either fail to achieve high accuracy toward transformed data or fail to reduce computational complexity. To ensure high detection accuracy and reduce computational complexity, we propose a Weighted Context Graph Model (WCGM) in this paper. The main goal of WCGM is three folds. First, the weighted context graph is proposed to build the contextual relation of data, based on which sub-graph matching method is used to calculate similarity features between tested data and pre-defined template. Second, machine learning algorithms are used to classify the tested data based on the similarity features of its context graphs. Third, privacy- preserving graph masking method is proposed to protect the data privacy of data holders. Extensive simulation results show that the proposed WCGM is able to achieve significant enhancement in terms of running time and accuracy. © 2018 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 9
ER  -

TY  - CONF
AU  - Meng, F.
AU  - Lou, F.
AU  - Fu, Y.
AU  - Tian, Z.
TI  - Deep learning based attribute classification insider threat detection for data security
PY  - 2018
C7  - 8411913
SP  - 576
EP  - 581
DO  - 10.1109/DSC.2018.00092
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051018957&doi=10.1109%2FDSC.2018.00092&partnerID=40&md5=df957e3741d2c4b1b75c3c36d47f4482
AB  - With the evolution of network threat, identifying threat from internal is getting more and more difficult. To detect malicious insiders, we move forward a step and propose a novel attribute classification insider threat detection method based on long short term memory recurrent neural networks (LSTM-RNNs). To achieve high detection rate, event aggregator, feature extractor, several attribute classifiers and anomaly calculator are seamlessly integrated into an end-to-end detection framework. Using the CERT insider threat dataset v6.2 and threat detection recall as our performance metric, experimental results validate that the proposed threat detection method greatly outperforms k-Nearest Neighbor, Isolation Forest, Support Vector Machine and Principal Component Analysis based threat detection methods. © 2018 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 59
ER  -

TY  - CONF
AU  - Hall, A.
AU  - Pitropakis, N.
AU  - Buchanan, W.J.
AU  - Sheykhkanloo, N.M.
TI  - Predicting Malicious Insider Threat Scenarios Using Organizational Data and a Heterogeneous Stack-Classifier
PY  - 2018
C7  - 8621922
SP  - 5034
EP  - 5039
DO  - 10.1109/BigData.2018.8621922
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062614245&doi=10.1109%2FBigData.2018.8621922&partnerID=40&md5=7f70e34bc79b7f3ab863346b76a0df1b
AB  - Insider threats continue to present a major challenge for the information security community. Despite constant research taking place in this area; a substantial gap still exists between the requirements of this community and the solutions that are currently available. This paper uses the CERT dataset r4.2 along with a series of machine learning classifiers to predict the occurrence of a particular malicious insider threat scenario - the uploading sensitive information to wiki leaks before leaving the organization. These algorithms are aggregated into a meta-classifier which has a stronger predictive performance than its constituent models. It also defines a methodology for performing pre-processing on organizational log data into daily user summaries for classification, and is used to train multiple classifiers. Boosting is also applied to optimise classifier accuracy. Overall the models are evaluated through analysis of their associated confusion matrix and Receiver Operating Characteristic (ROC) curve, and the best performing classifiers are aggregated into an ensemble classifier. This meta-classifier has an accuracy of 96.2% with an area under the ROC curve of 0.988. © 2018 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 21
ER  -

TY  - CONF
AU  - Elshafei, S.
AU  - Abdelnaby, A.
TI  - Using semantic variations in clustering insiders behavior
PY  - 2018
VL  - 2018-January
SP  - 1
EP  - 5
DO  - 10.1109/ISDFS.2018.8355394
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050975309&doi=10.1109%2FISDFS.2018.8355394&partnerID=40&md5=8674dcfb9c9320dc3906029414b56e89
AB  - We show a new clustering procedure which can be considered a first step in an insider threat detection framework. The procedure relies on plainly unsupervised mining of typical behavior of insiders. In other words, the ranking of an individual observation on the feature space is of minimal importance. We use a publicly available data set composed of truncated Unix commands issued by insiders. Evaluation of the algorithm output, defined as the ability of the algorithm to detect violations of the allowed behavior grouping, is conducted through comparisons with the ground truth provided with the data set used. © 2018 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Kim, D.-W.
AU  - Hong, S.-S.
AU  - Han, M.-M.
TI  - A study on classification of insider threat using markov chain model
PY  - 2018
T2  - KSII Transactions on Internet and Information Systems
VL  - 12
IS  - 4
SP  - 1887
EP  - 1898
DO  - 10.3837/tiis.2018.04.027
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046900557&doi=10.3837%2Ftiis.2018.04.027&partnerID=40&md5=0facea4ff5a0d5f1aa67fb9f33fcb4ea
AB  - In this paper, a method to classify insider threat activity is introduced. The internal threats help detecting anomalous activity in the procedure performed by the user in an organization. When an anomalous value deviating from the overall behavior is displayed, we consider it as an inside threat for classification as an inside intimidator. To solve the situation, Markov Chain Model is employed. The Markov Chain Model shows the next state value through an arbitrary variable affected by the previous event. Similarly, the current activity can also be predicted based on the previous activity for the insider threat activity. A method was studied where the change items for such state are defined by a transition probability, and classified as detection of anomaly of the inside threat through values for a probability variable. We use the properties of the Markov chains to list the behavior of the user over time and to classify which state they belong to. Sequential data sets were generated according to the influence of n occurrences of Markov attribute and classified by machine learning algorithm. In the experiment, only 15% of the Cert: insider threat dataset was applied, and the result was 97% accuracy except for NaiveBayes. As a result of our research, it was confirmed that the Markov Chain Model can classify insider threats and can be fully utilized for user behavior classification. © 2018 KSII.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 12
ER  -

TY  - CONF
AU  - Jiang, W.
AU  - Tian, Y.
AU  - Liu, W.
AU  - Liu, W.
TI  - An insider threat detection method based on user behavior analysis
PY  - 2018
T2  - IFIP Advances in Information and Communication Technology
VL  - 538
SP  - 421
EP  - 429
DO  - 10.1007/978-3-030-00828-4_43
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055681846&doi=10.1007%2F978-3-030-00828-4_43&partnerID=40&md5=75be1f6baa52bffb73225b2ec991bb3c
AB  - Insider threat has always been an important hidden danger of information system security, and the detection of insider threat is the main concern of information system organizers. Before the anomaly detection, the process of feature extraction often causes a part of information loss, and the detection of insider threats in a single time point often causes false positives. Therefore, this paper proposes a user behavior analysis model, by aggregating user behavior in a period of time, comprehensively characterizing user attributes, and then detecting internal attacks. Firstly, the user behavior characteristics are extracted from the multi-domain features extracted from the audit log, and then the XGBoost algorithm is used to train. The experimental results on a user behavior dataset show that the XGBoost algorithm can be used to identify the insider threats. The value of F-measure is up to 99.96% which is better than SVM and random forest algorithm. © IFIP International Federation for Information Processing 2018.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 20
ER  -

TY  - JOUR
TI  - 13th International Conference on Wireless Algorithms, Systems, and Applications, WASA 2018
PY  - 2018
T2  - Lecture Notes in Computer Science
VL  - 10874 LNCS
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049002824&partnerID=40&md5=2d58c5dedf515f2f5803741931dde36f
AB  - The proceedings contain 82 papers. The special focus in this conference is on Wireless Algorithms, Systems, and Applications. The topics include: Smart device fingerprinting based on webpage loading; trajectory prediction for ocean vessels base on K-order multivariate markov chain; experimental study on deployment of mobile edge computing to improve wireless video streaming quality; an efficient privacy-preserving data aggregation scheme for IoT; Improving security and stability of AODV with fuzzy neural network in VANET; exploiting aerial heterogeneous network for implementing wireless flight recorder; TOA estimation algorithm based on noncoherent detection in IR-UWB system; max-Min fairness scheme in wireless powered communication networks with multi-user cooperation; cancer-drug interaction network construction and drug target prediction based on multi-source data; A novel energy harvesting aware IEEE 802.11 power saving mechanism; Enabling efficient and fine-grained DNA similarity search with access control over encrypted cloud data; sampling based δ-approximate data aggregation in sensor equipped IoT networks; Poisoning machine learning based wireless IDSs via stealing learning model; signal-selective time difference of arrival estimation based on generalized cyclic correntropy in impulsive noise environments; iKey: An intelligent key system based on efficient inclination angle sensing techniques; Massive MIMO power allocation in millimeter wave networks; a detection-resistant covert timing channel based on geometric huffman coding; spark: A smart parking lot monitoring system; a hybrid model based on multi-dimensional features for insider threat detection; throughput analysis for energy harvesting cognitive radio networks with unslotted users; Interest-aware next POI recommendation for mobile social networks; a crowdsourcing-based wi-fi fingerprinting mechanism using un-supervised learning.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Yuan, F.
AU  - Cao, Y.
AU  - Shang, Y.
AU  - Liu, Y.
AU  - Tan, J.
AU  - Fang, B.
TI  - Insider threat detection with deep neural network
PY  - 2018
T2  - Lecture Notes in Computer Science
VL  - 10860 LNCS
SP  - 43
EP  - 54
DO  - 10.1007/978-3-319-93698-7_4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048985680&doi=10.1007%2F978-3-319-93698-7_4&partnerID=40&md5=19d4ed02f23115f344e66a321210e91c
AB  - Insider threat detection has attracted a considerable attention from the researchers and industries. Existing work mainly focused on applying machine-learning techniques to detecting insider threat. However, this work requires “feature engineering” which is difficult and time-consuming. As we know, the deep learning technique can automatically learn powerful features. In this paper, we present a novel insider threat detection method with Deep Neural Network (DNN) based on user behavior. Specifically, we use the LSTM-CNN framework to find user’s anomalous behavior. First, similar to natural language modeling, we use the Long Short Term Memory (LSTM) to learn the language of user behavior through user actions and extract abstracted temporal features. Second, the extracted features are converted to the fixed-size feature matrices and the Convolutional Neural Network (CNN) use these fixed-size feature matrices to detect insider threat. We conduct experiments on a public dataset of insider threats. Experimental results show that our method can successfully detect insider threat and we obtained AUC = 0.9449 in best case. © Springer International Publishing AG, part of Springer Nature 2018.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 126
ER  -

TY  - JOUR
AU  - Zhang, J.
AU  - Chen, Y.
AU  - Ju, A.
TI  - Insider threat detection of adaptive optimization DBN for behavior logs
PY  - 2018
T2  - Turkish Journal of Electrical Engineering and Computer Sciences
VL  - 26
IS  - 2
SP  - 792
EP  - 802
DO  - 10.3906/elk-1706-163
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045020600&doi=10.3906%2Felk-1706-163&partnerID=40&md5=4a079cfadee3c2f2308188a54118b8f4
AB  - For the problems of insider threats such as great harm due to damage and resultant loss, difficulty in extracting abnormal behavior features of insiders because of transparency and concealment, and low detection rate, an insider threat detection model using adaptive optimization DBN for behavior logs is put forward. The model carries out deep learning based on the integrated and normalized behavior logs to fully learn normal and abnormal behavior features of insiders to form optimal representations of the behavior features of insiders. The experimental results show that the multiple-hidden-layer deep learning model can fully learn the behavior features of insiders, improving the detection rate of insider threat. Particularly, the adaptive optimization method of the golden section is better than that using the dichotomy method, which can increase the threat detection rate of the DBN model to 97.872%, with more significant advantages. © TUBITAK.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 16
ER  -

TY  - CONF
TI  - 2017 IEEE International Conference on Intelligence and Security Informatics: Security and Big Data, ISI 2017
PY  - 2017
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030239883&partnerID=40&md5=56089c3f71a00597d63f8cbe266ac3ae
AB  - The proceedings contain 54 papers. The topics discussed include: proactive information security behavior and individual creativity: effects of group culture and decentralized IT governance; a novel approach for analysis of attack graph; identifying mobile malware and key threat actors in online hacker forums for proactive cyber threat intelligence; linking social network accounts by modeling user spatiotemporal habits; raising flags: detecting covert storage channels using relative entropy; clustering and monitoring edge behaviour in enterprise network traffic; phishing detection: a recent intelligent machine learning comparison based on models content and features; alignment-free indexing-first-one hashing with bloom filter integration; impact of human mobility on police allocation; behavior enhanced deep Bot detection in social media; topic and user based refinement for competitive perspective identification; resolving reflection methods in android applications; the impact of different perceived dimensions of mobile media app users on customer commitment and customer recommendation; analyzing multimodal public sentiment based on hierarchical semantic attentional network; and wavelet transform and unsupervised machine learning to detect insider threat on cloud file-sharing.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
TI  - Proceedings - 2017 IEEE International Conference on Cloud Computing in Emerging Markets, CCEM 2017
PY  - 2017
VL  - 2018-January
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172743374&partnerID=40&md5=4c60d0bf8ce62db6615175293f5aaaa5
AB  - The proceedings contain 18 papers. The topics discussed include: user behaviour anomaly detection in multidimensional data; cloud based big data platform for image analytics; cognitive model for smarter dispatch system/elevator; experimental exploration of support vector machine for cancer cell classification; cloud-based framework for cancelable biometric system; insider threat detection with face recognition and KNN user classification; a dynamic and energy efficient greedy scheduling algorithm for cloud data centers; a robotic cloud advisory service; cloud-based system for supervised classification of plant diseases using convolutional neural networks; a network aware energy efficient offloading algorithm for mobile cloud computing over 5g network; interoperability based resource management in cloud computing by adaptive dimensional search; predictive visual analysis of twitter big data originated from cloud using machine learning algorithms; SCAuth: selective cloud user authorization for ciphertext-policy attribute-based access control; CANTAV: a cloud centric framework for navigation and control of autonomous road vehicles; application migration architecture for cross clouds analysis on the strategies methods and frameworks; and a model for hybrid cloud integration: with a case study for IT service management (ITSM).
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Sarma, M.S.
AU  - Srinivas, Y.
AU  - Abhiram, M.
AU  - Ullala, L.
AU  - Prasanthi, M.S.
AU  - Rao, J.R.
TI  - Insider threat detection with face recognition and KNN user classification
PY  - 2017
VL  - 2018-January
SP  - 39
EP  - 44
DO  - 10.1109/CCEM.2017.16
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049617644&doi=10.1109%2FCCEM.2017.16&partnerID=40&md5=9b3b3094eb92431bcc91c5a48802707e
AB  - Information Security in cloud storage is a key trepidation with regards to Degree of Trust and Cloud Penetration. Cloud user community needs to ascertain performance and security via QoS. Numerous models have been proposed [2] [3] [6][7] to deal with security concerns. Detection and prevention of insider threats are concerns that also need to be tackled. Since the attacker is aware of sensitive information, threats due to cloud insider is a grave concern. In this paper, we have proposed an authentication mechanism, which performs authentication based on verifying facial features of the cloud user, in addition to username and password, thereby acting as two factor authentication. New QoS has been proposed which is capable of monitoring and detection of insider threats using Machine Learning Techniques. KNN Classification Algorithm has been used to classify users into legitimate, possibly legitimate, possibly not legitimate and not legitimate groups to verify image authenticity to conclude, whether there is any possible insider threat. A threat detection model has also been proposed for insider threats, which utilizes Facial recognition and Monitoring models. Security Method put forth in [6] [7] is honed to include threat detection QoS to earn higher degree of trust from cloud user community. As a recommendation, Threat detection module should be harnessed in private cloud deployments like Defense and Pharma applications. Experimentation has been conducted using open source Machine Learning libraries and results have been attached in this paper. © 2017 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 32
ER  -

TY  - CONF
TI  - IWSPA 2017 - Proceedings of the 3rd ACM International Workshop on Security and Privacy Analytics, co-located with CODASPY 2017
PY  - 2017
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018260088&partnerID=40&md5=1dc7e934ec5dcb914f636a655ec3ca45
AB  - The proceedings contain 10 papers. The topics discussed include: non-interactive (t, n)-incidence counting from differentially private indicator vectors; an internal/insider threat score for data loss prevention and detection; model-based cluster analysis for identifying suspicious activity sequences in software; identifying key cyber-physical terrain; continuous authentication using behavioral biometrics; analysis of causative attacks against SVMs learning from data streams; MCDefender: toward effective cyberbullying defense in mobile online social networks; tracing the arc of smartphone application security; predicting exploitation of disclosed software vulnerabilities using open-source data; what's in a URL: fast feature extraction and malicious URL detection; emulator vs real phone: Android malware detection using machine learning; and feature cultivation in privileged information-augmented detection.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Tuor, A.
AU  - Kaplan, S.
AU  - Hutchinson, B.
AU  - Nichols, N.
AU  - Robinson, S.
TI  - Deep learning for unsupervised insider threat detection in structured cybersecurity data streams
PY  - 2017
VL  - WS-17-01 - WS-17-15
SP  - 224
EP  - 234
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046103696&partnerID=40&md5=3d46268ca6592e08c93af802b75f57e3
AB  - Analysis of an organization's computer network activity is a key component of early detection and mitigation of insider threat, a growing concern for many organizations. Raw system logs are a prototypical example of streaming data that can quickly scale beyond the cognitive power of a human analyst. As a prospective filter for the human analyst, we present an online unsupervised deep learning approach to detect anomalous network activity from system logs in real time. Our models decompose anomaly scores into the contributions of individual user behavior features for increased interpretability to aid analysts reviewing potential cases of insider threat. Using the CERT Insider Threat Dataset v6.2 and threat detection recall as our performance metric, our novel deep and recurrent neural network models outperform Principal Component Analysis, Support Vector Machine and Isolation Forest based anomaly detection baselines. For our best model, the events labeled as insider threat activity in our dataset had an average anomaly score in the 95.53 percentile, demonstrating our approach's potential to greatly reduce analyst workloads. © Copyright 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 169
ER  -

TY  - JOUR
TI  - 13th IFIP WG 11.9 International Conference on Digital Forensics, 2017
PY  - 2017
T2  - IFIP Advances in Information and Communication Technology
VL  - 511
SP  - 1
EP  - 303
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029410489&partnerID=40&md5=1dc9262f81aa875e909d5ac44563ddf5
AB  - The proceedings contain 16 papers. The special focus in this conference is on Digital Forensics. The topics include: A model for digital evidence admissibility assessment; evaluating the authenticity of smartphone evidence; forensic evaluation of an amazon fire TV stick; detecting anomalous programmable logic controller events using machine learning; a forensic methodology for software-defined network switches; identifying evidence for cloud forensic analysis; digital forensic implications of collusion attacks on the lightning network; insider threat detection using time-series-based raw disk forensic analysis; anti-forensic threat modeling; a behavior-based approach for malware detection; categorizing mobile device malware based on system side-effects; semantic video carving using perceptual hashing and optical flow; detecting fraudulent bank checks; automated collection and correlation of file provenance information; using personal information in targeted grammar-based probabilistic password attacks.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Alzhrani, K.
AU  - Rudd, E.M.
AU  - Boult, T.E.
AU  - Chow, C.E.
TI  - Automated big text security classification
PY  - 2016
C7  - 7745451
SP  - 103
EP  - 108
DO  - 10.1109/ISI.2016.7745451
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85004065352&doi=10.1109%2FISI.2016.7745451&partnerID=40&md5=ccfb6435c5ae1b792c00191d20bc4c52
AB  - In recent years, traditional cybersecurity safeguards have proven ineffective against insider threats. Famous cases of sensitive information leaks caused by insiders, including the WikiLeaks release of diplomatic cables and the Edward Snowden incident, have greatly harmed the U.S. government's relationship with other governments and with its own citizens. Data Leak Prevention (DLP) is a solution for detecting and preventing information leaks from within an organization's network. However, state-of-Art DLP detection models are only able to detect very limited types of sensitive information, and research in the field has been hindered due to the lack of available sensitive texts. Many researchers have focused on document-based detection with artificially labeled 'confidential documents' for which security labels are assigned to the entire document, when in reality only a portion of the document is sensitive. This type of whole-document based security labeling increases the chances of preventing authorized users from accessing non-sensitive information within sensitive documents. In this paper, we introduce Automated Classification Enabled by Security Similarity (ACESS), a new and innovative detection model that penetrates the complexity of big text security classification/detection. To analyze the ACESS system, we constructed a novel dataset, containing formerly classified paragraphs from diplomatic cables made public by the WikiLeaks organization. To our knowledge this paper is the first to analyze a dataset that contains actual formerly sensitive information annotated at paragraph granularity. © 2016 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 18
ER  -

TY  - CONF
AU  - Rashid, T.
AU  - Agrafiotis, I.
AU  - Nurse, J.R.C.
TI  - A new take on detecting insider threats: Exploring the use of Hidden Markov Models
PY  - 2016
SP  - 47
EP  - 56
DO  - 10.1145/2995959.2995964
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001907693&doi=10.1145%2F2995959.2995964&partnerID=40&md5=00ccc1b521f19582c360a5a59d358879
AB  - The threat that malicious insiders pose towards organisations is a significant problem. In this paper, we investigate the task of detecting such insiders through a novel method of modelling a user's normal behaviour in order to detect anomalies in that behaviour which may be indicative of an attack. Specifically, we make use of Hidden Markov Models to learn what constitutes normal behaviour, and then use them to detect significant deviations from that behaviour. Our results show that this approach is indeed successful at detecting insider threats, and in particular is able to accurately learn a user's behaviour. These initial tests improve on existing research and may provide a useful approach in addressing this part of the insider-threat challenge. © 2016 ACM.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 165
ER  -

TY  - CONF
AU  - Agrafiotis, I.
AU  - Erola, A.
AU  - Happa, J.
AU  - Goldsmith, M.
AU  - Creese, S.
TI  - Validating an Insider Threat Detection System: A Real Scenario Perspective
PY  - 2016
C7  - 7527781
SP  - 286
EP  - 295
DO  - 10.1109/SPW.2016.36
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008627484&doi=10.1109%2FSPW.2016.36&partnerID=40&md5=936cf304f26247a68f23b229fade8269
AB  - There exists unequivocal evidence denoting the dire consequences which organisations and governmental institutions face from insider threats. While the in-depth knowledge of the modus operandi that insiders possess provides ground for more sophisticated attacks, organisations are ill-equipped to detect and prevent these from happening. The research community has provided various models and detection systems to address the problem, but the lack of real data due to privacy and ethical issues remains a significant obstacle for validating and designing effective and scalable systems. In this paper, we present the results and our experiences from applying our detection system into a multinational organisation, the approach followed to abide with the ethical and privacy considerations and the lessons learnt on how the validation process refined the system in terms of effectiveness and scalability. © 2016 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 16
ER  -

TY  - JOUR
AU  - Wen, Y.
AU  - Wang, W.-P.
AU  - Meng, D.
TI  - Mining user cross-domain behavior patterns for insider threat detection
PY  - 2016
T2  - Jisuanji Xuebao/Chinese Journal of Computers
VL  - 39
IS  - 8
SP  - 1555
EP  - 1569
DO  - 10.11897/SP.J.1016.2016.01555
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982239234&doi=10.11897%2FSP.J.1016.2016.01555&partnerID=40&md5=a21dc768c9e05893222c25e6b0be7bba
AB  - User behavior analysis is an important problem in the system security research filed. Recently existing work mainly focused on the single pattern analysis of user single-domain behavior, which needed to rely on expert's knowledge and user background knowledge. Thus, these work were not suitable for user behavior pattern analysis in the multi-domain scenarios. In this paper, we proposed a novel method for the user cross-domain behavior analysis. Our method could identify multi-pattern of user cross-domain behavior. Moreover, our method was a completely data driven resolution which did not need any expert's knowledge and user background knowledge. At last, we also designed an insider attack detection method based on our user behavior analysis approach. In our experiment, we used our methods to analyze and detect five user audit logs in real environment. The experimental results showed that our user behavior analysis method was effective on the multi-pattern analysis of the user cross-domain behavior in the multi-domain scenarios, and our insider attack detection method was better than two existing solutions: a single-domain detection method and a single patterns based detection method. © 2016, Science Press. All right reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 9
ER  -

TY  - CONF
AU  - Hsieh, C.-H.
AU  - Lai, C.-M.
AU  - Mao, C.-H.
AU  - Kao, T.-C.
AU  - Lee, K.-C.
TI  - AD2: Anomaly detection on active directory log data for insider threat monitoring
PY  - 2016
T2  - Proceedings - International Carnahan Conference on Security Technology
VL  - 2015-January
C7  - 7389698
SP  - 287
EP  - 292
DO  - 10.1109/CCST.2015.7389698
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964814509&doi=10.1109%2FCCST.2015.7389698&partnerID=40&md5=66b4dfdad51db6062744a9adeb694433
AB  - What you see is not definitely believable is not a rare case in the cyber security monitoring. However, due to various tricks of camouflages, such as packing or virutal private network (VPN), detecting «advanced persistent threat»(APT) by only signature based malware detection system becomes more and more intractable. On the other hand, by carefully modeling users' subsequent behaviors of daily routines, probability for one account to generate certain operations can be estimated and used in anomaly detection. To the best of our knowledge so far, a novel behavioral analytic framework, which is dedicated to analyze Active Directory domain service logs and to monitor potential inside threat, is now first proposed in this project. Experiments on real dataset not only show that the proposed idea indeed explores a new feasible direction for cyber security monitoring, but also gives a guideline on how to deploy this framework to various environments. © 2015 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 18
ER  -

TY  - CONF
TI  - Proceedings - 2016 IEEE 17th International Conference on Information Reuse and Integration, IRI 2016
PY  - 2016
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991239924&partnerID=40&md5=2542846b38b78e09d845c6c56cf651ab
AB  - The proceedings contain 83 papers. The topics discussed include: an automatic approach for discovering and geocoding locations in domain-specific web data; a machine learning approach to improve the accuracy of GPS-based map-matching algorithms; modeling integration and reuse of heterogeneous terminologies in faceted browsing systems; anomaly detection techniques for database protection against insider threats; a data driven approach for the science of cyber security: challenges and directions; reusable meta-models for crowdsourcing driven elastic systems; a novel method for fraudulent medicare claims detection from expected payment deviations; a risk-benefit driven architecture for personal data release; improving the utility of anonymized datasets through dynamic evaluation of generalization hierarchies; a formal language for writing contracts; Spekl: a layered system for specification authoring, sharing, and usage; modular verification of termination and execution time bounds using separation logic; modelling complex timing requirements with refinement; predicting students' behavioral patterns in university networks for efficient bandwidth allocation: a hybrid data mining method; cross-domain sentiment analysis: an empirical investigation; and clustering web pages based on structure and style similarity; classifying questions into fine-grained categories using topic enriching.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Yang, P.
AU  - He, J.
TI  - Model multiple heterogeneity via hierarchical multi-latent space learning
PY  - 2015
T2  - Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining
VL  - 2015-August
SP  - 1375
EP  - 1384
DO  - 10.1145/2783258.2783330
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954102722&doi=10.1145%2F2783258.2783330&partnerID=40&md5=8ca3da5a39845dc6fbae5eb393399677
AB  - In many real world applications such as satellite image analysis, gene function prediction, and insider threat detection, the data collected from heterogeneous sources often exhibit multiple types of heterogeneity, such as task heterogeneity, view heterogeneity, and label heterogeneity. To address this problem, we propose a Hierarchical Multi-Latent Space (HiMLS) learning approach to jointly model the triple types of heterogeneity. The basic idea is to learn a hierarchical multi-latent space by which we can simultaneously leverage the task relatedness, view consistency and the label correlations to improve the learning performance. We first propose a multi-latent space framework to model the complex heterogeneity, which is used as a building block to stack up a multi-layer structure so as to learn the hierarchical multilatent space. In such a way, we can gradually learn the more abstract concepts in the higher level. Then, a deep learning algorithm is proposed to solve the optimization problem. The experimental results on various data sets show the effectiveness of the proposed approach.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 13
ER  -

TY  - JOUR
AU  - Azaria, A.
AU  - Richardson, A.
AU  - Kraus, S.
AU  - Subrahmanian, V.S.
TI  - Behavioral analysis of insider threat: A survey and bootstrapped prediction in imbalanced data
PY  - 2014
T2  - IEEE Transactions on Computational Social Systems
VL  - 1
IS  - 2
C7  - 7010900
SP  - 135
EP  - 155
DO  - 10.1109/TCSS.2014.2377811
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921930635&doi=10.1109%2FTCSS.2014.2377811&partnerID=40&md5=a998d6a21fde48a14ba4b9efc8f6320f
AB  - The problem of insider threat is receiving increasing attention both within the computer science community as well as government and industry. This paper starts by presenting a broad, multidisciplinary survey of insider threat capturing contributions from computer scientists, psychologists, criminologists, and security practitioners. Subsequently, we present the behavioral analysis of insider threat (BAIT) framework, in which we conduct a detailed experiment involving 795 subjects on Amazon Mechanical Turk (AMT) in order to gauge the behaviors that real human subjects follow when attempting to exfiltrate data from within an organization. In the real world, the number of actual insiders found is very small, so supervised machine-learning methods encounter a challenge. Unlike past works, we develop bootstrapping algorithms that learn from highly imbalanced data, mostly unlabeled, and almost no history of user behavior from an insider threat perspective. We develop and evaluate seven algorithms using BAIT and show that they can produce a realistic (and acceptable) balance of precision and recall. © 2014 IEEE.
M3  - Review
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 118
ER  -

TY  - JOUR
AU  - Eldardiry, H.
AU  - Sricharan, K.
AU  - Liu, J.
AU  - Hanley, J.
AU  - Price, B.
AU  - Brdiczka, O.
AU  - Bart, E.
TI  - Multi-source fusion for anomaly detection: Using across-domain and across-time peer-group consistency checks
PY  - 2014
T2  - Journal of Wireless Mobile Networks, Ubiquitous Computing, and Dependable Applications
VL  - 5
IS  - 2
SP  - 39
EP  - 58
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903788582&partnerID=40&md5=721af021bc95d5a9682c866cd9e7037b
AB  - We present robust anomaly detection in multi-dimensional data. We describe information fusion across multiple levels in a layered architecture to ensure accurate and reliable detection of anomalies from heterogeneous data. We consider the problem of detecting anomalous entities (e.g., people) from observation data (e.g., activities) gathered from multiple contexts or information sources over time. We propose two anomaly detection methods. The first method seeks to identify anomalous behavior that blends within each information source but is inconsistent across sources. A supervised learning approach detects the blend-in anomalies manifested as across-information source inconsistencies. The second method identifies unusual changes in behavior over time using a Markov model approach. Finally, we present a fusion approach that integrates evidence from both methods to improve the accuracy and robustness of the anomaly detection system. We illustrate the performance of our proposed approaches on an insider threat detection problem using a real-world work-practice data set.
M3  - Article
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 17
ER  -

TY  - CONF
AU  - Gupta, S.
AU  - Hanson, C.
AU  - Gunter, C.A.
AU  - Frank, M.
AU  - Liebovitz, D.
AU  - Malin, B.
TI  - Modeling and detecting anomalous topic access
PY  - 2013
C7  - 6578795
SP  - 100
EP  - 105
DO  - 10.1109/ISI.2013.6578795
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883420860&doi=10.1109%2FISI.2013.6578795&partnerID=40&md5=31b4c4abfe3572928b2145e403c2b7f5
AB  - There has been considerable success in developing strategies to detect insider threats in information systems based on what one might call the random object access model or ROA. This approach models illegitimate users as ones who randomly access records. The goal is to use statistics, machine learning, knowledge of workflows and other techniques to support an anomaly detection framework that finds such users. In this paper we introduce and study a random topic access model or RTA aimed at users whose access may be illegitimate but is not fully random because it is focused on common semantic themes. We argue that this model is appropriate for a meaningful range of attacks and develop a system based on topic summarization that is able to formalize the model and provide anomalous user detection effectively for it. To this end, we use healthcare as an example and propose a framework for evaluating the ability to recognize various types of random users called random topic access detection or RTAD. Specifically, we utilize a combination of Latent Dirichlet Allocation (LDA), for feature extraction, a k-nearest neighbor (k-NN) algorithm for outlier detection and evaluate the ability to identify different adversarial types. We validate the technique in the context of hospital audit logs where we show varying degrees of success based on user roles and the anticipated characteristics of attackers. In particular, it was found that RTAD exhibits strong performance for roles are described by a few topics, but weaker performance when users are more topic-agnostic. © 2013 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 17
ER  -

TY  - CONF
AU  - Song, Y.
AU  - Salem, M.B.
AU  - Hershkop, S.
AU  - Stolfo, S.J.
TI  - System level user behavior biometrics using Fisher features and Gaussian mixture models
PY  - 2013
C7  - 6565229
SP  - 52
EP  - 59
DO  - 10.1109/SPW.2013.33
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882737816&doi=10.1109%2FSPW.2013.33&partnerID=40&md5=d1cc783cce6be1cb251145a308ab7b17
AB  - We propose a machine learning-based method for biometric identification of user behavior, for the purpose of masquerade and insider threat detection. We designed a sensor that captures system-level events such as process creation, registry key changes, and file system actions. These measurements are used to represent a user's unique behavior profile, and are refined through the process of Fisher feature selection to optimize their discriminative significance. Finally, a Gaussian mixture model is trained for each user using these features. We show that this system achieves promising results for user behavior modeling and identification, and surpasses previous works in this area. © 2013 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 45
ER  -

TY  - CONF
AU  - Chiu, C.-Y.
AU  - Yeh, C.-T.
AU  - Lee, Y.-J.
TI  - Frequent pattern based user behavior anomaly detection for cloud system
PY  - 2013
C7  - 6783844
SP  - 61
EP  - 66
DO  - 10.1109/TAAI.2013.25
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899418111&doi=10.1109%2FTAAI.2013.25&partnerID=40&md5=45aa767df2452cdf8360465edda25770
AB  - Cloud Computing is a hot topic in the global IT industry, which is considered as the main part of the network and computing service provider in recent years. Some security issues will be more threatening in cloud computing, such as account theft and insider threat. We propose a framework to utilize anomaly detection and random re-sampling techniques for profiling user's behaviors via the frequent patterns of activated system processes. By utilizing the user profiles learned from normal data, our method can detect malicious activities and discriminate suspicious activities from different users. We use virtual machine (VM) to collect process log of normal users and malicious tools. The collected data is used on verifying if our method can detect the malicious activities on the system. The results show that all the malicious activities are detected with less than 4.6% false-positive rate. We also collect real-world data for testing the ability of discriminating activities collected from different users. The results showed that the user profiles can averagely detect 86% suspicious behaviors from different users with less than 1% false positive rate. © 2013 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 15
ER  -

TY  - CONF
AU  - Brdiczka, O.
AU  - Liu, J.
AU  - Price, B.
AU  - Shen, J.
AU  - Patil, A.
AU  - Chow, R.
AU  - Bart, E.
AU  - Ducheneaut, N.
TI  - Proactive insider threat detection through graph learning and psychological context
PY  - 2012
C7  - 6227698
SP  - 142
EP  - 149
DO  - 10.1109/SPW.2012.29
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864245980&doi=10.1109%2FSPW.2012.29&partnerID=40&md5=98103ecbb0b1d4ea607ac121257f47ff
AB  - The annual incidence of insider attacks continues to grow, and there are indications this trend will continue. While there are a number of existing tools that can accurately identify known attacks, these are reactive (as opposed to proactive) in their enforcement, and may be eluded by previously unseen, adversarial behaviors. This paper proposes an approach that combines Structural Anomaly Detection (SA) from social and information networks and Psychological Profiling (PP) of individuals. SA uses technologies including graph analysis, dynamic tracking, and machine learning to detect structural anomalies in large-scale information network data, while PP constructs dynamic psychological profiles from behavioral patterns. Threats are finally identified through a fusion and ranking of outcomes from SA and PP. The proposed approach is illustrated by applying it to a large data set from a massively multi-player online game, World of War craft (WoW). The data set contains behavior traces from over 350,000 characters observed over a period of 6 months. SA is used to predict if and when characters quit their guild (a player association with similarities to a club or workgroup in non-gaming contexts), possibly causing damage to these social groups. PP serves to estimate the five-factor personality model for all characters. Both threads show good results on the gaming data set and thus validate the proposed approach. © 2012 IEEE.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 101
ER  -

TY  - CONF
AU  - Gafny, M.
AU  - Shabtai, A.
AU  - Rokach, L.
AU  - Elovici, Y.
TI  - Detecting data misuse by applying context-based data linkage
PY  - 2010
T2  - Proceedings of the ACM Conference on Computer and Communications Security
SP  - 3
EP  - 11
DO  - 10.1145/1866886.1866890
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650097664&doi=10.1145%2F1866886.1866890&partnerID=40&md5=d039acebd7b4916645f4eb88b9d5fc86
AB  - Detecting data leakage/misuse poses a great challenge for organizations. Whether caused by malicious intent or an inadvertent mistake, data leakage/misuse can diminish a company's brand, reduce shareholder value, and damage the company's goodwill and reputation. This challenge is intensified when trying to detect and/or prevent data leakage/misuse performed by an insider with legitimate permissions to access the organization's systems and its critical data. In this paper we propose a new approach for identifying suspicious insiders who can access data stored in a database via an application. In the proposed method suspicious access to sensitive data is detected by analyzing the result-sets sent to the user following a request that the user submitted. Result-sets are analyzed within the instantaneous context in which the request was submitted. From the analysis of the result-set and the context we derive a "level of anomality". If the derived level is above a predefined threshold, an alert can be sent to the security officer. The proposed method applies data-linkage techniques in order to link the contextual features and the result-sets. Machine learning algorithms are then employed for generating a behavioral model during a learning phase. The behavioral model encapsulates knowledge on the behavior of a user; i.e., the characteristics of the result-sets of legitimate or malicious requests. This behavioral model is used for identifying malicious requests based on their abnormality. An evaluation with sanitized data shows the usefulness of the proposed method in detecting data misuse. © 2010 ACM.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 16
ER  -

TY  - BOOK
AU  - P. Tsai, J.J.P.
AU  - Yu, P.S.
TI  - Machine learning in cyber trust: Security, privacy, and reliability
PY  - 2009
SP  - 1
EP  - 362
DO  - 10.1007/978-0-387-88735-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892224543&doi=10.1007%2F978-0-387-88735-7&partnerID=40&md5=3db9906da4b6caa622bcc24fa947a1c2
AB  - Many networked computer systems are far too vulnerable to cyber attacks that can inhibit their functioning, corrupt important data, or expose private information. Not surprisingly, the field of cyber-based systems turns out to be a fertile ground where many tasks can be formulated as learning problems and approached in terms of machine learning algorithms. This book contains original materials by leading researchers in the area and covers applications of different machine learning methods in the security, privacy, and reliability issues of cyber space. It enables readers to discover what types of learning methods are at their disposal, summarizing the state of the practice in this important area, and giving a classification of existing work. Specific features include the following: A survey of various approaches using machine learning/data mining techniques to enhance the traditional security mechanisms of databases A discussion of detection of SQL Injection attacks and anomaly detection for defending against insider threats An approach to detecting anomalies in a graph-based representation of the data collected during the monitoring of cyber and other infrastructures An empirical study of seven online-learning methods on the task of detecting malicious executables A novel network intrusion detection framework for mining and detecting sequential intrusion patterns A solution for extending the capabilities of existing systems while simultaneously maintaining the stability of the current systems An image encryption algorithm based on a chaotic cellular neural network to deal with information security and assurance An overview of data privacy research, examining the achievements, challenges and opportunities while pinpointing individual research efforts on the grand map of data privacy protection An algorithm based on secure multiparty computation primitives to compute the nearest neighbors of records in horizontally distributed data An approach for assessing the reliability of SOA-based systems using AI reasoning techniques The models, properties, and applications of context-aware Web services, including an ontology-based context model to enable formal description and acquisition of contextual information pertaining to service requestors and services Those working in the field of cyber-based systems, including industrial managers, researchers, engineers, and graduate and senior undergraduate students will find this an indispensable guide in creating systems resistant to and tolerant of cyber attacks. © Springer Science+Business Media, LLC 2009. All rights reserved.
M3  - Book
DB  - Scopus
N1  - Export Date: 23 December 2025; Cited By: 18
ER  -

